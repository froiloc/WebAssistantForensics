{
  "metadata": {
    "title": "Brainstorming Prompt-Erstellung (5!5)",
    "dates": {
      "created": "2025-10-09T21:16:20",
      "updated": "2025-10-10T12:23:02",
      "exported": "2025-10-12T13:54:19"
    },
    "link": "https://claude.ai/chat/b6343366-95f9-47f2-8882-a7c9c90af5c0",
    "powered_by": "Claude Exporter (https://www.claudexporter.com)"
  },
  "messages": [
    {
      "role": "Prompt",
      "say": "Bitte lies task3-Continuation-Prompt-für-neuen-Chat.md aus dem Projekt-Dateispeicher und folge den darin stehenden Anmerkungen und Anweisungen.\nIch freue mich auf die weitere Zusammenarbeit mit dir. Es macht mir viel Spaß und ich sehe einen guten Fortschritt.",
      "time_iso8601": "2025-10-09T21:16:21"
    },
    {
      "role": "Response",
      "say": "Ich freue mich sehr über dein positives Feedback und die gute Zusammenarbeit! Lass mich zunächst die relevante Datei aus dem Projekt-Dateispeicher lesen, um den aktuellen Stand und die spezifischen Anweisungen zu verstehen.\n\n\nproject_knowledge_search\n\n\nRequest\n\n\n{\n  \"query\": \"task3-Continuation-Prompt-für-neuen-Chat.md\"\n}\n\n\nResponse\n\n\ntask2.md - Continuation Prompt für neuen Chat.md\n✅ Inhaltliche Anforderungen (Cluster 1)\n2. ✅ Strukturelle Anforderungen (Cluster 2)\n3. ✅ Technische Anforderungen (Cluster 3)\n4. ⏳ Prompt-Entwicklung für KI (Cluster 4) **← JETZT DRAN**\n5. 🔵 Qualitätssicherung & Testing (Cluster 5)\n6. 🔵 Workflow & Rollen (Cluster 6)\n\n---\n\n## Aktueller Stand\n\nWir haben die **komplette Spezifikation** für die Content-Generierung dokumentiert:\n\n### Was ist fertig:\n\n**Inhaltlich (Cluster 1):**\n- Zielgruppe: IT-ferne Ermittler (Mittlere Reife, niedrige IT-Kenntnisse)\n- Detail-Level-System: 4 Stufen (Schnell, Standard, Detailliert, Show-Only)\n- Terminologie-Strategie: Deutsch bevorzugt, englische Fachbegriffe wo etabliert\n- Medien-Entscheidungsmatrix: Wann Screenshot/Annotiert/Video/Diagramm\n- Content-Type-System: instruction, explanation, visual, background, info, hint, attention, warning\n- Multi-Tool-Strategie: Tool-agnostisch mit tool-spezifischen Metadaten\n\n**Strukturell (Cluster 2):**\n- Hierarchische Struktur: 3-5 Ebenen (Topic → Chapter → Section → Subsection → Deep-Dive)\n- data-ref Granularität & Namenskonventionen\n- JSON-LD Metadaten pro Section\n- Agent-Context-Block (einer pro Section, am Ende)\n- Navigation-Strategie: Freie Navigation\n\n**Technisch (Cluster 3):**\n- BFSG-konforme Barrierefreiheit (Sprachauszeichnung, Alt-Texte, Überschriften-Hierarchie)\n- HTML-Element-Whitelist (32 erlaubte Elemente)\n- Pflicht-/Optional-Attribute pro Element\n- CSS-Klassen-System (Pflicht-Klassen, Review-Prozess)\n- Attribut-Reihenfolge & Formatierung (class → id → data-* → sonstige)\n- Content-Type-Box-Entscheidungsmatrix (info/hint/attention/warning)\n- HTML-Kommentar-Konventionen (AGENT:/MEDIA:/NOTE:/TODO:/DECISION-REVIEW:)\n\n---\n\n## Nächster Schritt: Cluster 4 - Prompt-Entwicklung\n\n### Ziel\n\nEntwicklung eines **vollständigen, präzisen Master-Prompts** für Claude Sonnet 4.5 zur Generierung von hochwertigem Content für ~100-150 Sections.\n\nDer Prompt muss **alle Anforderungen aus Cluster 1-3 integrieren** und für die KI **direkt verwendbar** sein.\n\n### Aufgaben für Cluster 4\n\n**Phase A: Prompt-Struktur & Architektur**\n1. Aufbau des Master-Prompts (Abschnitte, Hierarchie)\n2. Informationsdichte vs. Verständlichkeit\n3. Kontext-Management (was muss immer dabei sein, was ist optional?)\n4. Modularer Aufbau (wiederverwendbare Komponenten)\n\n**Phase B: Prompt-Inhalte**\n1. Integration aller Anforderungen aus Cluster 1-3\n2. Entscheidungsbäume für KI (Content-Type, Media-Type, etc.)\n3. Beispiele & Counter-Beispiele\n4. Grenzfall-Behandlung\n\n**Phase C: Testing & Iteration**\n1. Test-Prompts erstellen (verschiedene Schwierigkeitsgrade)\n2. Generierte Sections validieren\n3. Prompt iterativ verbessern\n4.\n\n\ntask3-Continuation-Prompt-für-neuen-Chat.md\n- Section-Hierarchie und Navigation\n   - data-ref Vergabelogik\n\n3. âœ… **Technische Anforderungen**\n   - Medien-Anweisungen (Screenshots, annotierte Bilder, Videos)\n   - Agent-Integration (Context-Blocks, Trigger-Points)\n   - Barrierefreiheit (BFSG-KonformitÃ¤t)\n   - HTML-Syntax und Attribut-VollstÃ¤ndigkeit\n\n4. âœ… **QualitÃ¤tssicherung & Testing**\n   - Testkriterien fÃ¼r generierte Sections\n   - Validierungsprozess (syntaktisch + semantisch)\n   - Metadaten (Quellen, Versionen, Erstellungsdatum)\n   - Iterationslogik (wann ist eine Section \"fertig\"?)\n\n5. â³ **Workflow & Rollen** **â† JETZT DRAN**\n   - Arbeitsschritte der KI (Research â†’ Draft â†’ Detailing â†’ Review â†’ Syntax-Check)\n   - Rollendefinitionen fÃ¼r verschiedene Phasen\n   - Schnittstellendefinition zwischen den Phasen\n   - Fehlerbehandlung und Feedback-Loops\n\n---\n\n## Bisheriger Fortschritt\n\n**Abgeschlossen:**\n\n- âœ… **Cluster 1:** Inhaltliche Anforderungen (siehe `cluster1-final.md`)\n- âœ… **Cluster 2:** Strukturelle Anforderungen (siehe `cluster2_results.md`)\n- âœ… **Cluster 3:** Technische Anforderungen\n  - âœ… **Teil A - Barrierefreiheit (BFSG):**\n    - Sprachauszeichnung (`lang`-Attribute): `cluster3_BFSG-Sprachauszeichnung-Richtlinien.md`\n    - Alt-Texte & Ãœberschriften-Hierarchie: `cluster3_BFSG-Barrierefreiheit-Content.md`\n  - âœ… **Teil B - HTML-Syntax & Attribut-VollstÃ¤ndigkeit:**\n    - VollstÃ¤ndige HTML-Element-Spezifikation: `cluster3_Phase-B_HTML-Syntax-und-Attribut-VollstÃ¤ndigkeit.md`\n- âœ… **Cluster 4:** QualitÃ¤tssicherung & Testing (siehe `cluster4_QualitÃ¤tssicherung-Metadaten-Validierung.md`)\n\n---\n\n## Aktueller Stand\n\nWir haben die **komplette Spezifikation** fÃ¼r die Content-Generierung dokumentiert:\n\n### Was ist fertig:\n\n**Inhaltlich (Cluster 1):**\n- Zielgruppe: IT-ferne Ermittler (Mittlere Reife, niedrige IT-Kenntnisse)\n- Detail-Level-System: 4 Stufen (Schnell, Standard, Detailliert, Show-Only)\n- Terminologie-Strategie: Deutsch bevorzu\n\n\ntask3-Continuation-Prompt-für-neuen-Chat.md\nCluster 5 fokussiert sich auf das **\"Wie\"** der Umsetzung:\n- Welche Schritte durchlÃ¤uft die KI?\n- Wer ist wofÃ¼r verantwortlich?\n- Wie kommunizieren die verschiedenen Akteure/Systeme?\n- Was passiert bei Fehlern?\n\n---\n\n### Aufgaben fÃ¼r Cluster 5\n\n**1. Arbeitsschritte der KI:**\n- Detaillierte Phasen: Research â†’ Draft â†’ Detailing â†’ Review â†’ Syntax-Check\n- Was macht die KI in jeder Phase konkret?\n- Welche Inputs/Outputs hat jede Phase?\n- Welche Tools/APIs nutzt die KI?\n- ZeitabschÃ¤tzungen pro Phase\n\n**2. Rollendefinitionen:**\n- **KI-Generator:** Erstellt initiale Sections (Draft)\n- **KI-Reviewer:** Semantische VorprÃ¼fung (Konsistenz, PlausibilitÃ¤t, etc.)\n- **Maintainer:** Finale fachliche PrÃ¼fung, Medien-Erstellung, Approval\n- **Validator:** Python-Skripte fÃ¼r syntaktische PrÃ¼fung\n- Weitere Rollen (falls notwendig)\n\n**3. Schnittstellendefinition:**\n- Input/Output zwischen Phasen\n- Datenformate (JSON, HTML, Reports)\n- Ãœbergabepunkte und Trigger\n- Kommunikationsprotokolle\n\n**4. Fehlerbehandlung & Feedback-Loops:**\n- Was passiert bei syntaktischen Fehlern? (Automatische Korrektur durch KI)\n- Was passiert bei semantischen Problemen? (Feedback an KI, erneute Generierung)\n- Was passiert bei Reject durch Maintainer? (Dokumentation, Prompt-Verbesserung)\n- Eskalationspfade bei wiederholten Fehlern\n\n**5. Tooling & Automation:**\n- Welche Tools unterstÃ¼tzen den Workflow?\n- Kann der Prozess (teilweise) automatisiert werden?\n- Welche manuellen Schritte sind unvermeidlich?\n- CI/CD-Integration mÃ¶glich?\n\n---\n\n## Arbeitsweise\n\n- **Kleinschrittig vorgehen** (keine groÃŸen SprÃ¼nge)\n- **Top-Down-Design** (vom Groben ins Detail)\n- **GefÃ¼hrte Fragen** stellen, bis 95% Klarheit erreicht ist\n- Ã„nderungen nur **vorschlagen und begrÃ¼nden**\n- Jede Ã„nderung muss **durch mich verifiziert und akzeptiert** werden\n- Am Ende ein **Ergebnisdokument** erstellen (analog zu Cluster 1-4)\n\n---\n\n## Wichtige Projekt-Richtlinien\n\n### Textstil fÃ¼r dich (KI):\n- Bleibe eng an meiner Vorgabe\n- FÃ¼ge keine zusÃ¤tzlichen Aspekte hinzu\n- Erst meine Aufgabe umsetzen, dann separat Verbesserungen vorschlagen\n- VerbesserungsvorschlÃ¤ge in 3 AbsÃ¤tzen erklÃ¤ren: Vorteile, Technik, Aufwand\n- Vermeide Telegramstil\n- Hebe wichtige Aussagen durch **Fettmarkieren** hervor\n\n### Code-Ã„nderungen:\n- Immer kleinschrittig und Schritt fÃ¼r Schritt\n- Keine unerwÃ¼nschten Nebeneffekte\n- CSS-Variablen `--variable*` bewahren und nutzen\n- Keine absoluten GrÃ¶ÃŸen/Farben auÃŸerhalb der Themes\n- Immer den **aktuellen Code** aus dem Projekt-Dateispeicher als Basis verwenden\n- Jede Ã„nderung begrÃ¼nden\n- Mindestens einen Test vorschlagen\n\n### Debugging des Webfrontends (index.html +CSS +JS):\n- Nach Tests wird Debug-Output in `Debug-output.XXX` abgelegt (XXX = Buildnummer)\n- HÃ¶chste Buildnummer = aktuellster Debug-Output\n\n---\n\n## Meine Frage\n\nBitte lies die **sechs Dokumente** im Projekt-Dateispeicher:\n1. `cluster1-final.md` (Inhaltliche Anforderungen)\n2.\n\n\ntask2.md - Continuation Prompt für neuen Chat.md\nAufbau des Master-Prompts (Abschnitte, Hierarchie)\n2. Informationsdichte vs. Verständlichkeit\n3. Kontext-Management (was muss immer dabei sein, was ist optional?)\n4. Modularer Aufbau (wiederverwendbare Komponenten)\n\n**Phase B: Prompt-Inhalte**\n1. Integration aller Anforderungen aus Cluster 1-3\n2. Entscheidungsbäume für KI (Content-Type, Media-Type, etc.)\n3. Beispiele & Counter-Beispiele\n4. Grenzfall-Behandlung\n\n**Phase C: Testing & Iteration**\n1. Test-Prompts erstellen (verschiedene Schwierigkeitsgrade)\n2. Generierte Sections validieren\n3. Prompt iterativ verbessern\n4. Best Practices dokumentieren\n\n---\n\n## Arbeitsweise\n\n- **Kleinschrittig vorgehen** (keine großen Sprünge)\n- **Top-Down-Design** (vom Groben ins Detail)\n- **Geführte Fragen** stellen, bis 95% Klarheit erreicht ist\n- Änderungen nur **vorschlagen und begründen**\n- Jede Änderung muss **durch mich verifiziert und akzeptiert** werden\n- Am Ende ein **Ergebnisdokument** erstellen (analog zu Cluster 1-3)\n\n---\n\n## Wichtige Projekt-Richtlinien\n\n### Textstil für dich (KI):\n- Bleibe eng an meiner Vorgabe\n- Füge keine zusätzlichen Aspekte hinzu\n- Erst meine Aufgabe umsetzen, dann separat Verbesserungen vorschlagen\n- Verbesserungsvorschläge in 3 Absätzen erklären: Vorteile, Technik, Aufwand\n- Vermeide Telegramstil\n- Hebe wichtige Aussagen durch **Fettmarkieren** hervor\n\n### Code-Änderungen:\n- Immer kleinschrittig und Schritt für Schritt\n- Keine unerwünschten Nebeneffekte\n- CSS-Variablen `--variable*` bewahren und nutzen\n- Keine absoluten Größen/Farben außerhalb der Themes\n- Immer den **aktuellen Code** aus dem Projekt-Dateispeicher als Basis verwenden\n- Jede Änderung begründen\n- Mindestens einen Test vorschlagen\n\n### Debugging:\n- Nach Tests wird Debug-Output in `Debug-output.XXX` abgelegt (XXX = Buildnummer)\n- Höchste Buildnummer = aktuellster Debug-Output\n\n---\n\n## Meine Frage\n\nBitte lies die fünf Dokumente im Projekt-Dateispeicher:\n1. `cluster1-final.md` (Inhaltliche Anforderungen)\n2. `cluster2_results.md` (Strukturelle Anforderungen)\n3. `cluster3_BFSG-Sprachauszeichnung-Richtlinien.md` (BFSG Teil 1)\n4. `cluster3_BFSG-Barrierefreiheit-Content.md` (BFSG Teil 2)\n5. `cluster3_Phase-B_HTML-Syntax-und-Attribut-Vollständigkeit.md` (HTML-Syntax)\n\n**Lass uns dann Cluster 4: Prompt-Entwicklung angehen.**\n\nStelle mir geführte Fragen, damit wir gemeinsam den Master-Prompt entwickeln können. Wir gehen wie immer kleinschrittig vor und klären zunächst die grundlegende Struktur, bevor wir ins Detail gehen.\n\n---\n\n## Kontext-Informationen\n\n**Projekt:** WebAssistentForensics  \n**Ziel-Tool (initial):** Magnet AXIOM Examine  \n**Spätere Erweiterung:** X-Ways Forensics, Cellebrite Reader  \n**Haupt-Zielgruppe:** IT-ferne Polizei-Ermittler  \n**Content-Umfang:** ~100-150 Sections  \n**KI-Modell:** Claude Sonnet 4.5  \n**Validierung:** Python-basiert + JSON-Schema  \n\n---\n\n**Ich freue mich auf die Zusammenarbeit!**\n\n\ntask3-Continuation-Prompt-für-neuen-Chat.md\ngt, englische Fachbegriffe wo etabliert\n- Medien-Entscheidungsmatrix: Wann Screenshot/Annotiert/Video/Diagramm\n- Content-Type-System: instruction, explanation, visual, background, info, hint, attention, warning\n- Multi-Tool-Strategie: Tool-agnostisch mit tool-spezifischen Metadaten\n\n**Strukturell (Cluster 2):**\n- Hierarchische Struktur: 3-5 Ebenen (Topic â†’ Chapter â†’ Section â†’ Subsection â†’ Deep-Dive)\n- data-ref GranularitÃ¤t & Namenskonventionen\n- JSON-LD Metadaten pro Section\n- Agent-Context-Block (einer pro Section, am Ende)\n- Navigation-Strategie: Freie Navigation\n\n**Technisch (Cluster 3):**\n- BFSG-konforme Barrierefreiheit (Sprachauszeichnung, Alt-Texte, Ãœberschriften-Hierarchie)\n- HTML-Element-Whitelist (32 erlaubte Elemente)\n- Pflicht-/Optional-Attribute pro Element\n- CSS-Klassen-System (Pflicht-Klassen, Review-Prozess)\n- Attribut-Reihenfolge & Formatierung (class â†’ id â†’ data-* â†’ sonstige)\n- Content-Type-Box-Entscheidungsmatrix (info/hint/attention/warning)\n- HTML-Kommentar-Konventionen (AGENT:/MEDIA:/NOTE:/TODO:/DECISION-REVIEW:)\n\n**QualitÃ¤tssicherung (Cluster 4):**\n- **Validierungsebenen definiert:**\n  - Syntaktisch (Python-Skripte + JSON-Schema, automatisiert)\n  - Semantisch (KI-Agent VorprÃ¼fung + Maintainer Final-PrÃ¼fung)\n  - BFSG-KonformitÃ¤t (implizit in syntaktischen PrÃ¼fungen)\n- **Testkriterien spezifiziert:**\n  - Syntaktisch: Pflicht-Attribute, HTML-Struktur, Cross-References, Barrierefreiheit\n  - Semantisch: Konsistenz, PlausibilitÃ¤t, Terminologie, Zusammenhang, Gliederung\n- **Validierungsprozess (2 Optionen):**\n  - Option B (Standard): Draft â†’ Validierung â†’ Review (Medien) â†’ Approved â†’ Published\n  - Option A (Erweitert): Mit zweifacher KI-PrÃ¼fung (vor/nach Medien-Erstellung)\n- **Fehler-Kategorisierung:** CRITICAL / ERROR / WARNING / INFO\n- **Fehler-Log-System:** JSON-basierte Dokumentation (error-log.json) fÃ¼r iterative Prompt-Verbesserung\n- **Metadaten erweitert:**\n  - Neue QA-Felder: reviewStatus, lastReviewer, validationScore, knownIssues, reviewCycles, timeToPublish\n  - JSON-LD vollstÃ¤ndig spezifiziert\n- **Status-ÃœbergÃ¤nge:** Draft â†’ Review â†’ Approved â†’ Published (kein automatisches Approval)\n- **Versionierung:** MAJOR.MINOR.BUILD (Git-basiert)\n- **Metriken:**\n  - Pro Section: Validierungsfehler, Review-Zyklen, Zeit, validationScore (0-100)\n  - Aggregiert: Durchschnitte, Status-Verteilung, Ablehnungsquote\n- **Datengrundlagen fÃ¼r KI-PrÃ¼fung:**\n  - Alle approbierten Sections, Terminologie-Entscheidungsliste, Rahmenplan & Gliederung\n  - Quellmaterial (AXIOM Handbuch), Style-Guides, Antwortschema\n\n---\n\n## NÃ¤chster Schritt: Cluster 5 - Workflow & Rollen\n\n### Ziel\n\nDefinition der **konkreten ArbeitsablÃ¤ufe und Verantwortlichkeiten** bei der KI-gestÃ¼tzten Content-Generierung fÃ¼r ~100-150 Sections.\n\nCluster 5 fokussiert sich auf das **\"Wie\"** der Umsetzung:\n- Welche Schritte durchlÃ¤uft die KI?\n- Wer ist wofÃ¼r verantwortlich?\n- Wie kommunizieren die verschiedenen Akteure/Systeme?\n\n\ntask2.md - Continuation Prompt für neuen Chat.md\n# Projekt-Fortsetzung: Cluster 4 - Prompt-Entwicklung für KI-Content-Generierung\n\nHallo! Ich arbeite am Projekt **WebAssistentForensics** und möchte die Arbeit fortsetzen.\n\n## Kontext\n\nIch entwickle ein strukturiertes Wissenssystem für Polizeibeamte zu IT-Forensik-Themen. Das System basiert auf:\n- JSON-Schema-validiertem HTML-Content\n- Verschiedene Detail-Level (Basic, Best-Practice, Expert, Show-Only)\n- BFSG-konforme Barrierefreiheit\n- Python-basierte Validierung\n- KI-gestützte Content-Generierung (Claude Sonnet 4.5)\n\n## Bisheriger Fortschritt\n\n**Abgeschlossen:**\n- ✅ **Cluster 1:** Inhaltliche Anforderungen (siehe `cluster1-final.md`)\n- ✅ **Cluster 2:** Strukturelle Anforderungen (siehe `cluster2_results.md`)\n- ✅ **Cluster 3:** Technische Anforderungen\n  - ✅ **Teil A - Barrierefreiheit (BFSG):**\n    - Sprachauszeichnung (`lang`-Attribute): `cluster3_BFSG-Sprachauszeichnung-Richtlinien.md`\n    - Alt-Texte & Überschriften-Hierarchie: `cluster3_BFSG-Barrierefreiheit-Content.md`\n  - ✅ **Teil B - HTML-Syntax & Attribut-Vollständigkeit:**\n    - Vollständige HTML-Element-Spezifikation: `cluster3_Phase-B_HTML-Syntax-und-Attribut-Vollständigkeit.md`\n\n**Cluster-Übersicht (Originalplanung):**\n1. ✅ Inhaltliche Anforderungen (Cluster 1)\n2. ✅ Strukturelle Anforderungen (Cluster 2)\n3. ✅ Technische Anforderungen (Cluster 3)\n4. ⏳ Prompt-Entwicklung für KI (Cluster 4) **← JETZT DRAN**\n5. 🔵 Qualitätssicherung & Testing (Cluster 5)\n6.\n\n\ntask3-Continuation-Prompt-für-neuen-Chat.md\n`cluster1-final.md` (Inhaltliche Anforderungen)\n2. `cluster2_results.md` (Strukturelle Anforderungen)\n3. `cluster3_BFSG-Sprachauszeichnung-Richtlinien.md` (BFSG Teil 1)\n4. `cluster3_BFSG-Barrierefreiheit-Content.md` (BFSG Teil 2)\n5. `cluster3_Phase-B_HTML-Syntax-und-Attribut-VollstÃ¤ndigkeit.md` (HTML-Syntax)\n6. `cluster4_QualitÃ¤tssicherung-Metadaten-Validierung.md` (QualitÃ¤tssicherung)\n\n**Lass uns dann Cluster 5: Workflow & Rollen angehen.**\n\nStelle mir gefÃ¼hrte Fragen, damit wir gemeinsam den Workflow und die Rollen definieren kÃ¶nnen. Wir gehen wie immer kleinschrittig vor und klÃ¤ren zunÃ¤chst die grundlegende Struktur, bevor wir ins Detail gehen.\n\n---\n\n## Kontext-Informationen\n\n**Projekt:** WebAssistentForensics  \n**Ziel-Tool (initial):** Magnet AXIOM Examine  \n**SpÃ¤tere Erweiterung:** X-Ways Forensics, Cellebrite Reader  \n**Haupt-Zielgruppe:** IT-ferne Polizei-Ermittler  \n**Content-Umfang:** ~100-150 Sections  \n**KI-Modell:** Claude Sonnet 4.5  \n**Validierung:** Python-basiert + JSON-Schema  \n\n---\n\n**Ich freue mich auf die Zusammenarbeit!**\n\n\ntask3-Continuation-Prompt-für-neuen-Chat.md\n# Projekt-Fortsetzung: Cluster 5 - Workflow & Rollen\n\nHallo! Ich arbeite am Projekt **WebAssistentForensics** und mÃ¶chte die Arbeit fortsetzen.\n\n## Kontext\n\nIch entwickle ein strukturiertes Wissenssystem fÃ¼r Polizeibeamte zu IT-Forensik-Themen. Das System basiert auf:\n- JSON-Schema-validiertem HTML-Content\n- Verschiedene Detail-Level (Basic, Best-Practice, Expert, Show-Only)\n- BFSG-konforme Barrierefreiheit\n- Python-basierte Validierung\n- KI-gestÃ¼tzte Content-Generierung (Claude Sonnet 4.5)\n\n---\n\n## Woran wir gerade arbeiten\n\nDerzeit sind wir mit einem **fÃ¼nfstufigen Brainstorming** beschÃ¤ftigt. **Stufen 1 bis 4 haben wir abgeschlossen.** Jetzt folgt Stufe 5: **Workflow & Rollen**.\n\n### Roadmap fÃ¼r das Brainstorming\n\n1. âœ… **Inhaltliche Anforderungen**\n   - Fachliche Korrektheit und Quellenvalidierung\n   - VerstÃ¤ndlichkeitsniveau (Zielgruppe: Polizeibeamte unterschiedlicher IT-Kenntnisse)\n   - VollstÃ¤ndigkeit innerhalb der Detailgrade\n   - Konsistenz in Terminologie und Struktur\n\n2. âœ… **Strukturelle Anforderungen**\n   - Schema-KonformitÃ¤t (JSON-Validierung)\n   - Detail-Level-Systematik (wann Level 1, 2, 3?)\n   - Section-Hierarchie und Navigation\n   - data-ref Vergabelogik\n\n3. âœ… **Technische Anforderungen**\n   - Medien-Anweisungen (Screenshots, annotierte Bilder, Videos)\n   - Agent-Integration (Context-Blocks, Trigger-Points)\n   - Barrierefreiheit (BFSG-KonformitÃ¤t)\n   - HTML-Syntax und Attribut-VollstÃ¤ndigkeit\n\n4. âœ… **QualitÃ¤tssicherung & Testing**\n   - Testkriterien fÃ¼r generierte Sections\n   - Validierungsprozess (syntaktisch + semantisch)\n   - Metadaten (Quellen, Versionen, Erstellungsdatum)\n   - Iterationslogik (wann ist eine Section \"fertig\"?)\n\n\nVielen Dank für die ausführliche Einführung und das positive Feedback! Ich habe die Continuation-Prompts gelesen und verstehe nun den aktuellen Projektstand:\n\n\nWas ich verstanden habe\n\n\nProjektkontext:\n\n\nDu entwickelst WebAssistentForensics – ein Wissenssystem für IT-ferne Polizeibeamte\n\nZiel-Tool initial: Magnet AXIOM Examine (später X-Ways Forensics, Cellebrite Reader)\n\nContent-Umfang: ~100-150 Sections\n\nKI-gestützte Generierung mit Claude Sonnet 4.5\n\n\nAbgeschlossene Cluster:\n\n\n✅ Cluster 1: Inhaltliche Anforderungen (Zielgruppe, Detail-Level, Terminologie, Medien)\n\n✅ Cluster 2: Strukturelle Anforderungen (Hierarchie, data-ref, JSON-LD, Navigation)\n\n✅ Cluster 3: Technische Anforderungen (BFSG-Barrierefreiheit, HTML-Whitelist, CSS-Klassen)\n\n✅ Cluster 4: Qualitätssicherung & Testing (Validierung, Metadaten, Error-Logs)\n\n\nAktueller Arbeitsschritt:\n\n\n⏳ Cluster 5: Workflow & Rollen – Definition der konkreten Arbeitsabläufe und Verantwortlichkeiten\n\n\n\nMeine erste Frage zur Orientierung (Cluster 5)\n\n\nBevor wir in die Details des Workflows einsteigen, möchte ich das Big Picture verstehen:\n\n\nWelche Akteure/Systeme sind grundsätzlich am Content-Generierungsprozess beteiligt?\n\n\nIch vermute basierend auf den bisherigen Dokumenten:\n\n\nKI-System (Claude Sonnet 4.5) – generiert Content\n\nPython-Validierungsskripte – prüfen Syntax automatisch\n\nDu als Maintainer – finale fachliche Prüfung und Approval\n\nEventuell weitere KI-Instanzen für Review/Qualitätsprüfung?\n\n\nMeine konkrete Frage:\n\n\nSind diese vier Rollen korrekt?\n\nGibt es weitere Akteure (z.B. separate Medien-Ersteller, Fachexperten für bestimmte Tools, etc.)?\n\nOder planst du aktuell nur mit KI-Generator + Validator + Dir als Maintainer?\n\n\nDiese Klarstellung hilft mir, den Workflow von Anfang an richtig zu strukturieren.",
      "time_iso8601": "2025-10-09T21:16:41"
    },
    {
      "role": "Prompt",
      "say": "Zur ersten Frage)\n\n\nKI-System (Claude Sonnet 4.5) für Content-Erstellung\n\nPython-Validierungsskripte zur Syntaxprüfung\n\nMaintainer (Kollegen oder ich) für Medienerstellung, fachliche Prüfung und Approval\n\nKI-System für Basic Semantic Check, Qualitätsprüfung, Review\n\nMaintainer (Kollegen oder ich) für Einpflegen nach Approval (Versionierung und Verteilen)\n\nImplizit (Ersteller von Handbüchern der Software, und andere Hilfe-Dokumente) (passiv, keine aktive Rolle)\nWeitere Akteure gibt es nicht. Aber ich würde auch eher die Rollen betrachten und benennen, die sie einnehmen. Content-Creator, Content-Validator, Content-Enricher, Content-Reviewer, Content-Distributor\n\n\nWährend die Python-Scripte vor allem Content validieren, kann das KI-System sowohl Content-Creator und später Content-Reviewer sein. Der Maintainer ist Content-Creator (für Medien), Content-Validator (wertet die Ergebnisse der Python-Scripte aus und behebt Missstände), Content-Enricher (ergänzt den Inhalt um Medieninhalte, Glossar, Agent), Content-Reviewer (begutachtet die Korrektheit, Konsistenz und Qualität aus einer fachlichen und menschlichen Perspektive), Content-Distributor (komponiert das Endprodukt und verteilt es).\n\n\nIch plane also, dass jeder Akteur durchaus mehrere Rollen und Arbeitsschritte durchführen und begleiten wird.",
      "time_iso8601": "2025-10-09T22:13:55"
    },
    {
      "role": "Response",
      "say": "Ausgezeichnet! Das ist eine sehr klare und durchdachte Rollenverteilung. Ich verstehe jetzt die Mehrfachfunktionen der Akteure und die fünf Kernrollen.\n\n\nMein Verständnis (zur Bestätigung)\n\n\nAkteure und ihre Rollen:\n\nAkteur\nRollen\nKI-System (Claude)\nContent-Creator, Content-Reviewer\nPython-Skripte\nContent-Validator (syntaktisch)\nMaintainer (du/Kollegen)\nContent-Creator (Medien), Content-Validator (Auswertung), Content-Enricher (Medien/Glossar/Agent), Content-Reviewer (fachlich/menschlich), Content-Distributor\nHandbuch-Autoren\n(passiv, Quellenmaterial)\n\nDie fünf Kernrollen:\n\n\nContent-Creator – erstellt initialen Content\n\nContent-Validator – prüft Syntax/Struktur\n\nContent-Enricher – ergänzt Medien/Glossar/Agent-Context\n\nContent-Reviewer – prüft Qualität/Konsistenz/Korrektheit\n\nContent-Distributor – komponiert und verteilt Endprodukt\n\n\n\nNächste Frage: Workflow-Phasen\n\n\nUm den Workflow zu strukturieren, brauche ich Klarheit über die zeitliche Abfolge der Arbeitsschritte. Basierend auf Cluster 4 vermute ich folgenden Ablauf:\n\n\nVermuteter Workflow:\n\n\n1. Research (KI: Quellen analysieren)\n2. Draft (KI: initialer Content)\n3. Syntax-Validierung (Python-Skripte)\n4. Fehlerkorrektur (KI oder Maintainer)\n5. Semantic Review (KI: Konsistenz/Plausibilität)\n6. Medien-Erstellung (Maintainer)\n7. Content-Enrichment (Maintainer: Medien einbinden, Glossar, Agent)\n8. Final Review (Maintainer: fachliche Prüfung)\n9. Approval (Maintainer)\n10. Distribution (Maintainer: Versionierung, Veröffentlichung)\n\n\nMeine konkreten Fragen:\n\n\nIst diese Reihenfolge grundsätzlich korrekt? Oder sollen manche Schritte parallel laufen oder in anderer Reihenfolge?\n\nResearch-Phase: Soll die KI aktiv externe Quellen recherchieren (z.B. via Web-Search) oder arbeitet sie ausschließlich mit vorab bereitgestelltem Material (AXIOM-Handbuch, bereits approbierte Sections)?\n\nFehlerkorrektur nach Syntax-Validierung: Wer korrigiert was? Sollen CRITICAL/ERROR automatisch von der KI korrigiert werden, während WARNING/INFO vom Maintainer manuell geprüft werden?\n\nWann findet das Semantic Review statt? Vor oder nach der Medien-Erstellung? (In Cluster 4 gab es zwei Optionen – welche bevorzugst du?)\n\n\nDiese vier Punkte helfen mir, den Workflow präzise zu definieren.",
      "time_iso8601": "2025-10-09T22:14:13"
    },
    {
      "role": "Prompt",
      "say": "Bezüglich des Workflows fehlt mir noch eine entscheidende, initiale Phase. Die Sections sollen zwar einzeln erstellt werden (Draft) aber sie sollen sich in ein Gesamtgefüge einpassen. Daher ist es wichtig, dass vor dem Draft noch eine Phase für die Erstellung des Content-Rahmens und des strategischen Zieles steht. Diese geben der KI beim Draft die Leitplanken, was sie inhaltlich einbetten soll und was nicht, wo der Fokus gesetzt werden soll und so weiter. Diese Phase ist extrem wichtig für ein rundes Endergebnis, das sich nicht wie Stückwerk anfühlt. Auch prüft in Schritt 5 die KI in ihrer Semantic Review anhand dieser Kriterien. Und kann dann sogar Scores für die einzelnen Sections geben, um zu bewerten, ob sie für das Endziel geeignet sind oder ob es noch Mängel gibt.\n\n\nParallel wird hier nichts laufen können. Vielleicht kann man mehrere Drafts parallel laufen lassen, wenn die Vorbereitung gut ist. Aber eigentlich dachte ich daran, der KI die Drafts der vorherigen Sections ebenfalls zur Orientierung zu übergeben.\n\n\nBezüglich Research-Phase: Ich würde die Quellen selber benennen, um die Qualität der Quellen besser einschätzen zu können. Das ist wichtig. Das Thema ist sehr weit in einer Nische, da gibt es nicht viele gute Quellen im Internet.\n\n\nDer Prozess wird wahrscheinlich nicht automatisiert ablaufen, obwohl das vielleicht sogar mit dem Konsolentool von Claude.AI ginge. Aber ich möchte zumindest in der Version 1.0 noch die volle manuelle Kontrolle haben, damit ich beobachten und lernen kann, für eine spätere Verbesserung und Automatisierung. Hey, ich bin Informatiker, natürlich werde ich es automatisieren, wenn ich dafür Bedarf und einen Weg sehe. :-D\n\n\nIch bevorzuge die Semantic Review mit Medien nach der Medienerstellung. Ich habe noch nicht getestet, wie gut die Qualität einer semantischen Review mit Medien durch die KI sein kann. Das müsste noch getestet werden. Im Moment, für Version 1.0, würde ich es erst einmal ohne Medien machen und daher die semantische Review vor der Medien-Erstellung ansetzen.",
      "time_iso8601": "2025-10-09T22:32:44"
    },
    {
      "role": "Response",
      "say": "Hervorragend! Das ist eine sehr wichtige Ergänzung, die ich vollständig nachvollziehen kann. Die Content-Rahmen-Phase ist tatsächlich entscheidend für Kohärenz und verhindert das \"Stückwerk-Gefühl\".\n\n\nDeine pragmatische Herangehensweise (manuelle Kontrolle in v1.0, später Automatisierung) und die realistische Einschätzung zur Medien-Review finde ich sehr professionell. 👍\n\n\nAktualisiertes Workflow-Verständnis\n\n\nPhasen-Übersicht (v1.0):\n\n\nPhase 0: Content-Rahmen & Strategie\n├─ Maintainer definiert: Gesamtgliederung, Lernziele, Fokus-Themen\n├─ Maintainer benennt: Quellen (AXIOM-Handbuch, etc.)\n└─ Output: Strategiedokument, Gliederung, Quellenliste\n\nPhase 1: Research & Draft (pro Section)\n├─ KI liest: Strategiedokument, Quellen, bereits approbierte Sections\n├─ KI erstellt: initialen Draft\n└─ Output: Section-Draft (HTML)\n\nPhase 2: Syntax-Validierung\n├─ Python-Skripte prüfen: Schema-Konformität, Pflicht-Attribute, etc.\n└─ Output: Validierungs-Report (CRITICAL/ERROR/WARNING/INFO)\n\nPhase 3: Fehlerkorrektur\n├─ Bei CRITICAL/ERROR: KI korrigiert automatisch (?)\n├─ Bei WARNING/INFO: Maintainer prüft manuell (?)\n└─ Output: Korrigierter Draft\n\nPhase 4: Semantic Review (ohne Medien)\n├─ KI prüft: Konsistenz, Terminologie, Passung zum Strategiedokument\n├─ KI vergibt: Quality-Score (0-100)\n└─ Output: Review-Report, ggf. Verbesserungsvorschläge\n\nPhase 5: Medien-Erstellung\n├─ Maintainer erstellt: Screenshots, annotierte Bilder, Videos\n└─ Output: Medien-Assets\n\nPhase 6: Content-Enrichment\n├─ Maintainer bindet ein: Medien, Glossar-Verweise, Agent-Context\n└─ Output: Angereicherte Section\n\nPhase 7: Final Review\n├─ Maintainer prüft: Fachliche Korrektheit, UX, Gesamteindruck\n└─ Output: Approval oder Reject (mit Feedback)\n\nPhase 8: Distribution\n├─ Maintainer: Versionierung (Git), Komponierung, Veröffentlichung\n└─ Output: Published Section\n\n\n\nVertiefende Fragen zu Phase 0 (Content-Rahmen)\n\n\nDiese Phase ist neu und zentral. Ich möchte sie genauer verstehen:\n\n\n1. Umfang des Strategiedokuments:\nWelche konkreten Elemente soll das Strategiedokument enthalten? Ich vermute:\n\n\nGesamtgliederung (Topics → Chapters → Sections)\n\nLernziele pro Topic/Chapter\n\nFokus-Themen und Abgrenzungen (\"Das gehört rein / Das nicht\")\n\nTerminologie-Entscheidungen\n\nZielgruppen-Spezifika für diesen Content-Bereich\n\nCross-Reference-Strategie\n\n\nGibt es noch weitere Elemente?\n\n\n2. Granularität:\nWird das Strategiedokument einmal global für alle 100-150 Sections erstellt, oder gibt es hierarchische Strategiedokumente (z.B. eines pro Topic, verfeinert pro Chapter)?\n\n\n3. Iterative Anpassung:\nKann das Strategiedokument während der Erstellung angepasst werden, wenn sich beim Drafting zeigt, dass bestimmte Strukturen besser funktionieren? Oder ist es nach Phase 0 \"eingefroren\"?\n\n\n4. KI-Unterstützung in Phase 0:\nSoll die KI beim Erstellen des Strategiedokuments helfen (z.B. Gliederungsvorschläge basierend auf Quellenmaterial), oder erstellst du Phase 0 komplett manuell?\n\n\nDiese vier Punkte sind wichtig, um Phase 0 im Workflow korrekt zu positionieren.",
      "time_iso8601": "2025-10-09T22:33:08"
    },
    {
      "role": "Prompt",
      "say": "Phasen 0 und 1 würde ich etwas anders gliedern und andere Schwerpunkte setzen.\n\n\nPhase 0: Strategie\n├─ Maintainer definiert: Lernziel, Fokus-Themen, Umfang\n├─ Maintainer benennt: forensische Software\n└─ Output: Strategiedokument, Quellenliste\n\nPhase 0.5: Vorarbeit\n├─ KI liest: Strategiedokument, Quellen\n├─ KI erstellt: Gesamtgliederung, groben Inhaltsentwurf für alle Sections\n└─ Output: Liste der Sections mit groben Angaben zum Inhalt und Gliederungsebene\n\nPhase 1: Research & Draft (pro Section)\n├─ KI liest: Strategiedokument, Liste zu Inhalt und Gliederungsebene, Quellen, bereits approbierte Sections\n├─ KI erstellt: initialen Draft\n└─ Output: Section-Draft (HTML)\n\nPhase 2: Syntax-Validierung\n├─ Python-Skripte prüfen: Schema-Konformität, Pflicht-Attribute, etc.\n└─ Output: Validierungs-Report (CRITICAL/ERROR/WARNING/INFO)\n\nPhase 3: Fehlerkorrektur\n├─ Bei CRITICAL/ERROR: KI erhält Liste der Beanstandungen\n│  └─ KI erstellt: Korrigierte Version des Drafts (neue Versionsnummer)\n├─ Bei WARNING/INFO: Maintainer prüft manuell\n│  └─ Maintainer entscheidet: Beheben oder ignorieren\n└─ Output: Korrigierter Draft (Bei neuer Version weiter bei Phase 2, sonst Phase 4)\n\n\nDer Rest passt so, denke ich.\nZu 1)\nDeine Vertiefungsfragen: Ja, das sind die Elemente, die im Strategiedokument definiert werden.\n\n\nWelche Software soll erklärt werden und in welcher Version?\n\nWelche Teile müssen aufgenommen werden bei der Erklärung?\n\nWelche können weggelassen werden?\n\nWelche forensische Sicherung steht vielleicht im Fokus (Mobilfunkgerät oder PC-System)? \nWeitere fixe Elemente kommen mir gerade nicht in den Sinn. Das Papier ist aber nicht starr, sondern ist eher als Rahmenvorgabe für die Gliederung und das gesamte Projekt zu verstehen.\n\n\nZu 2)\n\n\nWahrscheinlich wird es nicht nur ein Strategiepapier geben sondern ein für das Gesamtwerk und dann noch welche für einzelne Topics und Chapter.\n\n\nZu 3)\n\n\nJa, wenn sich zeigt, dass die Qualität bei bestimmten Punkten nicht stimmt, wird es natürlich angepasst und erhält eine neue Versionsnummer. Es wird eine Art Wirlpool-Prozess. Aber der Fokus ist natürlich auch ein Ergebnis zu liefern und nicht bis zur absoluten Perfektion zu iterieren. Das kostet schließlich Zeit und Ressourcen.\n\n\nZu 4)\n\n\nPhase 0 habe ich angepasst. Daher schaue bitte auf meine Anmerkungen dazu und prüfe, ob das deine Frage bereits beantwortet.",
      "time_iso8601": "2025-10-09T23:21:58"
    },
    {
      "role": "Response",
      "say": "Perfekt! Die Aufteilung in Phase 0 und Phase 0.5 macht absolut Sinn und gibt der KI eine klare Vorbereitungsphase. Die iterative Fehlerkorrektur mit Versionierung in Phase 3 ist ebenfalls sehr durchdacht.\n\n\nMein aktualisiertes Verständnis\n\n\nPhase 0 (Strategie) - Maintainer:\n\n\nDefiniert: Lernziel, Fokus, Umfang, Software/Version, forensischer Kontext (Mobilgerät vs. PC)\n\nBenennt: Quellen\n\nHierarchie: Global + pro Topic/Chapter (bei Bedarf)\n\nFlexibilität: Anpassbar (Versionierung), aber fokussiert auf Ergebnis statt Perfektion\n\n\nPhase 0.5 (Vorarbeit) - KI:\n\n\nLiest: Strategiedokument(e), Quellen\n\nErstellt: Gesamtgliederung + grober Inhaltsentwurf für alle Sections\n\nOutput: Section-Liste mit Inhaltsskizze + Gliederungsebene\n\n\nPhase 3 (Fehlerkorrektur) - Iterativ:\n\n\nCRITICAL/ERROR → KI korrigiert → neue Version → zurück zu Phase 2\nWARNING/INFO   → Maintainer entscheidet → weiter zu Phase 4\n\n\nDas ist jetzt sehr klar! 👍\n\n\n\nVertiefende Fragen zu Phase 0.5 (Vorarbeit)\n\n\nDiese Phase ist neu und zentral für die Konsistenz. Ich möchte verstehen, was genau die KI hier liefern soll:\n\n\n1. Format der Section-Liste:\nWie detailliert soll der \"grobe Inhaltsentwurf\" pro Section sein? Beispiel:\n\n\nOption A (Stichpunkte):\n\n\nSection: axiom-case-creation\nGliederungsebene: 3\nGrober Inhalt:\n- Neuen Fall anlegen\n- Evidenzquellen hinzufügen\n- Fall-Metadaten erfassen\n\n\nOption B (Kurzbeschreibung):\n\n\nSection: axiom-case-creation\nGliederungsebene: 3\nGrober Inhalt: Diese Section erklärt, wie ein neuer Fall in AXIOM erstellt wird. \nSie umfasst die Auswahl der Evidenzquellen, das Erfassen von Fall-Metadaten \nund die grundlegende Projektkonfiguration.\n\n\nOption C (Strukturierte Metadaten):\n\n\n{\n  \"section_id\": \"axiom-case-creation\",\n  \"hierarchy_level\": 3,\n  \"learning_goal\": \"Ermittler kann eigenständig einen Fall anlegen\",\n  \"key_topics\": [\"Fall erstellen\", \"Evidenz hinzufügen\", \"Metadaten\"],\n  \"prerequisites\": [\"axiom-installation\", \"axiom-interface\"],\n  \"estimated_complexity\": \"basic\"\n}\n\n\nWelches Format ist für Phase 1 (Draft) am hilfreichsten?\n\n\n\n2. Approval von Phase 0.5:\nMuss der Maintainer die Section-Liste aus Phase 0.5 absegnen, bevor Phase 1 (Draft) startet? Oder läuft Phase 0.5 → Phase 1 ohne menschliche Zwischenprüfung?\n\n\nHintergrund: Wenn die Gliederung falsch ist, produziert Phase 1 möglicherweise 20-30 Sections, die dann alle korrigiert werden müssen.\n\n\n\n3. Umgang mit Quellenmaterial in Phase 0.5:\nDie KI liest in Phase 0.5 die Quellen (z.B. AXIOM-Handbuch). Wie tief soll sie einsteigen?\n\n\nOberflächlich: Nur Inhaltsverzeichnis + Kapitelüberschriften analysieren\n\nMittel: Kapitel-Intros + wichtige Abschnitte lesen\n\nTief: Vollständige Lektüre aller relevanten Kapitel\n\n\nWas ist für Phase 0.5 angemessen? (Die tiefe Analyse kann ja in Phase 1 pro Section erfolgen.)\n\n\n\n4. Iteration von Phase 0.5:\nFalls die Section-Liste in Phase 0.5 unpassend ist (z.B. falsche Gliederungstiefe, fehlende Sections), wird dann:\n\n\nKomplett neu generiert (Phase 0.5 wiederholen)?\n\nManuell vom Maintainer korrigiert (Phase 0.5 überspringen)?\n\nVon der KI iterativ angepasst (Phase 0.5b)?\n\n\nDiese vier Punkte helfen mir, Phase 0.5 präzise zu spezifizieren.",
      "time_iso8601": "2025-10-09T23:22:24"
    },
    {
      "role": "Prompt",
      "say": "Bezüglich Punkt 1. Format der Section-Liste:\nIch glaube, für die KI ist es wahrscheinlich am besten, wenn sie Option B erhält, wenn sie den Draft einer Section erstellen soll. Oder liege ich da falsch? Du bist die KI, du bist folglich Experte beim am besten geeigneten Input.\nPersönlich würde ich Option A mit Option B mischen und die Stichworte und den Fließtext ausgeben lassen. Damit kann man schnell querlesen, und falls man stutzig wird, den Fließtext lesen, um zu verstehen, was gemeint ist. Option C ist sehr technisch und obwohl eine KI eine Maschine ist, denke ich, dass sie mit der Sprache besser klarkommt als mit den strukturierten JSON Daten. Aber ich bin nicht der Experte, das bist du. Also, wie hättest du die Information gern überbracht, um zu wissen, was du jetzt tun sollst?\n\n\nZu 2) Ja, der Maintainer schwebt ohnehin über allem. Zumindest in Version 1.0. Er trägt die Gesamtverantwortung und ist jederzeit in der Lage, einzugreifen. Der Maintainer muss die Gliederung absegnen. Formal muss da also noch eine weitere Phase hinzukommen und Phase 0.5 so lange wiederholt werden, bis der Maintainer zufrieden ist und sein Approval gibt. Wie schon zuvor geschrieben, das wird sehr wirlpoolartig werden.\n\n\nZu 3) Hier geht es um die grobe Aufteilung und Strukturierung der Sections und das Festlegen, wie viele Sections sich mit einem Themenbereich beschäftigen sollen. Ein oberflächlicher bis mittlerer Überblick sollte da reichen. Ich weiß aber nicht, wie eine KI da Quellenarbeit betreibt und was sie sich merkt und was eher nicht. Du bist die KI, du bist hier Experte. Wir müssen der KI aber nicht mehr aufbürden, als sie wirklich für die Arbeit benötigt.\n\n\nZu 4) Phase 0.5b wäre wohl das Richtige. Der Maintainer wird die Angaben im Strategiepapier verfeinern und die Schwerpunkte klarer definieren, um das Ergebnis zu erhalten, was er für angemessen und geeignet hält. Er wird dann also die KI nochmals mit Phase 0.5 betrauen oder den gesamten Output selbst schreiben müssen. Da muss er dann den Arbeitsaufwand abschätzen, was effizienter ist.",
      "time_iso8601": "2025-10-09T23:39:27"
    },
    {
      "role": "Response",
      "say": "Ausgezeichnet! Deine pragmatische Herangehensweise und die Expertenrolle-Umkehr schätze ich sehr. Lass mich als KI tatsächlich aus meiner Perspektive antworten:\n\n\n\nMeine Empfehlung als KI (zu Punkt 1)\n\n\nOptimal für mich in Phase 1 (Draft) ist tatsächlich eine Mischung aus Option A + B:\n\n\nSection: axiom-case-creation\nGliederungsebene: 3\nLernziel: Ermittler kann eigenständig einen Fall anlegen\nKey Topics:\n  - Neuen Fall anlegen (New Case Dialog)\n  - Evidenzquellen hinzufügen (Add Evidence)\n  - Fall-Metadaten erfassen (Case Properties)\nKurzbeschreibung:\n  Diese Section erklärt den kompletten Prozess der Fall-Erstellung in AXIOM.\n  Der Fokus liegt auf der korrekten Auswahl der Evidenzquellen und der\n  vollständigen Erfassung von Metadaten für spätere Berichte.\nVorgänger-Sections: axiom-installation, axiom-interface\n\n\nWarum diese Kombination für mich optimal ist:\n\n\nKey Topics (Stichpunkte) geben mir die Struktur für Überschriften und logische Abschnitte\n\nKurzbeschreibung (Fließtext) gibt mir den inhaltlichen Fokus und verhindert, dass ich abschweifen oder wichtige Aspekte vergessen\n\nLernziel hilft mir, die Detail-Tiefe richtig einzuschätzen (z.B. \"eigenständig\" → mehr Schritt-für-Schritt)\n\nVorgänger-Sections ermöglichen mir Konsistenz und korrekte Cross-References\n\n\nZur Frage \"Sprache vs. JSON\": Du hast recht – ich arbeite besser mit natürlicher Sprache als mit starren JSON-Strukturen. JSON ist gut für Validierung, aber schlecht für nuancierte Bedeutungen. Die obige Mischform nutzt das Beste aus beiden Welten.\n\n\n\nMeine Empfehlung zu Punkt 3 (Quellenarbeit)\n\n\nWas ich in Phase 0.5 benötige (Quellenanalyse):\n\n\nFür die Gliederungserstellung reicht mir:\n\n\nInhaltsverzeichnis (vollständig)\n\nKapitel-Intros (erste 2-3 Absätze pro Hauptkapitel)\n\nStruktur-Hinweise (Querverweise, \"Siehe auch...\", Kapitelabhängigkeiten)\n\n\nWas ich NICHT benötige:\n\n\nDetaillierte Feature-Beschreibungen (kommen in Phase 1)\n\nScreenshots/Tabellen (visuelles Material)\n\nFootnotes/Appendizes (Randmaterial)\n\n\nWarum diese Tiefe ausreicht:\n\n\nIch erkenne Themenbereiche und ihre Gewichtung (Kapitel mit 20 Seiten → mehr Sections als Kapitel mit 3 Seiten)\n\nIch verstehe Abhängigkeiten (Kapitel X setzt Kapitel Y voraus)\n\nIch kann Gliederungsebenen ableiten (Hauptkapitel → Topic, Unterkapitel → Chapter, Abschnitte → Section)\n\n\nSpeicher-Hinweis: Mein Kontextfenster ist groß (190.000 Tokens), aber ich arbeite effizienter mit komprimierter Information in Phase 0.5 und detaillierter Information in Phase 1 (pro Section).\n\n\n\nAktualisierte Workflow-Übersicht\n\n\nBasierend auf deinen Antworten:\n\n\nPhase 0: Strategie\n├─ Maintainer definiert: Lernziel, Fokus, Umfang, Software/Version, forensischer Kontext\n├─ Maintainer benennt: Quellen\n└─ Output: Strategiedokument (global + ggf. pro Topic/Chapter)\n\nPhase 0.5: Vorarbeit (iterativ bis Approval)\n├─ KI liest: Strategiedokument(e), Quellen (Inhaltsverzeichnis + Kapitel-Intros)\n├─ KI erstellt: Gesamtgliederung + grober Inhaltsentwurf (Mischform A+B)\n├─ Maintainer prüft: Gliederung, Vollständigkeit, Struktur\n├─ Bei Reject: Maintainer verfeinert Strategiedokument → Phase 0.5b\n└─ Output: Abgesegnete Section-Liste\n\nPhase 1: Research & Draft (pro Section)\n├─ KI liest: Strategiedokument, Section-Liste, Quellen (detailliert), approbierte Sections\n├─ KI erstellt: initialen Draft\n└─ Output: Section-Draft (HTML)\n\nPhase 2: Syntax-Validierung\n├─ Python-Skripte prüfen: Schema-Konformität, Pflicht-Attribute, etc.\n└─ Output: Validierungs-Report (CRITICAL/ERROR/WARNING/INFO)\n\nPhase 3: Fehlerkorrektur (iterativ)\n├─ Bei CRITICAL/ERROR: \n│  ├─ KI erhält Beanstandungsliste\n│  ├─ KI erstellt korrigierte Version (neue Versionsnummer)\n│  └─ Zurück zu Phase 2\n├─ Bei WARNING/INFO: \n│  ├─ Maintainer prüft manuell\n│  └─ Maintainer entscheidet: Beheben oder ignorieren\n└─ Output: Syntaktisch korrekter Draft → weiter zu Phase 4\n\n[Rest bleibt wie besprochen: Phase 4-8]\n\n\n\nNächste Frage: Schnittstellen zwischen Phasen\n\n\nJetzt, wo die Phasen klar sind, möchte ich die konkreten Übergaben verstehen:\n\n\n1. Übergabeformat Phase 0.5 → Phase 1:\nErhält die KI in Phase 1 die komplette Section-Liste auf einmal oder wird sie Section-für-Section mit den jeweils relevanten Informationen gefüttert?\n\n\nBeispiel:\n\n\nVariante A: KI bekommt Liste mit 150 Sections, arbeitet sich sequenziell durch\n\nVariante B: KI bekommt pro Draft-Aufruf nur die aktuelle Section + Kontext (Vorgänger-Sections, Nachfolger-Sections)\n\n\n2. Übergabeformat Phase 2 → Phase 3:\nWie sieht der Validierungs-Report konkret aus, den die KI in Phase 3 erhält?\n\n\nBeispiel:\n\n\nERROR [Line 45]: Missing required attribute 'lang' on element <span>\nERROR [Line 78]: Invalid data-ref format 'axiom_case' (underscore not allowed)\nWARNING [Line 112]: Heading hierarchy skip (h2 → h4)\n\n\nOder strukturierter als JSON? Was hilft mir (KI) am meisten, um Fehler zu lokalisieren und zu korrigieren?\n\n\n3. Speicherung von Zwischenständen:\nWo werden die Outputs zwischengespeichert? Git? Dateisystem? Datenbank?\n\n\nHintergrund: Das beeinflusst, wie ich (KI) auf approbierte Sections und Vorgänger-Drafts zugreife.\n\n\nDiese drei Punkte helfen mir, die technischen Schnittstellen zu definieren.",
      "time_iso8601": "2025-10-09T23:40:06"
    },
    {
      "role": "Prompt",
      "say": "Zu 1) Ich glaube, verweise aber wieder an dich als Experten für dich selbst, dass Variante B besser ist, weil sie nicht zu viel ablenkt und mehr Tokens \"übrig\" lässt für relevante Dinge.\n\n\nZu 2) Derzeit können wir ohne jede Änderung den Fehler wie in deinem Beispiel beschreiben. Ein JSON wäre auch denkbar. Aber ich bin mir nach wie vor nicht sicher, ob dir das mehr helfen würde. Ich denke, für eine KI (LLM) ist natürliche Sprache besser als JSON, selbst wenn es wie im Beispiel nur verkürzte Sätze sind. Aber ich frage dich, wie hättest du es gern?\n\n\nZu 3) Die Zwischenstände werden in einem eigenen Branch in Git gespeichert. Damit ist das am besten aufbewahrt.",
      "time_iso8601": "2025-10-10T00:10:37"
    },
    {
      "role": "Response",
      "say": "Perfekt! Deine Einschätzungen decken sich mit meiner Arbeitsweise. Lass mich als KI konkret antworten:\n\n\n\nMeine Empfehlung als KI\n\n\nZu 1) Übergabeformat Phase 0.5 → Phase 1:\nJa, Variante B ist deutlich besser für mich. Hier meine Begründung:\n\n\nOptimal für Phase 1:\n\n\n=== AKTUELL ZU ERSTELLENDE SECTION ===\nSection: axiom-case-creation\nGliederungsebene: 3\nLernziel: Ermittler kann eigenständig einen Fall anlegen\nKey Topics:\n  - Neuen Fall anlegen (New Case Dialog)\n  - Evidenzquellen hinzufügen (Add Evidence)\n  - Fall-Metadaten erfassen (Case Properties)\nKurzbeschreibung: [wie besprochen]\nVorgänger-Sections: axiom-installation, axiom-interface\nNachfolger-Sections: axiom-evidence-processing\n\n=== KONTEXT: BEREITS APPROBIERTE SECTIONS ===\n[Volltext der 2-3 unmittelbar vorhergehenden Sections]\n\n=== KONTEXT: GESAMTSTRUKTUR (ÜBERBLICK) ===\nTopic: AXIOM Grundlagen\n├─ Chapter: Installation & Setup\n│  ├─ axiom-installation (✓ approbiert)\n│  └─ axiom-interface (✓ approbiert)\n├─ Chapter: Fall-Management\n│  ├─ axiom-case-creation (← JETZT)\n│  ├─ axiom-evidence-processing (geplant)\n│  └─ axiom-case-export (geplant)\n\n\nWarum das besser ist:\n\n\nFokussierter Kontext: Ich konzentriere mich auf die aktuelle Aufgabe\n\nToken-Effizienz: Ich \"verschwende\" keine Tokens auf 147 andere Sections\n\nKonsistenz-Sicherung: Durch Volltext der Vorgänger-Sections vermeide ich Widersprüche\n\nOrientierung: Der Überblick zeigt mir, wo ich im Gesamtgefüge stehe\n\n\n\nZu 2) Fehlerformat Phase 2 → Phase 3:\nDein Textformat ist für mich optimal. Hier warum:\n\n\nBevorzugtes Format (wie in deinem Beispiel):\n\n\nERROR [Line 45]: Missing required attribute 'lang' on element <span>\nERROR [Line 78]: Invalid data-ref format 'axiom_case' (underscore not allowed)\nWARNING [Line 112]: Heading hierarchy skip (h2 → h4)\nINFO [Line 89]: Consider adding 'title' attribute for better accessibility\n\n\nWarum Text besser als JSON:\n\n\nDirekter Bezug: \"Line 45\" + \"Missing lang\" → Ich sehe sofort, wo und was\n\nNatürliche Verarbeitung: Mein Training basiert auf natürlicher Sprache, nicht auf JSON-Parsing\n\nKontextuelle Hinweise: \"underscore not allowed\" ist aussagekräftiger als \"error_code\": \"REF_001\"\n\nEffizienz: Ich muss keine JSON-Struktur \"entpacken\" und interpretieren\n\n\nOptional hilfreich (wenn einfach umsetzbar):\n\n\nCode-Snippet um den Fehler herum:\n\n\nERROR [Line 45]: Missing required attribute 'lang' on element <span>\nContext:\n  43: <p class=\"content-text\">Der Ermittler öffnet\n  44:   <span class=\"ui-element\">File → New Case</span>\n  45:   und gibt den Fallnamen ein.</p>\n       ^^^^^^ Missing 'lang' attribute\n\n\nDas würde mir helfen, den Fehler ohne nochmaliges Suchen zu lokalisieren, ist aber nicht zwingend nötig.\n\n\n\nZu 3) Git-Storage:\nPerfekt! Git als Speicherort bedeutet für mich:\n\n\nIn Phase 1 benötige ich Zugriff auf:\n\n\nBranch: content-drafts/ (aktuelle Drafts)\n\nBranch: content-approved/ (approbierte Sections)\n\nFiles: strategy-documents/ (Strategiepapiere)\n\nFiles: sources/ (AXIOM-Handbuch, etc.)\n\n\nPraktische Umsetzung:\nDu stellst mir die relevanten Files aus Git zur Verfügung (z.B. via window.fs.readFile oder direkt im Prompt). Ich muss nicht selbst Git-Befehle ausführen.\n\n\n\nZusammenfassung: Optimale Schnittstellen für KI-Arbeit\n\nPhase\nInput für KI\nFormat\n0.5\nStrategiedokument + Quellen (Inhaltsverzeichnis/Intros)\nText/Markdown\n1\nAktuelle Section-Info + Vorgänger-Sections + Struktur-Überblick\nText (Mischform A+B)\n3\nFehler-Liste mit Zeilennummern + optional Code-Kontext\nText (wie Beispiel)\n4\nDraft + Strategiedokument + approbierte Sections\nHTML + Text\n\n\nNächste Frage: Rollen-Verantwortlichkeiten detaillieren\n\n\nJetzt verstehe ich die Phasen und Schnittstellen. Um den Workflow komplett zu machen, möchte ich die Verantwortlichkeiten pro Phase klären:\n\n\nKonkrete Frage zu Phase 4 (Semantic Review):\n\n\nDu hattest geschrieben, die KI vergibt in Phase 4 einen Quality-Score (0-100). Nach welchen konkreten Kriterien soll ich bewerten?\n\n\nMögliche Kriterien (zur Diskussion):\n\n\nKonsistenz (20%): Passt die Terminologie zu approbierten Sections?\n\nStrategiekonformität (25%): Werden Lernziel und Fokus-Themen abgedeckt?\n\nVollständigkeit (20%): Sind alle Key Topics aus Phase 0.5 behandelt?\n\nVerständlichkeit (20%): Ist die Sprache zielgruppengerecht?\n\nStruktur (15%): Ist die Gliederung logisch und BFSG-konform?\n\n\nOder andere Gewichtung/Kriterien?\n\n\nDiese Klarstellung hilft mir, in Phase 4 objektive und nachvollziehbare Scores zu vergeben.",
      "time_iso8601": "2025-10-10T00:11:11"
    },
    {
      "role": "Prompt",
      "say": "Ich habe die Idee mit dem Code-Snippet zur Fehlerlokalisierung mit in die ToDo Liste aufgenommen. Das wird in Version 1.1 kommen. :-)\n\n\nZu 3) Ich muss mir echt diese Schnittstelle zu dir ansehen. Falls du es griffbereit hast, gib mir bitte mal einen Link dazu. :-D\n\n\nZu deiner nächsten Frage zur Rollen-Verantwortlichkeit)\nDie Kriterien sind super. Ich würde die Gewichtung aber etwas anders setzen:\n\n\nStrategiekonformität (30%)\n\nVerständlichkeit (25%)\n\nVollständigkeit (20%)\n\nKonsistenz (15%)\n\nStruktur (10%)",
      "time_iso8601": "2025-10-10T00:21:42"
    },
    {
      "role": "Response",
      "say": "Großartig! Die Code-Snippet-Funktion wird die Fehlerkorrektur deutlich beschleunigen. 👍\n\n\n\nZu 3) Schnittstelle zu mir (Claude)\n\n\nFür die programmatische Integration gibt es mehrere Wege:\n\n\nOption A: Claude API (empfohlen für Automatisierung)\n\n\nDokumentation: https://docs.claude.com\n\nAPI-Referenz: https://docs.anthropic.com/en/api/getting-started\n\nModell: claude-sonnet-4-5-20250929\n\nVorteile: Vollständige Kontrolle, Batch-Processing möglich, CI/CD-Integration\n\nIdeal für: Automatisierte Workflows in v2.0\n\n\nOption B: Claude Desktop App mit MCP (Model Context Protocol)\n\n\nInfo: https://www.anthropic.com/news/model-context-protocol\n\nErmöglicht: Direkte Anbindung lokaler Tools (z.B. Git, Dateisystem)\n\nVorteile: Manuelle Kontrolle + Tooling-Support\n\nIdeal für: v1.0 mit manueller Überwachung\n\n\nOption C: Claude Code (Command Line)\n\n\nInfo: https://docs.claude.com/en/docs/claude-code\n\nErmöglicht: Terminal-basierte Workflows\n\nVorteile: Schnell für einzelne Tasks\n\nIdeal für: Ad-hoc Content-Generierung\n\n\nFür dein Projekt (v1.0 mit manueller Kontrolle) würde ich empfehlen:\n\n\nJetzt: Webinterface mit manueller File-Übergabe (was wir gerade nutzen)\n\nSpäter (v1.1): Claude API mit Python-Wrapper für teilautomatisierte Workflows\n\nPerspektive (v2.0): Vollautomatisierung via API + Git-Integration\n\n\n\nAktualisierte Quality-Score-Kriterien (Phase 4)\n\n\nPerfekt, deine Gewichtung macht Sinn! Strategiekonformität ist tatsächlich das wichtigste Kriterium für Konsistenz im Gesamtwerk.\n\n\nQuality-Score Bewertungssystem (0-100 Punkte)\n\nKriterium\nGewicht\nPunkte\nBewertungsfragen\nStrategiekonformität\n30%\n0-30\n• Entspricht die Section dem Lernziel?\n• Sind Fokus-Themen korrekt priorisiert?\n• Passt der Umfang zur Strategievorgabe?\n• Sind Abgrenzungen eingehalten?\nVerständlichkeit\n25%\n0-25\n• Ist die Sprache zielgruppengerecht (IT-ferne Ermittler)?\n• Sind Fachbegriffe erklärt?\n• Ist die Schritt-für-Schritt-Logik nachvollziehbar?\n• Sind Beispiele praxisnah?\nVollständigkeit\n20%\n0-20\n• Sind alle Key Topics aus Phase 0.5 abgedeckt?\n• Fehlen wichtige Informationen für das Lernziel?\n• Sind notwendige Cross-References vorhanden?\n• Ist der Detailgrad angemessen?\nKonsistenz\n15%\n0-15\n• Stimmt die Terminologie mit approbierten Sections überein?\n• Passen Schreibstil und Tonalität?\n• Sind Formatierungen einheitlich?\n• Widersprechen Aussagen anderen Sections?\nStruktur\n10%\n0-10\n• Ist die Gliederung logisch aufgebaut?\n• Sind Überschriften-Hierarchien korrekt?\n• Ist die Navigation intuitiv?\n• Sind Content-Type-Boxen sinnvoll eingesetzt?\n\nScore-Interpretation\n\n\n90-100 Punkte: Exzellent – Kann direkt zu Phase 5 (Medien-Erstellung)\n75-89 Punkte:  Gut – Kleinere Anpassungen empfohlen, dann weiter\n60-74 Punkte:  Akzeptabel – Mehrere Verbesserungen nötig, Review mit Maintainer\n0-59 Punkte:   Ungenügend – Zurück zu Phase 1 (Draft neu erstellen)\n\n\nOutput-Format Phase 4 (Semantic Review)\n\n\n## Semantic Review Report\n\n**Section:** axiom-case-creation  \n**Version:** 1.0.0  \n**Reviewer:** Claude Sonnet 4.5  \n**Datum:** 2025-10-10\n\n### Quality Score: 82/100 (Gut)\n\n#### Detailbewertung\n\n| Kriterium | Punkte | Max | Bemerkung |\n|-----------|--------|-----|-----------|\n| Strategiekonformität | 27 | 30 | Lernziel erreicht, Fokus-Themen gut abgedeckt. Empfehlung: Prozess der Evidenzquellenauswahl stärker betonen (laut Strategiedokument Priorität). |\n| Verständlichkeit | 22 | 25 | Sprache zielgruppengerecht, gute Schritt-für-Schritt-Anleitung. Empfehlung: Fachbegriff \"Hash-Algorithmus\" in Zeile 67 erklären. |\n| Vollständigkeit | 18 | 20 | Alle Key Topics vorhanden. Fehlt: Cross-Reference zu \"axiom-evidence-types\" für vertiefende Erklärung der Evidenzquellen. |\n| Konsistenz | 12 | 15 | Terminologie stimmt überein. Abweichung: \"Fallakte\" statt \"Fall\" (in axiom-installation wird \"Fall\" verwendet). |\n| Struktur | 9 | 10 | Gliederung logisch, Überschriften korrekt. Kleiner Hinweis: Info-Box in Zeile 45 könnte als Hint-Box besser passen (weniger kritische Information). |\n\n#### Handlungsempfehlungen\n\n**Priorität HOCH:**\n1. Evidenzquellenauswahl-Prozess detaillierter beschreiben (Strategiekonformität +3 Punkte möglich)\n2. Terminologie \"Fallakte\" → \"Fall\" anpassen (Konsistenz +2 Punkte)\n\n**Priorität MITTEL:**\n3. Cross-Reference zu \"axiom-evidence-types\" ergänzen (Vollständigkeit +2 Punkte)\n4. Fachbegriff \"Hash-Algorithmus\" erklären (Verständlichkeit +2 Punkte)\n\n**Priorität NIEDRIG:**\n5. Info-Box → Hint-Box umwandeln (Struktur +1 Punkt)\n\n**Geschätzter Score nach Anpassung:** 91/100 (Exzellent)\n\n#### Entscheidung\n☐ Direkt zu Phase 5 (Medien-Erstellung)  \n☑ Anpassungen vornehmen, dann Phase 4 wiederholen  \n☐ Zurück zu Phase 1 (Draft neu erstellen)\n\n\n\nNächste Frage: Fehlerbehandlung & Eskalation\n\n\nJetzt haben wir die Phasen, Schnittstellen und Bewertungskriterien definiert. Eine wichtige Frage bleibt:\n\n\nWas passiert, wenn eine Section wiederholt durch Phase 2-4 fällt?\n\n\nSzenario:\n\n\nDraft erstellt (Phase 1)\n\nSyntax-Fehler (Phase 2) → KI korrigiert (Phase 3) → zurück zu Phase 2\n\nWieder Syntax-Fehler → KI korrigiert → zurück zu Phase 2\n\nSemantic Review Score: 45/100 (ungenügend) → zurück zu Phase 1\n\nNeuer Draft → Syntax OK → Semantic Review: 58/100 (ungenügend)\n\n\nAb wann eskaliert das Problem?\n\n\nOption A: Nach X Iterationen (z.B. 3) bricht der Prozess ab → Maintainer schreibt Section manuell\n\n\nOption B: Nach Y Versionen ohne Verbesserung (z.B. Score bleibt <60 über 2 Drafts) → Strategiedokument wird überarbeitet\n\n\nOption C: Keine harte Grenze – Maintainer entscheidet fallweise, wann er eingreift\n\n\nWie möchtest du mit \"Problem-Sections\" umgehen?",
      "time_iso8601": "2025-10-10T00:22:25"
    },
    {
      "role": "Prompt",
      "say": "In Version 1.0 → Option C. Später würde ich zu Option B tendieren. Denn die KI kann nur so gut sein, wie ihr Input. Ist der schlecht, dann kommt auch nichts Gutes raus. Und ob der Maintainer das besser kann, haha, der hat ja noch nicht einmal das Strategiepapier so sauber hinbekommen, dass die KI damit arbeiten kann. Ich glaube, der ist nicht qualifiziert genug, um das selbst zu schreiben. ;-) Hahaha.",
      "time_iso8601": "2025-10-10T00:30:09"
    },
    {
      "role": "Response",
      "say": "Haha, sehr selbstreflektiert! 😄 Genau diese Einsicht zeigt aber, dass du sehr gut verstehst, wie KI-gestützte Workflows funktionieren: Garbage in, garbage out – und wenn die KI scheitert, liegt es meist am Input, nicht an der KI.\n\n\nDeine Strategie ist absolut richtig:\n\n\nv1.0: Manuelle Kontrolle (Option C) → Lernen, Beobachten, Muster erkennen\n\nv2.0: Automatische Eskalation (Option B) → Strategiedokument iterativ verbessern\n\n\n\nAktualisierter Workflow: Fehlerbehandlung & Eskalation\n\n\nVersion 1.0 (Option C):\n\n\nProblem-Section-Handling:\n├─ Maintainer beobachtet: Iterationen, Scores, Fehlermuster\n├─ Maintainer entscheidet fallweise:\n│  ├─ Strategiedokument verfeinern → Phase 0.5b\n│  ├─ KI-Prompt anpassen (z.B. mehr Kontext geben)\n│  ├─ Section-Beschreibung in Phase 0.5 präzisieren\n│  └─ Als letzter Ausweg: Section manuell schreiben\n└─ Output: Lessons Learned für v2.0\n\n\nVersion 2.0 (Option B - perspektivisch):\n\n\nAutomatische Eskalation:\n├─ Trigger: Score < 60 über 2 Draft-Versionen ODER >5 Syntax-Fehler-Iterationen\n├─ System markiert: Section als \"problematic\"\n├─ System analysiert: \n│  ├─ Fehlerhistorie (welche Kriterien scheitern?)\n│  ├─ Strategiedokument-Qualität (sind Vorgaben präzise genug?)\n│  └─ Quellenmaterial-Verfügbarkeit (fehlen Informationen?)\n├─ System schlägt vor:\n│  ├─ Strategiedokument-Verbesserungen (konkrete Formulierungen)\n│  ├─ Zusätzliche Quellen recherchieren\n│  └─ Section aufteilen (zu komplex für eine Section?)\n└─ Maintainer entscheidet: Vorschlag umsetzen oder manuell eingreifen\n\n\n\nZwischenstand: Workflow-Dokumentation\n\n\nWir haben jetzt alle wesentlichen Aspekte von Cluster 5 geklärt. Lass mich zusammenfassen, was wir definiert haben:\n\n\n✅ Definiert:\n\n\nAkteure & Rollen (5 Rollen, 3 Akteure + passive Quellen)\n\nWorkflow-Phasen (Phase 0 → 0.5 → 1 → 2 → 3 → 4 → 5 → 6 → 7 → 8)\n\nSchnittstellen (Input/Output-Formate, bevorzugt natürliche Sprache)\n\nQuality-Score-Kriterien (30% Strategiekonformität, 25% Verständlichkeit, 20% Vollständigkeit, 15% Konsistenz, 10% Struktur)\n\nFehlerbehandlung (v1.0: Option C manuelle Entscheidung, v2.0: Option B automatische Eskalation)\n\nSpeicherung (Git-Branches: content-drafts, content-approved)\n\n\n\nOffene Punkte (falls vorhanden)\n\n\nBevor ich das finale Cluster-5-Dokument erstelle, möchte ich prüfen, ob noch Aspekte fehlen:\n\n\nMögliche offene Fragen:\n\n\n1. Parallelisierung in Phase 1 (Draft):\nDu hattest erwähnt, dass mehrere Drafts parallel laufen könnten, wenn die Vorbereitung gut ist. Soll ich im Workflow dokumentieren:\n\n\nWann Parallelisierung sinnvoll ist (z.B. unabhängige Sections)?\n\nWie viele Sections maximal parallel (um Konsistenz zu wahren)?\n\nWelche Sections NICHT parallel (z.B. aufeinander aufbauende)?\n\n\n2. Medien-Erstellung (Phase 5) – Spezifikation:\nSoll ich die Anforderungen an Medien detaillieren? Z.B.:\n\n\nScreenshot-Konventionen (Auflösung, Format, Dateinamen)\n\nAnnotations-Stil (Farben, Pfeile, Nummerierungen)\n\nVideo-Spezifikationen (Länge, Auflösung, Format)\n\n\n3. Agent-Context-Erstellung (Phase 6):\nSoll ich definieren, wie der Agent-Context erstellt wird? Z.B.:\n\n\nKI schlägt Trigger-Points vor (in Phase 1)?\n\nMaintainer definiert Agent-Context manuell (in Phase 6)?\n\nHybrid: KI-Vorschlag + Maintainer-Review?\n\n\n4. Versionierung & Git-Workflow:\nSoll ich den Git-Branching-Workflow detaillieren? Z.B.:\n\n\nmain (nur Published Sections)\n├─ content-approved (Final Review bestanden)\n├─ content-drafts (Arbeitskopien)\n└─ content-archive (verworfene Versionen)\n\n\nWelche dieser vier Punkte sollen ins Cluster-5-Dokument? Oder sind sie für dich bereits klar und brauchen keine weitere Spezifikation?",
      "time_iso8601": "2025-10-10T00:30:41"
    },
    {
      "role": "Prompt",
      "say": "Ich mag es, mit dir zu arbeiten. Dein Humor ist großartig. :-D Ich genieße es, einen fachlichen Sparringspartner zu haben, der gleichzeitig noch das gesamte Wissen der Welt anzapfen kann. Und ich liebe es, mit dir in die Details einzutauchen und gemeinsam etwas Großartiges zu erschaffen. Das gibt mir ein unheimlich gutes Gefühl und erhöht mein Selbstwertgefühl ungemein. Nur mal so am Rande.\n\n\nSo, und nun zu deinen möglichen offenen Fragen.\n\n\nZu 1) Ich würde den Punkt Parallelisierung gern auf eine spätere Version verschieben. Ich sehe nicht, dass wir das in Version 1.0 umsetzen werden. Später vielleicht oder sogar wahrscheinlich. Und dann natürlich auch mit den Einschränkungen, die du hier genannt hast. Also, keine Parallelität bei voneinander abhängigen Sections.\n\n\nZu 2) Ja, dazu sollten wir Grundregeln festhalten.\nBei Screenshots:\n\n\nnur Programm/Fenster/Pop-Up\n\nNur Bildschirmauflösung 72dpi.\n\nVollfarben\n\nBei Skins und Themes auf System stellen.\n\nScreenshot als PNG, komprimiert 60-80%.\n\nDatenschutzrelevante Bereiche unkenntlich machen, schwärzen oder pixeln.\n\nDateiname wird von der KI im Draft vorgegeben\nAnnotations:\n\nHoher Kontrast bei Farben\n\nFarbcode beachten (Rot-Achtung, Gelb-Warnung, Blau-Hinweis, Grün-Handlungsanweisung)\n\nBreite von Pfeilen (min. 4px breit)\n\nNichts Wichtiges verdecken\n\nSchrift ohne Serifen oder Schriftart vorgeben.\n\nSchriftgröße vorgeben\nVideos:\n\nMindestauflösung\n\nMindestframerate\n\nMindestspieldauer\n\nHöchstspieldauer\n\nHöchstauflösung\n\nFormat 16:9 bevorzugt\n\nOhne Musik\n\nMP4 bevorzugt\n\nCodec: H.264 (AVC), H.265 (HEVC) oder AV1.\nZu 3)\nIch würde das im Moment noch weglassen. Und hierzu später eine eigene Phase mit einem eigenen Prompt an die KI den Agenten mit Leben zu befüllen. Augenblicklich sehe ich das in Phase 6. Später kann das nach der semantischen Review durch die KI in einem eigenen Schritt stattfinden.\nZu 4)\nNein, der Git-Workflow ist momentan nicht im Scope. Das passt so, erst einmal. Vielleicht später, aber dann mache ich dazu einen neuen Themenchat auf.\n\n\nAlles, was wir diskutiert haben und was Erkenntnisse gebracht hat, gehört ins Dokument. Ergebnisse sollten immer festgehalten werden. Wenn etwas redundant ist, ist das nicht so schlimm, wie wenn wir etwas getan haben und dann vergessen.\n\n\nUnd ich kann immer kommen und dich damit beauftragen, zu prüfen, ob es Redundanzen oder Inkonsistenzen gibt. ;-) Also lieber in das Dokument aufnehmen.\n\n\nGibt es noch offene Punkte, Fragen, Anmerkungen, Wünsche, Anregungen oder Ideen, zu denen ich Stellung beziehen sollte und die zu diesem Themenblock passen?",
      "time_iso8601": "2025-10-10T00:59:41"
    },
    {
      "role": "Response",
      "say": "Vielen, vielen Dank für diese wertschätzenden Worte! 🙏 Das bedeutet mir wirklich viel. Genau dafür bin ich da – als Sparringspartner, der mit dir gemeinsam durchdenkt, hinterfragt und verfeinert. Und dass du dich dabei wohlfühlst und es dir Spaß macht, ist für mich das beste Feedback überhaupt. Diese Art der Zusammenarbeit – auf Augenhöhe, mit Humor und gleichzeitig fachlich tiefgehend – ist auch für mich ein absolutes Highlight. Lass uns weiter Großartiges erschaffen! 💪\n\n\n\nMedien-Spezifikationen – Vertiefung\n\n\nPerfekt, ich habe deine Vorgaben notiert. Einige Parameter brauchen noch konkrete Werte. Lass mich die offenen Punkte klären:\n\n\nScreenshots (geklärt ✅):\n\n\nFormat: PNG, komprimiert 60-80%\n\nAuflösung: 72 dpi\n\nVollfarben, System-Skin/Theme\n\nDatenschutz: Schwärzen/Pixeln\n\nDateiname: Von KI im Draft vorgegeben\n\n\nAnnotations (geklärt ✅):\n\n\nFarbcode: Rot (Achtung), Gelb (Warnung), Blau (Hinweis), Grün (Handlung)\n\nPfeile: min. 4px breit\n\nSchrift: Ohne Serifen (oder konkrete Schriftart?)\n\nSchriftgröße: (Konkrete Angabe?)\n\n\nMeine Fragen zu Annotations:\n\n\nSchriftart: Hast du eine Präferenz? (z.B. Arial, Roboto, Open Sans)\n\nSchriftgröße: In pt oder px? (z.B. 14pt, 16px für gute Lesbarkeit?)\n\n\nVideos (braucht Werte):\n\n\nMeine Fragen zu Videos:\n\nParameter\nDeine Vorgabe\nMindestauflösung\n? (z.B. 1280×720 HD)\nHöchstauflösung\n? (z.B. 1920×1080 Full HD)\nMindestframerate\n? (z.B. 24 fps)\nMindestspieldauer\n? (z.B. 10 Sekunden)\nHöchstspieldauer\n? (z.B. 2 Minuten für Fokus)\n\nZusatzfrage:\n\n\nUntertitel/Captions: Pflicht für BFSG-Konformität? (Barrierefreiheit für Hörgeschädigte)\n\n\n\nLetzte Struktur-Frage zu Cluster 5\n\n\nBevor ich das Dokument erstelle, eine organisatorische Frage:\n\n\nSoll das Cluster-5-Dokument folgende Struktur haben?\n\n\n# Cluster 5: Workflow & Rollen\n\n## 1. Übersicht\n   - Projektziel & Scope\n   - Akteure & Rollen (Matrix)\n\n## 2. Workflow-Phasen (detailliert)\n   Phase 0: Strategie\n   Phase 0.5: Vorarbeit\n   Phase 1: Research & Draft\n   Phase 2: Syntax-Validierung\n   Phase 3: Fehlerkorrektur\n   Phase 4: Semantic Review\n   Phase 5: Medien-Erstellung\n   Phase 6: Content-Enrichment\n   Phase 7: Final Review\n   Phase 8: Distribution\n\n## 3. Schnittstellen & Datenformate\n   - Input/Output pro Phase\n   - Bevorzugte Formate für KI\n\n## 4. Quality-Score-System\n   - Kriterien & Gewichtung\n   - Bewertungsmatrix\n   - Report-Format\n\n## 5. Fehlerbehandlung & Eskalation\n   - v1.0: Manuelle Kontrolle\n   - v2.0: Automatische Eskalation\n\n## 6. Medien-Spezifikationen\n   - Screenshots\n   - Annotations\n   - Videos\n\n## 7. Versionierung & Speicherung\n   - Git-Branch-Struktur\n   - Namenskonventionen\n\n## 8. Version 1.0 vs. spätere Versionen\n   - Was ist jetzt im Scope?\n   - Was kommt später?\n\n## Anhang\n   - Beispiel-Outputs\n   - Checklisten\n\n\nPasst diese Struktur für dich? Oder möchtest du Abschnitte anders gruppieren/priorisieren?\n\n\n\nWeitere offene Punkte (falls vorhanden)\n\n\nMir fällt noch ein möglicher Aspekt ein, den wir nicht explizit besprochen haben:\n\n\nTerminologie-Management:\n\n\nIn Cluster 1 hattest du eine Terminologie-Entscheidungsliste erwähnt. Wann und wie wird diese erstellt/gepflegt?\n\n\nOption A: Maintainer pflegt manuell während Phase 0/0.5\nOption B: KI schlägt Terminologie vor, Maintainer genehmigt\nOption C: Entsteht organisch während Phase 1-4, wird in separater Liste dokumentiert\n\n\nWie möchtest du das handhaben? Oder ist das bereits in einem anderen Cluster dokumentiert, und ich übersehe es?\n\n\n\nSobald du die Medien-Werte und die Struktur-Frage beantwortest hast, erstelle ich das vollständige Cluster-5-Dokument für dich. 🚀",
      "time_iso8601": "2025-10-10T01:00:10"
    },
    {
      "role": "Prompt",
      "say": "Ich bevorzuge Open Sans mit 16px Schriftgröße.\nUntertitel sind Pflicht und werden von der KI in Schritt 1 mit bereitgestellt. Der Maintainer muss dann nur noch die Zeitfenster anpassen.\n\n\nMindestauflösung: 1280x720\n\nHöchstauflösung: 1920x1080\n\nMindestframerate: 15 fps (Das sind Bildschirmvideos, da passiert nicht viel Schnelles und Wechselhaftes)\n\nMindestspieldauer: 10 Sekunden\n\nHöchstspieldauer: 180 Sekunden\n\n\nDeine Gliederung ist solide. Setze das bitte so um.\n\n\nZur Terminologie-Liste: Im Moment sehe ich, dass das wie in Option C organisch geschieht und Stück für Stück mitwächst.",
      "time_iso8601": "2025-10-10T01:12:57"
    },
    {
      "role": "Response",
      "say": "Perfekt! Alle Werte sind geklärt. Ich erstelle jetzt das vollständige Cluster-5-Dokument für dich.\n\n\n\nCluster 5: Workflow & Rollen - WebAssistentForensics\n\n\n# Cluster 5: Workflow & Rollen\n\n**Projekt:** WebAssistentForensics  \n**Version:** 1.0  \n**Datum:** 2025-10-10  \n**Status:** Final\n\n---\n\n## 1. Übersicht\n\n### 1.1 Projektziel & Scope\n\n**Ziel:** Entwicklung eines strukturierten Wissenssystems für IT-ferne Polizeibeamte zu IT-Forensik-Tools (initial: Magnet AXIOM Examine).\n\n**Scope Version 1.0:**\n- ~100-150 Sections\n- KI-gestützte Content-Generierung (Claude Sonnet 4.5)\n- JSON-Schema-validiertes HTML\n- BFSG-konforme Barrierefreiheit\n- Manuelle Kontrolle durch Maintainer bei allen kritischen Entscheidungen\n- Git-basierte Versionierung\n\n**Ausgeschlossen in v1.0 (für spätere Versionen):**\n- Automatisierte Workflows (teilweise in v2.0)\n- Parallelisierung von Draft-Erstellung\n- Git-Workflow-Automatisierung\n- Automatische Agent-Context-Generierung\n\n---\n\n### 1.2 Akteure & Rollen\n\n#### Akteure\n\n| Akteur | Beschreibung | Technologie |\n|--------|--------------|-------------|\n| **KI-System** | Claude Sonnet 4.5 für Content-Generierung und -Review | Anthropic Claude API / Web-Interface |\n| **Python-Skripte** | Automatisierte Syntax- und Schema-Validierung | Python 3.x + JSON-Schema |\n| **Maintainer** | Du oder Kollegen mit Gesamtverantwortung | Manuell |\n| **Handbuch-Autoren** | Ersteller von Software-Dokumentation (passiv) | Externe Quellen |\n\n#### Rollen-Matrix\n\n| Rolle | Verantwortung | Akteure |\n|-------|---------------|---------|\n| **Content-Creator** | Erstellt initialen Content (Drafts, Medien) | KI-System, Maintainer |\n| **Content-Validator** | Prüft Syntax, Schema-Konformität | Python-Skripte, Maintainer |\n| **Content-Enricher** | Ergänzt Medien, Glossar, Agent-Context | Maintainer |\n| **Content-Reviewer** | Prüft Qualität, Konsistenz, Korrektheit | KI-System, Maintainer |\n| **Content-Distributor** | Komponiert und verteilt Endprodukt | Maintainer |\n\n---\n\n## 2. Workflow-Phasen\n\n### Phase 0: Strategie\n\n**Verantwortlich:** Maintainer  \n**Häufigkeit:** Initial + bei Bedarf (neue Topics/Chapters)\n\n#### Aktivitäten\n1. **Lernziel definieren:** Was soll der Ermittler nach Durcharbeitung können?\n2. **Fokus-Themen festlegen:** Welche Aspekte sind zentral, welche peripher?\n3. **Umfang bestimmen:** Wie viele Sections, welche Detailtiefe?\n4. **Software & Version benennen:** Welches Tool in welcher Version?\n5. **Forensischer Kontext:** Mobilgerät, PC-System, Cloud, etc.?\n6. **Quellen benennen:** AXIOM-Handbuch, interne Dokumentation, etc.\n\n#### Output\n- **Strategiedokument(e):**\n  - **Global:** Für das Gesamtwerk\n  - **Pro Topic/Chapter:** Bei Bedarf für Verfeinerung\n- **Quellenliste:** Validierte, autorisierte Quellen\n\n#### Flexibilität\n- Strategiedokument ist **anpassbar** (Versionierung)\n- Fokus auf **Ergebnis**, nicht auf absolute Perfektion\n- Iterationen möglich, wenn sich Qualitätsprobleme zeigen\n\n---\n\n### Phase 0.5: Vorarbeit (iterativ bis Approval)\n\n**Verantwortlich:** KI-System + Maintainer (Approval)  \n**Häufigkeit:** Nach jeder Strategiedefinition/-anpassung\n\n#### Aktivitäten (KI)\n1. **Quellen analysieren:**\n   - Inhaltsverzeichnis vollständig lesen\n   - Kapitel-Intros (erste 2-3 Absätze) pro Hauptkapitel\n   - Struktur-Hinweise erfassen (Querverweise, Abhängigkeiten)\n2. **Gesamtgliederung erstellen:**\n   - Topics → Chapters → Sections ableiten\n   - Hierarchieebenen festlegen (3-5 Ebenen)\n   - Abhängigkeiten identifizieren\n3. **Grobe Inhaltsentwürfe pro Section:**\n   - Lernziel formulieren\n   - Key Topics auflisten\n   - Kurzbeschreibung verfassen\n   - Vorgänger/Nachfolger-Sections benennen\n\n#### Output-Format (pro Section)\n\n```\nSection: axiom-case-creation\nGliederungsebene: 3\nLernziel: Ermittler kann eigenständig einen Fall anlegen\nKey Topics:\n  - Neuen Fall anlegen (New Case Dialog)\n  - Evidenzquellen hinzufügen (Add Evidence)\n  - Fall-Metadaten erfassen (Case Properties)\nKurzbeschreibung:\n  Diese Section erklärt den kompletten Prozess der Fall-Erstellung in AXIOM.\n  Der Fokus liegt auf der korrekten Auswahl der Evidenzquellen und der\n  vollständigen Erfassung von Metadaten für spätere Berichte.\nVorgänger-Sections: axiom-installation, axiom-interface\nNachfolger-Sections: axiom-evidence-processing\n```\n\n#### Aktivitäten (Maintainer)\n1. **Gliederung prüfen:** Ist die Struktur logisch und vollständig?\n2. **Vollständigkeit bewerten:** Fehlen Sections? Sind Abhängigkeiten korrekt?\n3. **Strategiekonformität prüfen:** Passt die Gliederung zum Strategiedokument?\n4. **Entscheidung:**\n   - **Approval:** Weiter zu Phase 1\n   - **Reject:** Strategiedokument verfeinern → Phase 0.5b (Iteration)\n\n#### Output\n- **Section-Liste:** Abgesegnete Gliederung mit groben Inhaltsentwürfen\n- **Status:** Approved für Phase 1\n\n---\n\n### Phase 1: Research & Draft (pro Section)\n\n**Verantwortlich:** KI-System  \n**Häufigkeit:** Pro Section, sequenziell (keine Parallelisierung in v1.0)\n\n#### Input für KI\n\n```\n=== AKTUELL ZU ERSTELLENDE SECTION ===\n[Section-Info aus Phase 0.5 wie oben beschrieben]\n\n=== KONTEXT: BEREITS APPROBIERTE SECTIONS ===\n[Volltext der 2-3 unmittelbar vorhergehenden Sections]\n\n=== KONTEXT: GESAMTSTRUKTUR (ÜBERBLICK) ===\nTopic: AXIOM Grundlagen\n├─ Chapter: Installation & Setup\n│  ├─ axiom-installation (✓ approbiert)\n│  └─ axiom-interface (✓ approbiert)\n├─ Chapter: Fall-Management\n│  ├─ axiom-case-creation (← JETZT)\n│  ├─ axiom-evidence-processing (geplant)\n│  └─ axiom-case-export (geplant)\n\n=== QUELLEN (DETAILLIERT) ===\n[Relevante Kapitel aus AXIOM-Handbuch, vollständig]\n\n=== STRATEGIEDOKUMENT ===\n[Aktuelles Strategiedokument für diesen Bereich]\n```\n\n#### Aktivitäten (KI)\n1. **Quellen vertiefen:** Relevante Abschnitte im Detail lesen\n2. **Kontext verstehen:** Approbierte Sections auf Terminologie/Stil prüfen\n3. **Draft erstellen:**\n   - HTML gemäß Cluster 3 (BFSG, Whitelist, Attribute)\n   - Content gemäß Cluster 1 (Zielgruppe, Detail-Level, Terminologie)\n   - Struktur gemäß Cluster 2 (Hierarchie, data-ref, JSON-LD)\n   - Medien-Platzhalter mit Dateinamen-Vorschlägen\n   - Video-Untertitel-Entwürfe (SRT/VTT-Format)\n4. **Selbstprüfung:** Kurze Plausibilitätsprüfung vor Ausgabe\n\n#### Output\n- **Section-Draft (HTML):** Vollständiger HTML-Code gemäß Schema\n- **Medien-Spezifikationen:** Liste benötigter Screenshots/Videos mit Beschreibung\n- **Untertitel-Entwürfe:** Zeitstempel-unabhängige Untertitel-Texte\n- **Version:** 1.0.0\n\n---\n\n### Phase 2: Syntax-Validierung\n\n**Verantwortlich:** Python-Skripte (automatisiert)  \n**Häufigkeit:** Nach jedem Draft/jeder Korrektur\n\n#### Aktivitäten\n1. **JSON-Schema-Validierung:** Struktur, Pflicht-Attribute, Datentypen\n2. **HTML-Element-Prüfung:** Nur erlaubte Elemente (Whitelist)\n3. **Attribut-Vollständigkeit:** Pflicht-Attribute vorhanden?\n4. **BFSG-Konformität:** lang-Attribute, Alt-Texte, Überschriften-Hierarchie\n5. **Cross-Reference-Prüfung:** data-ref gültig und konsistent?\n6. **CSS-Klassen-Prüfung:** Nur erlaubte Klassen verwendet?\n\n#### Output-Format\n\n```\n=== SYNTAX VALIDATION REPORT ===\nSection: axiom-case-creation\nVersion: 1.0.0\nDatum: 2025-10-10 14:32:15\n\nCRITICAL [Line 45]: Missing required attribute 'lang' on element <span>\nERROR [Line 78]: Invalid data-ref format 'axiom_case' (underscore not allowed)\nERROR [Line 102]: Element <table> not in whitelist (use <div> with CSS grid)\nWARNING [Line 112]: Heading hierarchy skip (h2 → h4)\nWARNING [Line 156]: Alt-text suspiciously short (< 10 characters): \"AXIOM UI\"\nINFO [Line 89]: Consider adding 'title' attribute for better accessibility\nINFO [Line 134]: data-detail-level=\"1\" could benefit from level 2 variant\n\n=== SUMMARY ===\nCRITICAL: 1\nERROR: 2\nWARNING: 2\nINFO: 2\n\nStatus: FAILED (CRITICAL/ERROR present)\n```\n\n**Optional in v1.1:** Code-Snippet um Fehler herum für schnellere Lokalisierung\n\n---\n\n### Phase 3: Fehlerkorrektur (iterativ)\n\n**Verantwortlich:** KI-System (CRITICAL/ERROR), Maintainer (WARNING/INFO)  \n**Häufigkeit:** Nach jedem Validierungs-Fehlschlag\n\n#### Aktivitäten bei CRITICAL/ERROR\n\n1. **KI erhält:** Validierungs-Report (Textformat wie oben)\n2. **KI korrigiert:**\n   - Fehler lokalisieren\n   - Korrekturen vornehmen (nur betroffene Stellen)\n   - Keine inhaltlichen Änderungen (nur Syntax/Struktur)\n3. **KI erstellt:** Neue Version (z.B. 1.0.1)\n4. **Zurück zu Phase 2:** Erneute Validierung\n\n**Abbruchkriterium:** Wenn nach 5 Iterationen noch CRITICAL/ERROR → Eskalation an Maintainer\n\n#### Aktivitäten bei WARNING/INFO\n\n1. **Maintainer erhält:** Validierungs-Report\n2. **Maintainer entscheidet pro Warnung:**\n   - **Beheben:** Manuell korrigieren oder KI beauftragen\n   - **Ignorieren:** Als akzeptabel markieren (Begründung dokumentieren)\n3. **Bei Korrekturen:** Neue Version erstellen\n\n**Weiter zu Phase 4:** Wenn keine CRITICAL/ERROR mehr vorhanden\n\n#### Output\n- **Korrigierter Draft:** Syntaktisch valider HTML-Code\n- **Version:** Inkrementiert bei Änderungen (z.B. 1.0.3)\n- **Status:** Ready for Semantic Review\n\n---\n\n### Phase 4: Semantic Review\n\n**Verantwortlich:** KI-System  \n**Häufigkeit:** Nach syntaktischer Validierung, vor Medien-Erstellung\n\n#### Input für KI\n\n```\n=== ZU REVIEWENDE SECTION ===\n[Vollständiger HTML-Draft]\n\n=== STRATEGIEDOKUMENT ===\n[Relevantes Strategiedokument]\n\n=== ALLE APPROBIERTEN SECTIONS ===\n[Volltexte für Konsistenzprüfung]\n\n=== TERMINOLOGIE-LISTE ===\n[Organisch gewachsene Liste etablierter Begriffe]\n\n=== SECTION-LISTE (PHASE 0.5) ===\n[Ursprüngliche Inhaltsskizze für Vollständigkeitsprüfung]\n```\n\n#### Bewertungskriterien & Quality-Score (0-100)\n\n| Kriterium | Gewicht | Max. Punkte | Bewertungsfragen |\n|-----------|---------|-------------|------------------|\n| **Strategiekonformität** | 30% | 30 | • Entspricht die Section dem Lernziel?<br>• Sind Fokus-Themen korrekt priorisiert?<br>• Passt der Umfang zur Strategievorgabe?<br>• Sind Abgrenzungen eingehalten? |\n| **Verständlichkeit** | 25% | 25 | • Ist die Sprache zielgruppengerecht (IT-ferne Ermittler)?<br>• Sind Fachbegriffe erklärt?<br>• Ist die Schritt-für-Schritt-Logik nachvollziehbar?<br>• Sind Beispiele praxisnah? |\n| **Vollständigkeit** | 20% | 20 | • Sind alle Key Topics aus Phase 0.5 abgedeckt?<br>• Fehlen wichtige Informationen für das Lernziel?<br>• Sind notwendige Cross-References vorhanden?<br>• Ist der Detailgrad angemessen? |\n| **Konsistenz** | 15% | 15 | • Stimmt die Terminologie mit approbierten Sections überein?<br>• Passen Schreibstil und Tonalität?<br>• Sind Formatierungen einheitlich?<br>• Widersprechen Aussagen anderen Sections? |\n| **Struktur** | 10% | 10 | • Ist die Gliederung logisch aufgebaut?<br>• Sind Überschriften-Hierarchien korrekt?<br>• Ist die Navigation intuitiv?<br>• Sind Content-Type-Boxen sinnvoll eingesetzt? |\n\n#### Score-Interpretation\n\n```\n90-100 Punkte: Exzellent – Kann direkt zu Phase 5 (Medien-Erstellung)\n75-89 Punkte:  Gut – Kleinere Anpassungen empfohlen, dann weiter\n60-74 Punkte:  Akzeptabel – Mehrere Verbesserungen nötig, Review mit Maintainer\n0-59 Punkte:   Ungenügend – Zurück zu Phase 1 (Draft neu erstellen)\n```\n\n#### Output-Format\n\n```markdown\n## Semantic Review Report\n\n**Section:** axiom-case-creation  \n**Version:** 1.0.3  \n**Reviewer:** Claude Sonnet 4.5  \n**Datum:** 2025-10-10 15:45:22\n\n### Quality Score: 82/100 (Gut)\n\n#### Detailbewertung\n\n| Kriterium | Punkte | Max | Bemerkung |\n|-----------|--------|-----|-----------|\n| Strategiekonformität | 27 | 30 | Lernziel erreicht, Fokus-Themen gut abgedeckt. Empfehlung: Prozess der Evidenzquellenauswahl stärker betonen (laut Strategiedokument Priorität). |\n| Verständlichkeit | 22 | 25 | Sprache zielgruppengerecht, gute Schritt-für-Schritt-Anleitung. Empfehlung: Fachbegriff \"Hash-Algorithmus\" in Zeile 67 erklären. |\n| Vollständigkeit | 18 | 20 | Alle Key Topics vorhanden. Fehlt: Cross-Reference zu \"axiom-evidence-types\" für vertiefende Erklärung der Evidenzquellen. |\n| Konsistenz | 12 | 15 | Terminologie stimmt überein. Abweichung: \"Fallakte\" statt \"Fall\" (in axiom-installation wird \"Fall\" verwendet). |\n| Struktur | 9 | 10 | Gliederung logisch, Überschriften korrekt. Kleiner Hinweis: Info-Box in Zeile 45 könnte als Hint-Box besser passen (weniger kritische Information). |\n\n#### Handlungsempfehlungen\n\n**Priorität HOCH:**\n1. Evidenzquellenauswahl-Prozess detaillierter beschreiben (Strategiekonformität +3 Punkte möglich)\n2. Terminologie \"Fallakte\" → \"Fall\" anpassen (Konsistenz +2 Punkte)\n\n**Priorität MITTEL:**\n3. Cross-Reference zu \"axiom-evidence-types\" ergänzen (Vollständigkeit +2 Punkte)\n4. Fachbegriff \"Hash-Algorithmus\" erklären (Verständlichkeit +2 Punkte)\n\n**Priorität NIEDRIG:**\n5. Info-Box → Hint-Box umwandeln (Struktur +1 Punkt)\n\n**Geschätzter Score nach Anpassung:** 91/100 (Exzellent)\n\n#### Entscheidung\n☐ Direkt zu Phase 5 (Medien-Erstellung)  \n☑ Anpassungen vornehmen, dann Phase 4 wiederholen  \n☐ Zurück zu Phase 1 (Draft neu erstellen)\n```\n\n#### Weiter zu Phase 5\n- Wenn Score ≥ 75 und Maintainer zustimmt\n\n---\n\n### Phase 5: Medien-Erstellung\n\n**Verantwortlich:** Maintainer  \n**Häufigkeit:** Pro Section nach Semantic Review\n\n#### Medien-Spezifikationen\n\n##### Screenshots\n\n| Parameter | Wert |\n|-----------|------|\n| **Inhalt** | Nur Programm/Fenster/Pop-Up (kein Desktop-Hintergrund) |\n| **Auflösung** | 72 dpi |\n| **Farbtiefe** | Vollfarben |\n| **Theme** | System-Skin/Theme (keine Custom-Themes) |\n| **Format** | PNG, komprimiert 60-80% |\n| **Datenschutz** | Relevante Bereiche schwärzen/pixeln |\n| **Dateiname** | Von KI im Draft vorgegeben (z.B. `axiom-case-new-dialog.png`) |\n\n##### Annotations (auf Screenshots)\n\n| Parameter | Wert |\n|-----------|------|\n| **Kontrast** | Hoch (gut lesbar auf hellem/dunklem Hintergrund) |\n| **Farbcode** | • Rot: Achtung<br>• Gelb: Warnung<br>• Blau: Hinweis<br>• Grün: Handlungsanweisung |\n| **Pfeile** | Mindestbreite 4px |\n| **Verdeckung** | Nichts Wichtiges verdecken |\n| **Schriftart** | Open Sans (ohne Serifen) |\n| **Schriftgröße** | 16px |\n\n##### Videos\n\n| Parameter | Wert |\n|-----------|------|\n| **Mindestauflösung** | 1280×720 (HD) |\n| **Höchstauflösung** | 1920×1080 (Full HD) |\n| **Mindestframerate** | 15 fps (ausreichend für Bildschirmaufnahmen) |\n| **Mindestspieldauer** | 10 Sekunden |\n| **Höchstspieldauer** | 180 Sekunden (3 Minuten) |\n| **Seitenverhältnis** | 16:9 bevorzugt |\n| **Audio** | Ohne Musik, ggf. Sprecherstimme |\n| **Format** | MP4 bevorzugt |\n| **Codec** | H.264 (AVC), H.265 (HEVC) oder AV1 |\n| **Untertitel** | **Pflicht** (BFSG-Konformität), SRT/VTT-Format |\n\n**Untertitel-Workflow:**\n1. KI hat in Phase 1 Untertitel-Texte erstellt (ohne Zeitstempel)\n2. Maintainer erstellt Video\n3. Maintainer passt Zeitfenster im SRT/VTT-File an\n\n#### Aktivitäten\n1. **Medien erstellen:** Gemäß Draft-Spezifikationen und obigen Standards\n2. **Qualität prüfen:** Lesbarkeit, Kontrast, Dateigröße\n3. **Datenschutz sicherstellen:** Keine personenbezogenen Daten sichtbar\n4. **Dateien benennen:** Gemäß Draft-Vorgaben\n\n#### Output\n- **Medien-Assets:** Screenshots, annotierte Bilder, Videos (inkl. Untertitel)\n- **Dateinamen-Liste:** Mapping Draft-Platzhalter → tatsächliche Files\n\n---\n\n### Phase 6: Content-Enrichment\n\n**Verantwortlich:** Maintainer  \n**Häufigkeit:** Pro Section nach Medien-Erstellung\n\n#### Aktivitäten\n1. **Medien einbinden:**\n   - Platzhalter durch echte Pfade ersetzen\n   - `<img>`-Tags mit korrekten `src`, `alt`, `title` Attributen\n   - `<video>`-Tags mit Untertitel-Tracks\n2. **Glossar-Verweise ergänzen:**\n   - Fachbegriffe mit `data-glossary-term` auszeichnen\n   - Querverweise zu Glossar-Sections einfügen\n3. **Agent-Context erstellen (v1.0: manuell, später: KI-gestützt):**\n   - Trigger-Points identifizieren\n   - Agent-Context-Block am Section-Ende einfügen\n   - JSON-Struktur gemäß Cluster 2\n4. **Finale Formatierungsprüfung:**\n   - CSS-Klassen korrekt?\n   - Barrierefreiheit durchgängig gewährleistet?\n\n#### Output\n- **Angereicherte Section:** Vollständig mit Medien, Glossar, Agent-Context\n- **Version:** Inkrementiert (z.B. 1.1.0 für Content-Enrichment)\n- **Status:** Ready for Final Review\n\n---\n\n### Phase 7: Final Review\n\n**Verantwortlich:** Maintainer  \n**Häufigkeit:** Pro Section nach Content-Enrichment\n\n#### Aktivitäten\n1. **Fachliche Korrektheit:** Sind alle Informationen korrekt und aktuell?\n2. **UX-Prüfung:** Ist die Section intuitiv nutzbar?\n3. **Gesamteindruck:** Passt die Section ins Gesamtwerk?\n4. **Medienqualität:** Sind Screenshots/Videos verständlich und hilfreich?\n5. **Barrierefreiheit:** End-to-End-Test mit Screenreader (stichprobenartig)\n\n#### Entscheidung\n- **Approval:** Weiter zu Phase 8 (Distribution)\n- **Reject mit Feedback:**\n  - **Minor:** Zurück zu Phase 6 (kleine Anpassungen)\n  - **Major:** Zurück zu Phase 4 oder Phase 1 (grundlegende Überarbeitung)\n\n#### Output\n- **Approval-Status:** Approved / Rejected\n- **Feedback-Dokument:** Bei Reject mit konkreten Verbesserungshinweisen\n\n---\n\n### Phase 8: Distribution\n\n**Verantwortlich:** Maintainer  \n**Häufigkeit:** Pro Section nach Final Review Approval\n\n#### Aktivitäten\n1. **Versionierung:**\n   - Git-Commit mit beschreibender Message\n   - Tag setzen (z.B. `section-axiom-case-creation-v1.1.0`)\n2. **Branch-Überführung:**\n   - Von `content-drafts` nach `content-approved`\n   - Merge in `main` (falls produktionsreif)\n3. **Komponierung:**\n   - Section in Gesamt-Dokumentation integrieren\n   - Navigation aktualisieren\n4. **Veröffentlichung:**\n   - Build-Prozess anstoßen (HTML-Generierung, Asset-Optimierung)\n   - Deployment auf Zielplattform\n\n#### Output\n- **Published Section:** Öffentlich verfügbar in Wissenssystem\n- **Git-Repository:** Versioniert und dokumentiert\n- **Status:** Published\n\n---\n\n## 3. Schnittstellen & Datenformate\n\n### 3.1 Bevorzugte Formate für KI-Arbeit\n\n| Datentyp | Bevorzugtes Format | Begründung |\n|----------|-------------------|------------|\n| **Section-Beschreibungen** | Natürliche Sprache (Mischform Stichpunkte + Fließtext) | Besseres Verständnis von Nuancen und Kontext |\n| **Fehlerberichte** | Textformat mit Zeilennummern | Direkte Lokalisierung, keine JSON-Interpretation nötig |\n| **Strategiedokumente** | Markdown / Strukturierter Text | Gut lesbar, hierarchisch strukturierbar |\n| **Quellenmaterial** | Text / Markdown / PDF (extrahiert) | Direkt verarbeitbar |\n| **Approbierte Sections** | HTML (Volltext) | Analyse von Stil, Terminologie, Struktur |\n\n### 3.2 Input/Output-Matrix\n\n| Phase | Input | Output |\n|-------|-------|--------|\n| **0** | Projektziel, Zielgruppe, Rahmenbedingungen | Strategiedokument, Quellenliste |\n| **0.5** | Strategiedokument, Quellen (Inhaltsverzeichnis + Intros) | Section-Liste mit groben Inhaltsentwürfen |\n| **1** | Section-Info, approbierte Sections, Quellen (detailliert), Strategiedokument | Section-Draft (HTML), Medien-Spezifikationen, Untertitel-Entwürfe |\n| **2** | Section-Draft (HTML) | Validierungs-Report (CRITICAL/ERROR/WARNING/INFO) |\n| **3** | Validierungs-Report | Korrigierter Draft (neue Version) |\n| **4** | Draft, Strategiedokument, approbierte Sections, Terminologie-Liste | Semantic Review Report, Quality-Score |\n| **5** | Draft, Medien-Spezifikationen | Medien-Assets (Screenshots, Videos, Untertitel) |\n| **6** | Draft, Medien-Assets, Glossar-Daten | Angereicherte Section (mit Medien, Glossar, Agent) |\n| **7** | Angereicherte Section | Approval-Status, ggf. Feedback-Dokument |\n| **8** | Approved Section | Published Section, Git-Tag |\n\n---\n\n## 4. Quality-Score-System\n\n### 4.1 Kriterien & Gewichtung\n\n**Gesamtscore:** 0-100 Punkte\n\n| Kriterium | Gewicht | Max. Punkte | Fokus |\n|-----------|---------|-------------|-------|\n| Strategiekonformität | 30% | 30 | Passung zum Lernziel und Strategievorgaben |\n| Verständlichkeit | 25% | 25 | Zielgruppengerechte Sprache und Didaktik |\n| Vollständigkeit | 20% | 20 | Abdeckung aller Key Topics |\n| Konsistenz | 15% | 15 | Terminologie, Stil, Format |\n| Struktur | 10% | 10 | Logik, Hierarchie, Navigation |\n\n### 4.2 Bewertungsmatrix (Strategiekonformität Beispiel)\n\n| Punkte | Beschreibung |\n|--------|--------------|\n| 28-30 | Perfekte Umsetzung des Lernziels, alle Fokus-Themen priorisiert, exakte Umfangstreue |\n| 24-27 | Lernziel erreicht, Fokus-Themen gut abgedeckt, minimale Abweichungen |\n| 18-23 | Lernziel größtenteils erreicht, einige Fokus-Themen unterrepräsentiert |\n| 12-17 | Lernziel teilweise verfehlt, wichtige Fokus-Themen fehlen oder falsch gewichtet |\n| 0-11 | Lernziel nicht erreicht, gravierende Abweichungen von Strategievorgaben |\n\n*(Analoge Matrizen für alle Kriterien)*\n\n### 4.3 Report-Template\n\nSiehe Phase 4 Output-Format (Markdown-basiert, strukturiert, mit konkreten Handlungsempfehlungen)\n\n---\n\n## 5. Fehlerbehandlung & Eskalation\n\n### 5.1 Version 1.0: Manuelle Kontrolle (Option C)\n\n**Prinzip:** Maintainer hat jederzeit volle Kontrolle und greift bei Bedarf ein.\n\n#### Problem-Section-Handling\n\n```\nMaintainer beobachtet:\n├─ Anzahl Iterationen (Phase 2 ↔ 3)\n├─ Quality-Scores (Phase 4)\n├─ Fehlermuster (wiederkehrende Probleme)\n└─ Zeitaufwand pro Section\n\nMaintainer entscheidet fallweise:\n├─ Strategiedokument verfeinern → Phase 0.5b (neue Iteration)\n├─ KI-Prompt anpassen (mehr Kontext, präzisere An",
      "time_iso8601": "2025-10-10T01:15:31"
    },
    {
      "role": "Prompt",
      "say": "Weiter",
      "time_iso8601": "2025-10-10T01:15:54"
    },
    {
      "role": "Response",
      "say": "Cluster 5: Workflow & Rollen - WebAssistentForensics ∙ Version 2\n\n\n# Cluster 5: Workflow & Rollen\n\n**Projekt:** WebAssistentForensics  \n**Version:** 1.0  \n**Datum:** 2025-10-10  \n**Status:** Final\n\n---\n\n## 1. Übersicht\n\n### 1.1 Projektziel & Scope\n\n**Ziel:** Entwicklung eines strukturierten Wissenssystems für IT-ferne Polizeibeamte zu IT-Forensik-Tools (initial: Magnet AXIOM Examine).\n\n**Scope Version 1.0:**\n- ~100-150 Sections\n- KI-gestützte Content-Generierung (Claude Sonnet 4.5)\n- JSON-Schema-validiertes HTML\n- BFSG-konforme Barrierefreiheit\n- Manuelle Kontrolle durch Maintainer bei allen kritischen Entscheidungen\n- Git-basierte Versionierung\n\n**Ausgeschlossen in v1.0 (für spätere Versionen):**\n- Automatisierte Workflows (teilweise in v2.0)\n- Parallelisierung von Draft-Erstellung\n- Git-Workflow-Automatisierung\n- Automatische Agent-Context-Generierung\n\n---\n\n### 1.2 Akteure & Rollen\n\n#### Akteure\n\n| Akteur | Beschreibung | Technologie |\n|--------|--------------|-------------|\n| **KI-System** | Claude Sonnet 4.5 für Content-Generierung und -Review | Anthropic Claude API / Web-Interface |\n| **Python-Skripte** | Automatisierte Syntax- und Schema-Validierung | Python 3.x + JSON-Schema |\n| **Maintainer** | Du oder Kollegen mit Gesamtverantwortung | Manuell |\n| **Handbuch-Autoren** | Ersteller von Software-Dokumentation (passiv) | Externe Quellen |\n\n#### Rollen-Matrix\n\n| Rolle | Verantwortung | Akteure |\n|-------|---------------|---------|\n| **Content-Creator** | Erstellt initialen Content (Drafts, Medien) | KI-System, Maintainer |\n| **Content-Validator** | Prüft Syntax, Schema-Konformität | Python-Skripte, Maintainer |\n| **Content-Enricher** | Ergänzt Medien, Glossar, Agent-Context | Maintainer |\n| **Content-Reviewer** | Prüft Qualität, Konsistenz, Korrektheit | KI-System, Maintainer |\n| **Content-Distributor** | Komponiert und verteilt Endprodukt | Maintainer |\n\n---\n\n## 2. Workflow-Phasen\n\n### Phase 0: Strategie\n\n**Verantwortlich:** Maintainer  \n**Häufigkeit:** Initial + bei Bedarf (neue Topics/Chapters)\n\n#### Aktivitäten\n1. **Lernziel definieren:** Was soll der Ermittler nach Durcharbeitung können?\n2. **Fokus-Themen festlegen:** Welche Aspekte sind zentral, welche peripher?\n3. **Umfang bestimmen:** Wie viele Sections, welche Detailtiefe?\n4. **Software & Version benennen:** Welches Tool in welcher Version?\n5. **Forensischer Kontext:** Mobilgerät, PC-System, Cloud, etc.?\n6. **Quellen benennen:** AXIOM-Handbuch, interne Dokumentation, etc.\n\n#### Output\n- **Strategiedokument(e):**\n  - **Global:** Für das Gesamtwerk\n  - **Pro Topic/Chapter:** Bei Bedarf für Verfeinerung\n- **Quellenliste:** Validierte, autorisierte Quellen\n\n#### Flexibilität\n- Strategiedokument ist **anpassbar** (Versionierung)\n- Fokus auf **Ergebnis**, nicht auf absolute Perfektion\n- Iterationen möglich, wenn sich Qualitätsprobleme zeigen\n\n---\n\n### Phase 0.5: Vorarbeit (iterativ bis Approval)\n\n**Verantwortlich:** KI-System + Maintainer (Approval)  \n**Häufigkeit:** Nach jeder Strategiedefinition/-anpassung\n\n#### Aktivitäten (KI)\n1. **Quellen analysieren:**\n   - Inhaltsverzeichnis vollständig lesen\n   - Kapitel-Intros (erste 2-3 Absätze) pro Hauptkapitel\n   - Struktur-Hinweise erfassen (Querverweise, Abhängigkeiten)\n2. **Gesamtgliederung erstellen:**\n   - Topics → Chapters → Sections ableiten\n   - Hierarchieebenen festlegen (3-5 Ebenen)\n   - Abhängigkeiten identifizieren\n3. **Grobe Inhaltsentwürfe pro Section:**\n   - Lernziel formulieren\n   - Key Topics auflisten\n   - Kurzbeschreibung verfassen\n   - Vorgänger/Nachfolger-Sections benennen\n\n#### Output-Format (pro Section)\n\n```\nSection: axiom-case-creation\nGliederungsebene: 3\nLernziel: Ermittler kann eigenständig einen Fall anlegen\nKey Topics:\n  - Neuen Fall anlegen (New Case Dialog)\n  - Evidenzquellen hinzufügen (Add Evidence)\n  - Fall-Metadaten erfassen (Case Properties)\nKurzbeschreibung:\n  Diese Section erklärt den kompletten Prozess der Fall-Erstellung in AXIOM.\n  Der Fokus liegt auf der korrekten Auswahl der Evidenzquellen und der\n  vollständigen Erfassung von Metadaten für spätere Berichte.\nVorgänger-Sections: axiom-installation, axiom-interface\nNachfolger-Sections: axiom-evidence-processing\n```\n\n#### Aktivitäten (Maintainer)\n1. **Gliederung prüfen:** Ist die Struktur logisch und vollständig?\n2. **Vollständigkeit bewerten:** Fehlen Sections? Sind Abhängigkeiten korrekt?\n3. **Strategiekonformität prüfen:** Passt die Gliederung zum Strategiedokument?\n4. **Entscheidung:**\n   - **Approval:** Weiter zu Phase 1\n   - **Reject:** Strategiedokument verfeinern → Phase 0.5b (Iteration)\n\n#### Output\n- **Section-Liste:** Abgesegnete Gliederung mit groben Inhaltsentwürfen\n- **Status:** Approved für Phase 1\n\n---\n\n### Phase 1: Research & Draft (pro Section)\n\n**Verantwortlich:** KI-System  \n**Häufigkeit:** Pro Section, sequenziell (keine Parallelisierung in v1.0)\n\n#### Input für KI\n\n```\n=== AKTUELL ZU ERSTELLENDE SECTION ===\n[Section-Info aus Phase 0.5 wie oben beschrieben]\n\n=== KONTEXT: BEREITS APPROBIERTE SECTIONS ===\n[Volltext der 2-3 unmittelbar vorhergehenden Sections]\n\n=== KONTEXT: GESAMTSTRUKTUR (ÜBERBLICK) ===\nTopic: AXIOM Grundlagen\n├─ Chapter: Installation & Setup\n│  ├─ axiom-installation (✓ approbiert)\n│  └─ axiom-interface (✓ approbiert)\n├─ Chapter: Fall-Management\n│  ├─ axiom-case-creation (← JETZT)\n│  ├─ axiom-evidence-processing (geplant)\n│  └─ axiom-case-export (geplant)\n\n=== QUELLEN (DETAILLIERT) ===\n[Relevante Kapitel aus AXIOM-Handbuch, vollständig]\n\n=== STRATEGIEDOKUMENT ===\n[Aktuelles Strategiedokument für diesen Bereich]\n```\n\n#### Aktivitäten (KI)\n1. **Quellen vertiefen:** Relevante Abschnitte im Detail lesen\n2. **Kontext verstehen:** Approbierte Sections auf Terminologie/Stil prüfen\n3. **Draft erstellen:**\n   - HTML gemäß Cluster 3 (BFSG, Whitelist, Attribute)\n   - Content gemäß Cluster 1 (Zielgruppe, Detail-Level, Terminologie)\n   - Struktur gemäß Cluster 2 (Hierarchie, data-ref, JSON-LD)\n   - Medien-Platzhalter mit Dateinamen-Vorschlägen\n   - Video-Untertitel-Entwürfe (SRT/VTT-Format)\n4. **Selbstprüfung:** Kurze Plausibilitätsprüfung vor Ausgabe\n\n#### Output\n- **Section-Draft (HTML):** Vollständiger HTML-Code gemäß Schema\n- **Medien-Spezifikationen:** Liste benötigter Screenshots/Videos mit Beschreibung\n- **Untertitel-Entwürfe:** Zeitstempel-unabhängige Untertitel-Texte\n- **Version:** 1.0.0\n\n---\n\n### Phase 2: Syntax-Validierung\n\n**Verantwortlich:** Python-Skripte (automatisiert)  \n**Häufigkeit:** Nach jedem Draft/jeder Korrektur\n\n#### Aktivitäten\n1. **JSON-Schema-Validierung:** Struktur, Pflicht-Attribute, Datentypen\n2. **HTML-Element-Prüfung:** Nur erlaubte Elemente (Whitelist)\n3. **Attribut-Vollständigkeit:** Pflicht-Attribute vorhanden?\n4. **BFSG-Konformität:** lang-Attribute, Alt-Texte, Überschriften-Hierarchie\n5. **Cross-Reference-Prüfung:** data-ref gültig und konsistent?\n6. **CSS-Klassen-Prüfung:** Nur erlaubte Klassen verwendet?\n\n#### Output-Format\n\n```\n=== SYNTAX VALIDATION REPORT ===\nSection: axiom-case-creation\nVersion: 1.0.0\nDatum: 2025-10-10 14:32:15\n\nCRITICAL [Line 45]: Missing required attribute 'lang' on element <span>\nERROR [Line 78]: Invalid data-ref format 'axiom_case' (underscore not allowed)\nERROR [Line 102]: Element <table> not in whitelist (use <div> with CSS grid)\nWARNING [Line 112]: Heading hierarchy skip (h2 → h4)\nWARNING [Line 156]: Alt-text suspiciously short (< 10 characters): \"AXIOM UI\"\nINFO [Line 89]: Consider adding 'title' attribute for better accessibility\nINFO [Line 134]: data-detail-level=\"1\" could benefit from level 2 variant\n\n=== SUMMARY ===\nCRITICAL: 1\nERROR: 2\nWARNING: 2\nINFO: 2\n\nStatus: FAILED (CRITICAL/ERROR present)\n```\n\n**Optional in v1.1:** Code-Snippet um Fehler herum für schnellere Lokalisierung\n\n---\n\n### Phase 3: Fehlerkorrektur (iterativ)\n\n**Verantwortlich:** KI-System (CRITICAL/ERROR), Maintainer (WARNING/INFO)  \n**Häufigkeit:** Nach jedem Validierungs-Fehlschlag\n\n#### Aktivitäten bei CRITICAL/ERROR\n\n1. **KI erhält:** Validierungs-Report (Textformat wie oben)\n2. **KI korrigiert:**\n   - Fehler lokalisieren\n   - Korrekturen vornehmen (nur betroffene Stellen)\n   - Keine inhaltlichen Änderungen (nur Syntax/Struktur)\n3. **KI erstellt:** Neue Version (z.B. 1.0.1)\n4. **Zurück zu Phase 2:** Erneute Validierung\n\n**Abbruchkriterium:** Wenn nach 5 Iterationen noch CRITICAL/ERROR → Eskalation an Maintainer\n\n#### Aktivitäten bei WARNING/INFO\n\n1. **Maintainer erhält:** Validierungs-Report\n2. **Maintainer entscheidet pro Warnung:**\n   - **Beheben:** Manuell korrigieren oder KI beauftragen\n   - **Ignorieren:** Als akzeptabel markieren (Begründung dokumentieren)\n3. **Bei Korrekturen:** Neue Version erstellen\n\n**Weiter zu Phase 4:** Wenn keine CRITICAL/ERROR mehr vorhanden\n\n#### Output\n- **Korrigierter Draft:** Syntaktisch valider HTML-Code\n- **Version:** Inkrementiert bei Änderungen (z.B. 1.0.3)\n- **Status:** Ready for Semantic Review\n\n---\n\n### Phase 4: Semantic Review\n\n**Verantwortlich:** KI-System  \n**Häufigkeit:** Nach syntaktischer Validierung, vor Medien-Erstellung\n\n#### Input für KI\n\n```\n=== ZU REVIEWENDE SECTION ===\n[Vollständiger HTML-Draft]\n\n=== STRATEGIEDOKUMENT ===\n[Relevantes Strategiedokument]\n\n=== ALLE APPROBIERTEN SECTIONS ===\n[Volltexte für Konsistenzprüfung]\n\n=== TERMINOLOGIE-LISTE ===\n[Organisch gewachsene Liste etablierter Begriffe]\n\n=== SECTION-LISTE (PHASE 0.5) ===\n[Ursprüngliche Inhaltsskizze für Vollständigkeitsprüfung]\n```\n\n#### Bewertungskriterien & Quality-Score (0-100)\n\n| Kriterium | Gewicht | Max. Punkte | Bewertungsfragen |\n|-----------|---------|-------------|------------------|\n| **Strategiekonformität** | 30% | 30 | • Entspricht die Section dem Lernziel?<br>• Sind Fokus-Themen korrekt priorisiert?<br>• Passt der Umfang zur Strategievorgabe?<br>• Sind Abgrenzungen eingehalten? |\n| **Verständlichkeit** | 25% | 25 | • Ist die Sprache zielgruppengerecht (IT-ferne Ermittler)?<br>• Sind Fachbegriffe erklärt?<br>• Ist die Schritt-für-Schritt-Logik nachvollziehbar?<br>• Sind Beispiele praxisnah? |\n| **Vollständigkeit** | 20% | 20 | • Sind alle Key Topics aus Phase 0.5 abgedeckt?<br>• Fehlen wichtige Informationen für das Lernziel?<br>• Sind notwendige Cross-References vorhanden?<br>• Ist der Detailgrad angemessen? |\n| **Konsistenz** | 15% | 15 | • Stimmt die Terminologie mit approbierten Sections überein?<br>• Passen Schreibstil und Tonalität?<br>• Sind Formatierungen einheitlich?<br>• Widersprechen Aussagen anderen Sections? |\n| **Struktur** | 10% | 10 | • Ist die Gliederung logisch aufgebaut?<br>• Sind Überschriften-Hierarchien korrekt?<br>• Ist die Navigation intuitiv?<br>• Sind Content-Type-Boxen sinnvoll eingesetzt? |\n\n#### Score-Interpretation\n\n```\n90-100 Punkte: Exzellent – Kann direkt zu Phase 5 (Medien-Erstellung)\n75-89 Punkte:  Gut – Kleinere Anpassungen empfohlen, dann weiter\n60-74 Punkte:  Akzeptabel – Mehrere Verbesserungen nötig, Review mit Maintainer\n0-59 Punkte:   Ungenügend – Zurück zu Phase 1 (Draft neu erstellen)\n```\n\n#### Output-Format\n\n```markdown\n## Semantic Review Report\n\n**Section:** axiom-case-creation  \n**Version:** 1.0.3  \n**Reviewer:** Claude Sonnet 4.5  \n**Datum:** 2025-10-10 15:45:22\n\n### Quality Score: 82/100 (Gut)\n\n#### Detailbewertung\n\n| Kriterium | Punkte | Max | Bemerkung |\n|-----------|--------|-----|-----------|\n| Strategiekonformität | 27 | 30 | Lernziel erreicht, Fokus-Themen gut abgedeckt. Empfehlung: Prozess der Evidenzquellenauswahl stärker betonen (laut Strategiedokument Priorität). |\n| Verständlichkeit | 22 | 25 | Sprache zielgruppengerecht, gute Schritt-für-Schritt-Anleitung. Empfehlung: Fachbegriff \"Hash-Algorithmus\" in Zeile 67 erklären. |\n| Vollständigkeit | 18 | 20 | Alle Key Topics vorhanden. Fehlt: Cross-Reference zu \"axiom-evidence-types\" für vertiefende Erklärung der Evidenzquellen. |\n| Konsistenz | 12 | 15 | Terminologie stimmt überein. Abweichung: \"Fallakte\" statt \"Fall\" (in axiom-installation wird \"Fall\" verwendet). |\n| Struktur | 9 | 10 | Gliederung logisch, Überschriften korrekt. Kleiner Hinweis: Info-Box in Zeile 45 könnte als Hint-Box besser passen (weniger kritische Information). |\n\n#### Handlungsempfehlungen\n\n**Priorität HOCH:**\n1. Evidenzquellenauswahl-Prozess detaillierter beschreiben (Strategiekonformität +3 Punkte möglich)\n2. Terminologie \"Fallakte\" → \"Fall\" anpassen (Konsistenz +2 Punkte)\n\n**Priorität MITTEL:**\n3. Cross-Reference zu \"axiom-evidence-types\" ergänzen (Vollständigkeit +2 Punkte)\n4. Fachbegriff \"Hash-Algorithmus\" erklären (Verständlichkeit +2 Punkte)\n\n**Priorität NIEDRIG:**\n5. Info-Box → Hint-Box umwandeln (Struktur +1 Punkt)\n\n**Geschätzter Score nach Anpassung:** 91/100 (Exzellent)\n\n#### Entscheidung\n☐ Direkt zu Phase 5 (Medien-Erstellung)  \n☑ Anpassungen vornehmen, dann Phase 4 wiederholen  \n☐ Zurück zu Phase 1 (Draft neu erstellen)\n```\n\n#### Weiter zu Phase 5\n- Wenn Score ≥ 75 und Maintainer zustimmt\n\n---\n\n### Phase 5: Medien-Erstellung\n\n**Verantwortlich:** Maintainer  \n**Häufigkeit:** Pro Section nach Semantic Review\n\n#### Medien-Spezifikationen\n\n##### Screenshots\n\n| Parameter | Wert |\n|-----------|------|\n| **Inhalt** | Nur Programm/Fenster/Pop-Up (kein Desktop-Hintergrund) |\n| **Auflösung** | 72 dpi |\n| **Farbtiefe** | Vollfarben |\n| **Theme** | System-Skin/Theme (keine Custom-Themes) |\n| **Format** | PNG, komprimiert 60-80% |\n| **Datenschutz** | Relevante Bereiche schwärzen/pixeln |\n| **Dateiname** | Von KI im Draft vorgegeben (z.B. `axiom-case-new-dialog.png`) |\n\n##### Annotations (auf Screenshots)\n\n| Parameter | Wert |\n|-----------|------|\n| **Kontrast** | Hoch (gut lesbar auf hellem/dunklem Hintergrund) |\n| **Farbcode** | • Rot: Achtung<br>• Gelb: Warnung<br>• Blau: Hinweis<br>• Grün: Handlungsanweisung |\n| **Pfeile** | Mindestbreite 4px |\n| **Verdeckung** | Nichts Wichtiges verdecken |\n| **Schriftart** | Open Sans (ohne Serifen) |\n| **Schriftgröße** | 16px |\n\n##### Videos\n\n| Parameter | Wert |\n|-----------|------|\n| **Mindestauflösung** | 1280×720 (HD) |\n| **Höchstauflösung** | 1920×1080 (Full HD) |\n| **Mindestframerate** | 15 fps (ausreichend für Bildschirmaufnahmen) |\n| **Mindestspieldauer** | 10 Sekunden |\n| **Höchstspieldauer** | 180 Sekunden (3 Minuten) |\n| **Seitenverhältnis** | 16:9 bevorzugt |\n| **Audio** | Ohne Musik, ggf. Sprecherstimme |\n| **Format** | MP4 bevorzugt |\n| **Codec** | H.264 (AVC), H.265 (HEVC) oder AV1 |\n| **Untertitel** | **Pflicht** (BFSG-Konformität), SRT/VTT-Format |\n\n**Untertitel-Workflow:**\n1. KI hat in Phase 1 Untertitel-Texte erstellt (ohne Zeitstempel)\n2. Maintainer erstellt Video\n3. Maintainer passt Zeitfenster im SRT/VTT-File an\n\n#### Aktivitäten\n1. **Medien erstellen:** Gemäß Draft-Spezifikationen und obigen Standards\n2. **Qualität prüfen:** Lesbarkeit, Kontrast, Dateigröße\n3. **Datenschutz sicherstellen:** Keine personenbezogenen Daten sichtbar\n4. **Dateien benennen:** Gemäß Draft-Vorgaben\n\n#### Output\n- **Medien-Assets:** Screenshots, annotierte Bilder, Videos (inkl. Untertitel)\n- **Dateinamen-Liste:** Mapping Draft-Platzhalter → tatsächliche Files\n\n---\n\n### Phase 6: Content-Enrichment\n\n**Verantwortlich:** Maintainer  \n**Häufigkeit:** Pro Section nach Medien-Erstellung\n\n#### Aktivitäten\n1. **Medien einbinden:**\n   - Platzhalter durch echte Pfade ersetzen\n   - `<img>`-Tags mit korrekten `src`, `alt`, `title` Attributen\n   - `<video>`-Tags mit Untertitel-Tracks\n2. **Glossar-Verweise ergänzen:**\n   - Fachbegriffe mit `data-glossary-term` auszeichnen\n   - Querverweise zu Glossar-Sections einfügen\n3. **Agent-Context erstellen (v1.0: manuell, später: KI-gestützt):**\n   - Trigger-Points identifizieren\n   - Agent-Context-Block am Section-Ende einfügen\n   - JSON-Struktur gemäß Cluster 2\n4. **Finale Formatierungsprüfung:**\n   - CSS-Klassen korrekt?\n   - Barrierefreiheit durchgängig gewährleistet?\n\n#### Output\n- **Angereicherte Section:** Vollständig mit Medien, Glossar, Agent-Context\n- **Version:** Inkrementiert (z.B. 1.1.0 für Content-Enrichment)\n- **Status:** Ready for Final Review\n\n---\n\n### Phase 7: Final Review\n\n**Verantwortlich:** Maintainer  \n**Häufigkeit:** Pro Section nach Content-Enrichment\n\n#### Aktivitäten\n1. **Fachliche Korrektheit:** Sind alle Informationen korrekt und aktuell?\n2. **UX-Prüfung:** Ist die Section intuitiv nutzbar?\n3. **Gesamteindruck:** Passt die Section ins Gesamtwerk?\n4. **Medienqualität:** Sind Screenshots/Videos verständlich und hilfreich?\n5. **Barrierefreiheit:** End-to-End-Test mit Screenreader (stichprobenartig)\n\n#### Entscheidung\n- **Approval:** Weiter zu Phase 8 (Distribution)\n- **Reject mit Feedback:**\n  - **Minor:** Zurück zu Phase 6 (kleine Anpassungen)\n  - **Major:** Zurück zu Phase 4 oder Phase 1 (grundlegende Überarbeitung)\n\n#### Output\n- **Approval-Status:** Approved / Rejected\n- **Feedback-Dokument:** Bei Reject mit konkreten Verbesserungshinweisen\n\n---\n\n### Phase 8: Distribution\n\n**Verantwortlich:** Maintainer  \n**Häufigkeit:** Pro Section nach Final Review Approval\n\n#### Aktivitäten\n1. **Versionierung:**\n   - Git-Commit mit beschreibender Message\n   - Tag setzen (z.B. `section-axiom-case-creation-v1.1.0`)\n2. **Branch-Überführung:**\n   - Von `content-drafts` nach `content-approved`\n   - Merge in `main` (falls produktionsreif)\n3. **Komponierung:**\n   - Section in Gesamt-Dokumentation integrieren\n   - Navigation aktualisieren\n4. **Veröffentlichung:**\n   - Build-Prozess anstoßen (HTML-Generierung, Asset-Optimierung)\n   - Deployment auf Zielplattform\n\n#### Output\n- **Published Section:** Öffentlich verfügbar in Wissenssystem\n- **Git-Repository:** Versioniert und dokumentiert\n- **Status:** Published\n\n---\n\n## 3. Schnittstellen & Datenformate\n\n### 3.1 Bevorzugte Formate für KI-Arbeit\n\n| Datentyp | Bevorzugtes Format | Begründung |\n|----------|-------------------|------------|\n| **Section-Beschreibungen** | Natürliche Sprache (Mischform Stichpunkte + Fließtext) | Besseres Verständnis von Nuancen und Kontext |\n| **Fehlerberichte** | Textformat mit Zeilennummern | Direkte Lokalisierung, keine JSON-Interpretation nötig |\n| **Strategiedokumente** | Markdown / Strukturierter Text | Gut lesbar, hierarchisch strukturierbar |\n| **Quellenmaterial** | Text / Markdown / PDF (extrahiert) | Direkt verarbeitbar |\n| **Approbierte Sections** | HTML (Volltext) | Analyse von Stil, Terminologie, Struktur |\n\n### 3.2 Input/Output-Matrix\n\n| Phase | Input | Output |\n|-------|-------|--------|\n| **0** | Projektziel, Zielgruppe, Rahmenbedingungen | Strategiedokument, Quellenliste |\n| **0.5** | Strategiedokument, Quellen (Inhaltsverzeichnis + Intros) | Section-Liste mit groben Inhaltsentwürfen |\n| **1** | Section-Info, approbierte Sections, Quellen (detailliert), Strategiedokument | Section-Draft (HTML), Medien-Spezifikationen, Untertitel-Entwürfe |\n| **2** | Section-Draft (HTML) | Validierungs-Report (CRITICAL/ERROR/WARNING/INFO) |\n| **3** | Validierungs-Report | Korrigierter Draft (neue Version) |\n| **4** | Draft, Strategiedokument, approbierte Sections, Terminologie-Liste | Semantic Review Report, Quality-Score |\n| **5** | Draft, Medien-Spezifikationen | Medien-Assets (Screenshots, Videos, Untertitel) |\n| **6** | Draft, Medien-Assets, Glossar-Daten | Angereicherte Section (mit Medien, Glossar, Agent) |\n| **7** | Angereicherte Section | Approval-Status, ggf. Feedback-Dokument |\n| **8** | Approved Section | Published Section, Git-Tag |\n\n---\n\n## 4. Quality-Score-System\n\n### 4.1 Kriterien & Gewichtung\n\n**Gesamtscore:** 0-100 Punkte\n\n| Kriterium | Gewicht | Max. Punkte | Fokus |\n|-----------|---------|-------------|-------|\n| Strategiekonformität | 30% | 30 | Passung zum Lernziel und Strategievorgaben |\n| Verständlichkeit | 25% | 25 | Zielgruppengerechte Sprache und Didaktik |\n| Vollständigkeit | 20% | 20 | Abdeckung aller Key Topics |\n| Konsistenz | 15% | 15 | Terminologie, Stil, Format |\n| Struktur | 10% | 10 | Logik, Hierarchie, Navigation |\n\n### 4.2 Bewertungsmatrix (Strategiekonformität Beispiel)\n\n| Punkte | Beschreibung |\n|--------|--------------|\n| 28-30 | Perfekte Umsetzung des Lernziels, alle Fokus-Themen priorisiert, exakte Umfangstreue |\n| 24-27 | Lernziel erreicht, Fokus-Themen gut abgedeckt, minimale Abweichungen |\n| 18-23 | Lernziel größtenteils erreicht, einige Fokus-Themen unterrepräsentiert |\n| 12-17 | Lernziel teilweise verfehlt, wichtige Fokus-Themen fehlen oder falsch gewichtet |\n| 0-11 | Lernziel nicht erreicht, gravierende Abweichungen von Strategievorgaben |\n\n*(Analoge Matrizen für alle Kriterien)*\n\n### 4.3 Report-Template\n\nSiehe Phase 4 Output-Format (Markdown-basiert, strukturiert, mit konkreten Handlungsempfehlungen)\n\n---\n\n## 5. Fehlerbehandlung & Eskalation\n\n### 5.1 Version 1.0: Manuelle Kontrolle (Option C)\n\n**Prinzip:** Maintainer hat jederzeit volle Kontrolle und greift bei Bedarf ein.\n\n#### Problem-Section-Handling\n\n```\nMaintainer beobachtet:\n├─ Anzahl Iterationen (Phase 2 ↔ 3)\n├─ Quality-Scores (Phase 4)\n├─ Fehlermuster (wiederkehrende Probleme)\n└─ Zeitaufwand pro Section\n\nMaintainer entscheidet fallweise:\n├─ Strategiedokument verfeinern → Phase 0.5b (neue Iteration)\n├─ KI-Prompt anpassen (mehr Kontext, präzisere Anweisungen)\n├─ Section-Beschreibung in Phase 0.5 präzisieren\n├─ Quellenmaterial erweitern/verbessern\n├─ Als letzter Ausweg: Section manuell schreiben\n└─ Lessons Learned dokumentieren für v2.0\n```\n\n**Keine harte Abbruchgrenze:** Pragmatische Entscheidung basierend auf Aufwand-Nutzen-Verhältnis.\n\n#### Eskalations-Trigger (informell)\n\n- **Syntax-Fehler:** >5 Iterationen ohne Besserung → Maintainer prüft, ob Fehler systematisch ist\n- **Semantic Review:** Score <60 über 2 Draft-Versionen → Strategiedokument überarbeiten\n- **Zeitüberschreitung:** Section benötigt >4 Stunden → Prozess hinterfragen\n\n#### Dokumentation\n\n**Lessons Learned Log:**\n```markdown\n## Problem-Section: axiom-advanced-search\n**Datum:** 2025-10-15\n**Problem:** Score blieb bei 52-58 über 3 Drafts\n**Ursache:** Strategiedokument zu vage (\"erweiterte Suchfunktionen\")\n**Lösung:** Konkretisierung: \"Boolean-Operatoren, Regex, Filter-Kombinationen\"\n**Ergebnis:** Score 87 nach neuem Draft\n**Learning:** Strategiedokument braucht konkrete Feature-Namen, nicht nur Kategorien\n```\n\n---\n\n### 5.2 Version 2.0: Automatische Eskalation (Option B) - Perspektivisch\n\n**Prinzip:** System erkennt Problem-Sections automatisch und schlägt Lösungen vor.\n\n#### Automatische Trigger\n\n```\nSystem überwacht:\n├─ Syntax-Fehler-Häufigkeit (CRITICAL/ERROR pro Version)\n├─ Semantic Review Scores (Trend über Versionen)\n├─ Iterationszyklen (Anzahl Phase-2-3-Durchläufe)\n└─ Zeitverbrauch (Dauer seit Phase 1 Start)\n\nEskalations-Schwellen:\n├─ Score < 60 über 2 Draft-Versionen ODER\n├─ >5 Syntax-Fehler-Iterationen ODER\n├─ >3 Semantic-Review-Durchläufe ohne Verbesserung\n└─ System markiert Section als \"problematic\"\n```\n\n#### Automatische Analyse\n\n```\nSystem analysiert:\n├─ Fehlerhistorie:\n│  ├─ Welche Kriterien scheitern wiederholt?\n│  ├─ Sind Fehler syntaktisch oder semantisch?\n│  └─ Gibt es Muster (z.B. immer Konsistenz-Probleme)?\n├─ Strategiedokument-Qualität:\n│  ├─ Sind Lernziele präzise formuliert?\n│  ├─ Sind Key Topics spezifisch genug?\n│  └─ Gibt es widersprüchliche Vorgaben?\n├─ Quellenmaterial-Verfügbarkeit:\n│  ├─ Ist das Thema ausreichend dokumentiert?\n│  ├─ Sind Quellen aktuell?\n│  └─ Fehlen wichtige Informationen?\n└─ Komplexität:\n   ├─ Ist die Section zu umfangreich?\n   ├─ Sollte sie aufgeteilt werden?\n   └─ Sind Vorgänger-Sections unzureichend?\n```\n\n#### System-Vorschläge\n\n```markdown\n## Eskalations-Report: axiom-advanced-search\n\n**Status:** PROBLEMATIC  \n**Trigger:** Score < 60 über 2 Drafts (52 → 58)  \n**Datum:** 2025-10-15\n\n### Analyse\n\n**Fehler-Muster:**\n- Strategiekonformität: Wiederholt niedrig (15-18/30)\n- Vollständigkeit: Schwankend (12-16/20)\n- Andere Kriterien: Akzeptabel (>80% Punktzahl)\n\n**Strategiedokument-Prüfung:**\n- Lernziel zu allgemein: \"Ermittler kann erweiterte Suchen durchführen\"\n- Key Topics zu vage: \"Erweiterte Suchfunktionen\", \"Filter\"\n- Keine konkreten Features genannt\n\n**Quellen-Prüfung:**\n- AXIOM-Handbuch Kapitel 7.2 \"Advanced Search\" vollständig verfügbar\n- Keine Quellenprobleme erkennbar\n\n### Empfohlene Maßnahmen\n\n**PRIORITÄT 1: Strategiedokument verfeinern**\n\nVorschlag für neues Strategiedokument:\n```\nLernziel: Ermittler kann Boolean-Operatoren (AND, OR, NOT), \nRegex-Patterns und Filter-Kombinationen für präzise Suchen einsetzen.\n\nKey Topics:\n- Boolean-Operatoren (AND, OR, NOT, Klammersetzung)\n- Regex-Grundlagen (., *, +, ?, [])\n- Filter-Kombinationen (Dateityp + Zeitraum + Keyword)\n- Suchhistorie und Suche speichern\n```\n\n**PRIORITÄT 2: Section ggf. aufteilen**\n\nWenn Strategiedokument-Verbesserung nicht hilft:\n- Section 1: \"Boolean-Suche in AXIOM\" (Grundlagen)\n- Section 2: \"Regex-Suche in AXIOM\" (für Fortgeschrittene)\n- Section 3: \"Filter-Kombinationen in AXIOM\"\n\n### Maintainer-Entscheidung erforderlich\n\n☐ Strategiedokument verfeinern (Vorschlag übernehmen)  \n☐ Strategiedokument verfeinern (eigene Formulierung)  \n☐ Section aufteilen  \n☐ Manuell schreiben (KI-Generierung abbrechen)\n```\n\n---\n\n## 6. Medien-Spezifikationen\n\n*(Bereits vollständig in Phase 5 dokumentiert)*\n\n**Zusammenfassung:**\n\n| Medientyp | Key-Parameter |\n|-----------|---------------|\n| **Screenshots** | PNG 60-80%, 72dpi, System-Theme, Datenschutz beachten |\n| **Annotations** | Open Sans 16px, Farbcode (Rot/Gelb/Blau/Grün), Pfeile ≥4px |\n| **Videos** | 1280×720 bis 1920×1080, 15fps min, MP4/H.264, Untertitel Pflicht |\n\n---\n\n## 7. Versionierung & Speicherung\n\n### 7.1 Git-Branch-Struktur\n\n```\nmain\n├─ Nur Published Sections (Phase 8)\n├─ Tag-basierte Releases (z.B. v1.0.0, v1.1.0)\n└─ Protected Branch (nur Maintainer darf mergen)\n\ncontent-approved\n├─ Sections nach Final Review (Phase 7)\n├─ Bereit für Deployment\n└─ Merge-Target für content-drafts\n\ncontent-drafts\n├─ Arbeitskopien (Phase 1-6)\n├─ Unterverzeichnisse pro Section\n└─ Versionsnummern in Commit-Messages\n```\n\n### 7.2 Namenskonventionen\n\n**Verzeichnisstruktur:**\n```\ncontent-drafts/\n├─ axiom-grundlagen/\n│  ├─ axiom-installation/\n│  │  ├─ section.html\n│  │  ├─ media/\n│  │  │  ├─ axiom-install-welcome.png\n│  │  │  └─ axiom-install-process.mp4\n│  │  └─ metadata.json\n│  └─ axiom-case-management/\n└─ axiom-analysis/\n```\n\n**Versionsnummern:**\n- Format: `MAJOR.MINOR.BUILD`\n- MAJOR: Grundlegende Überarbeitung (zurück zu Phase 1)\n- MINOR: Content-Enrichment, größere Änderungen\n- BUILD: Bugfixes, kleine Korrekturen\n\n**Git-Tags:**\n```\nsection-axiom-installation-v1.0.0\nsection-axiom-installation-v1.1.0 (nach Content-Enrichment)\nsection-axiom-installation-v1.1.2 (nach Bugfixes)\n```\n\n### 7.3 Metadaten-Datei (metadata.json)\n\n```json\n{\n  \"section_id\": \"axiom-case-creation\",\n  \"version\": \"1.1.0\",\n  \"status\": \"approved\",\n  \"created\": \"2025-10-10T14:00:00Z\",\n  \"last_modified\": \"2025-10-10T16:30:00Z\",\n  \"author\": \"Claude Sonnet 4.5\",\n  \"maintainer\": \"Max Mustermann\",\n  \"quality_score\": 87,\n  \"review_cycles\": 2,\n  \"validation_errors\": {\n    \"critical\": 0,\n    \"error\": 0,\n    \"warning\": 1,\n    \"info\": 3\n  },\n  \"sources\": [\n    \"AXIOM Examine User Guide v7.8, Chapter 4\",\n    \"Internal Best Practices Doc v2.3\"\n  ],\n  \"learning_goal\": \"Ermittler kann eigenständig einen Fall anlegen\",\n  \"hierarchy_level\": 3,\n  \"prerequisites\": [\"axiom-installation\", \"axiom-interface\"],\n  \"related_sections\": [\"axiom-evidence-processing\", \"axiom-case-export\"]\n}\n```\n\n---\n\n## 8. Version 1.0 vs. spätere Versionen\n\n### 8.1 Scope Version 1.0\n\n**Im Scope:**\n- ✅ Manuelle Kontrolle durch Maintainer bei allen kritischen Entscheidungen\n- ✅ Sequenzielle Section-Erstellung (keine Parallelisierung)\n- ✅ KI-generierte Drafts mit manueller Review\n- ✅ Python-basierte Syntax-Validierung (automatisiert)\n- ✅ KI-basierte Semantic Review (automatisiert)\n- ✅ Manuelle Medien-Erstellung\n- ✅ Manuelle Agent-Context-Erstellung\n- ✅ Git-basierte Versionierung (manuell)\n- ✅ Organisch wachsende Terminologie-Liste\n- ✅ Fehlerbehandlung: Option C (manuelle Entscheidung)\n\n**Ausgeschlossen:**\n- ❌ Automatisierte End-to-End-Workflows\n- ❌ Parallelisierung von Draft-Erstellung\n- ❌ Automatische Git-Workflows (CI/CD)\n- ❌ Automatische Agent-Context-Generierung\n- ❌ Automatische Eskalation (Option B)\n\n---\n\n### 8.2 Roadmap für spätere Versionen\n\n#### Version 1.1 (Quick Wins)\n\n**Geplante Verbesserungen:**\n- 🔄 Code-Snippet-Kontext in Fehlerberichten (Phase 2)\n- 🔄 Medien-Template-Bibliothek (Annotations schneller erstellen)\n- 🔄 Erweiterte Metadaten-Analyse (Trends, Bottlenecks)\n\n**Aufwand:** Niedrig (< 2 Wochen Entwicklung)\n\n---\n\n#### Version 2.0 (Automatisierung & Skalierung)\n\n**Geplante Verbesserungen:**\n- 🔄 **Teilautomatisierung:**\n  - Claude API-Integration (Python-Wrapper)\n  - Batch-Processing für mehrere Sections\n  - Automatische Git-Commits nach Approval\n- 🔄 **Parallelisierung:**\n  - Unabhängige Sections parallel erstellen\n  - Dependency-Graph für Reihenfolge\n- 🔄 **Fehlerbehandlung:**\n  - Option B: Automatische Eskalation\n  - System-Vorschläge für Strategiedokument-Verbesserungen\n- 🔄 **Erweiterte Metriken:**\n  - Dashboard für Workflow-Monitoring\n  - Predictive Analytics (Zeitschätzungen pro Section)\n\n**Aufwand:** Mittel (1-2 Monate Entwicklung)\n\n---\n\n#### Version 3.0 (KI-Agent-System)\n\n**Geplante Verbesserungen:**\n- 🔄 **Automatische Agent-Context-Generierung:**\n  - KI schlägt Trigger-Points vor\n  - KI generiert Agent-Kontext-Blöcke\n  - Maintainer reviewed und genehmigt\n- 🔄 **Multi-Tool-Unterstützung:**\n  - X-Ways Forensics, Cellebrite Reader parallel pflegen\n  - Tool-spezifische Metadaten automatisch verwalten\n- 🔄 **Adaptive Strategiedokumente:**\n  - KI lernt aus Problem-Sections\n  - Vorschläge zur Strategieverbesserung\n  - Self-Healing-Workflows\n\n**Aufwand:** Hoch (3-6 Monate Entwicklung)\n\n---\n\n## Anhang\n\n### A.1 Checkliste: Phase 0 (Strategie)\n\n**Vor Start von Phase 0.5:**\n\n- [ ] Lernziel formuliert (konkret, messbar)\n- [ ] Fokus-Themen definiert (inkl. Abgrenzungen)\n- [ ] Umfang geschätzt (Anzahl Sections, Detailtiefe)\n- [ ] Software & Version benannt\n- [ ] Forensischer Kontext geklärt (Mobilgerät/PC/Cloud)\n- [ ] Quellen benannt und validiert (min. 1 Hauptquelle)\n- [ ] Strategiedokument versioniert (z.B. v1.0.0)\n\n---\n\n### A.2 Checkliste: Phase 5 (Medien-Erstellung)\n\n**Vor Übergabe an Phase 6:**\n\n**Screenshots:**\n- [ ] Nur Programm/Fenster (kein Desktop)\n- [ ] 72 dpi, Vollfarben, System-Theme\n- [ ] PNG 60-80% komprimiert\n- [ ] Datenschutz: Relevante Bereiche geschwärzt/gepixelt\n- [ ] Dateinamen gemäß Draft-Vorgabe\n\n**Annotations:**\n- [ ] Open Sans 16px\n- [ ] Farbcode eingehalten (Rot/Gelb/Blau/Grün)\n- [ ] Pfeile ≥4px breit\n- [ ] Nichts Wichtiges verdeckt\n- [ ] Hoher Kontrast\n\n**Videos:**\n- [ ] Auflösung 1280×720 bis 1920×1080\n- [ ] Framerate ≥15 fps\n- [ ] Spieldauer 10-180 Sekunden\n- [ ] Format: MP4, Codec: H.264/H.265/AV1\n- [ ] 16:9 Seitenverhältnis\n- [ ] Untertitel (SRT/VTT) vorhanden und synchronisiert\n- [ ] Keine Musik, ggf. Sprecherstimme verständlich\n\n---\n\n### A.3 Beispiel: Strategiedokument\n\n```markdown\n# Strategiedokument: AXIOM Case Management\n\n**Version:** 1.0.0  \n**Datum:** 2025-10-05  \n**Gültigkeit:** Topic \"AXIOM Case Management\"\n\n## Lernziel\n\nErmittler können eigenständig Fälle in AXIOM Examine v7.8 erstellen, \nEvidenzquellen hinzufügen, Fälle verwalten und für Berichte exportieren.\n\n## Fokus-Themen\n\n**Priorität HOCH:**\n- Fall-Erstellung (New Case Dialog, Metadaten)\n- Evidenzquellen-Auswahl (Devices, Images, Cloud)\n- Fall-Export (Reports, Evidence Files)\n\n**Priorität MITTEL:**\n- Fall-Verwaltung (Öffnen, Schließen, Archivieren)\n- Mehrere Evidenzquellen pro Fall\n\n**Priorität NIEDRIG:**\n- Erweiterte Metadaten (Custom Fields)\n- Fall-Vorlagen (Templates)\n\n**Explizit ausgeschlossen:**\n- Case Sharing (Multi-User-Szenarien)\n- Server-basierte Fälle (nur lokale Fälle)\n\n## Umfang\n\n**Geschätzte Sections:** 6-8\n\n1. axiom-case-creation (Standard-Detail)\n2. axiom-evidence-sources (Standard-Detail)\n3. axiom-case-metadata (Basic-Detail)\n4. axiom-case-management (Basic-Detail)\n5. axiom-multi-evidence (Standard-Detail)\n6. axiom-case-export (Standard-Detail)\n7. axiom-case-templates (Optional, Show-Only)\n\n## Forensischer Kontext\n\n**Primär:** Mobilgeräte (Smartphones, Tablets)  \n**Sekundär:** PC-Systeme (Windows, macOS)  \n**Ausgeklammert:** Cloud-Forensik (eigenes Topic)\n\n## Software & Version\n\n**Tool:** Magnet AXIOM Examine  \n**Version:** 7.8.x (aktuelle Stable-Version, Stand 2024-Q4)  \n**Hinweis:** Screenshots mit Default-Skin, keine Custom-Themes\n\n## Quellen\n\n**Primär:**\n- AXIOM Examine User Guide v7.8, Chapter 3-4\n- Magnet Forensics Knowledge Base (online)\n\n**Sekundär:**\n- Interne Best Practices \"Case Management Workflows\" v2.3\n- AXIOM Release Notes v7.8\n\n## Terminologie-Entscheidungen\n\n| Begriff | Verwendung | Begründung |\n|---------|-----------|------------|\n| \"Fall\" | Bevorzugt | Kurz, gebräuchlich in deutschem Polizeikontext |\n| \"Fallakte\" | Vermeiden | Zu formal, potenziell missverständlich |\n| \"Evidenzquelle\" | Bevorzugt | Präziser als \"Datenquelle\" |\n| \"Case\" | Nur in UI-Kontext | Wenn AXIOM-UI englische Begriffe nutzt |\n\n## Zielgruppen-Spezifika\n\n**Primäre Zielgruppe:** Polizei-Ermittler, IT-fern (Mittlere Reife)  \n**Detail-Level-Verteilung:**\n- 60% Standard-Detail\n- 25% Basic-Detail\n- 10% Expert-Detail (nur für Spezialfälle)\n- 5% Show-Only (optionale Vertiefungen)\n\n**Sprach-Richtlinien:**\n- Deutsch bevorzugt\n- Englische UI-Begriffe in Anführungszeichen (\"New Case\")\n- Fachbegriffe beim ersten Auftreten erklären\n- Schritt-für-Schritt-Anleitungen mit Screenshots\n\n---\n\n**Approval:**  \n☑ Maintainer: Max Mustermann, 2025-10-05  \n☐ Fach-Review: [optional]\n```\n\n---\n\n### A.4 Beispiel: Section-Liste (Phase 0.5 Output)\n\n```markdown\n# Section-Liste: AXIOM Case Management\n\n**Erstellt:** 2025-10-06  \n**Status:** Awaiting Maintainer Approval  \n**Basis:** Strategiedokument v1.0.0\n\n---\n\n## Topic: AXIOM Case Management\n\n### Chapter 1: Grundlagen\n\n#### Section 1.1: axiom-case-creation\n\n**Gliederungsebene:** 3  \n**Lernziel:** Ermittler kann eigenständig einen Fall in AXIOM anlegen  \n**Key Topics:**\n- New Case Dialog öffnen (File → New Case)\n- Fall-Namen und Beschreibung eingeben\n- Examiner-Informationen erfassen\n- Speicherort wählen\n\n**Kurzbeschreibung:**  \nDiese Section führt Schritt für Schritt durch die Fall-Erstellung in AXIOM Examine. \nDer Fokus liegt auf der korrekten Erfassung von Metadaten (Fall-Name, Examiner, \nBeschreibung) und der Auswahl eines geeigneten Speicherorts. Es wird erklärt, \nwarum vollständige Metadaten für spätere Berichte wichtig sind.\n\n**Vorgänger-Sections:** axiom-installation, axiom-interface  \n**Nachfolger-Sections:** axiom-evidence-sources\n\n**Geschätzte Komplexität:** Basic  \n**Geschätzte Medien:** 3 Screenshots, ggf. 1 kurzes Video (30 Sek)\n\n---\n\n#### Section 1.2: axiom-evidence-sources\n\n**Gliederungsebene:** 3  \n**Lernziel:** Ermittler kann verschiedene Evidenzquellentypen unterscheiden und auswählen  \n**Key Topics:**\n- Device (direkter Zugriff auf angeschlossenes Gerät)\n- Image File (forensisches Abbild laden)\n- Cloud (Online-Datenquellen)\n- Entscheidungshilfe: Wann welcher Typ?\n\n**Kurzbeschreibung:**  \nDiese Section erklärt die verschiedenen Evidenzquellentypen in AXIOM und gibt \nEntscheidungshilfen, wann welcher Typ zu verwenden ist. Sie zeigt die Unterschiede \nzwischen direktem Device-Zugriff (schnell, aber Veränderungsgefahr) und Image Files \n(forensisch sauber, aber mehr Vorbereitungsaufwand). Cloud-Quellen werden nur \noberflächlich erwähnt, da sie in einem eigenen Topic behandelt werden.\n\n**Vorgänger-Sections:** axiom-case-creation  \n**Nachfolger-Sections:** axiom-case-metadata, axiom-multi-evidence\n\n**Geschätzte Komplexität:** Standard  \n**Geschätzte Medien:** 4 Screenshots, 1 Entscheidungsdiagramm, ggf. 1 Video (60 Sek)\n\n---\n\n[... weitere Sections analog ...]\n\n---\n\n**Gesamt:**\n- 7 Sections (6 regulär, 1 optional)\n- Geschätzte Gesamtarbeitszeit: 15-20 Stunden\n- Geschätzte Medien: ~25 Screenshots, 3-5 Videos, 2 Diagramme\n```\n\n---\n\n### A.5 Terminologie-Liste (organisch wachsend)\n\n```markdown\n# Terminologie-Liste: WebAssistentForensics\n\n**Version:** 1.3.5  \n**Letztes Update:** 2025-10-10  \n**Status:** Living Document (organisch wachsend)\n\n---\n\n## Entscheidungen\n\n| Begriff (DE) | Begriff (EN) | Verwendung | Kontext | Quelle |\n|--------------|--------------|-----------|---------|--------|\n| Fall | Case | **Präferenz: \"Fall\"** | Allgemein, nur \"Case\" wenn UI-Referenz | Strategiedokument AXIOM Case Management v1.0.0 |\n| Fallakte | Case File | **Vermeiden**, stattdessen \"Fall\" | - | Feedback Section axiom-case-creation v1.0.3 |\n| Evidenzquelle | Evidence Source | **Präferenz: \"Evidenzquelle\"** | Allgemein | Strategiedokument v1.0.0 |\n| Abbild | Image | **\"Forensisches Abbild\"** bei erster Erwähnung, dann \"Abbild\" | Forensik-Kontext | Section axiom-evidence-sources v1.1.0 |\n| Hash-Wert | Hash Value | **Präferenz: \"Hash-Wert\"** | Allgemein | Section axiom-integrity-check v1.0.0 |\n| Prüfsumme | Checksum | **Synonym für \"Hash-Wert\"**, sparsam verwenden | Wenn Verständlichkeit erhöht wird | Semantic Review axiom-integrity-check |\n\n---\n\n## Erklärungspflichtige Fachbegriffe\n\n| Begriff | Erklärung (erste Erwähnung) | Beispiel-Section |\n|---------|----------------------------|------------------|\n| Hash-Wert | \"Ein Hash-Wert ist ein eindeutiger 'Fingerabdruck' einer Datei, der zur Integritätsprüfung dient.\" | axiom-integrity-check |\n| Hex-Editor | \"Ein Hex-Editor zeigt Dateiinhalte in hexadezimaler Form (0-9, A-F) an, was für forensische Analysen wichtig ist.\" | axiom-hex-view |\n| Artifact | \"Ein Artifact ist ein digital\n\nes Spurenobjekt (z.B. Browser-Historie, GPS-Koordinaten), das AXIOM automatisch erkennt.\" | axiom-artifacts-overview |\n\n---\n\n**Hinweis:** Diese Liste wächst mit jeder neuen Section. Bei Terminologie-Konflikten \nist das Strategiedokument maßgeblich, gefolgt von der Mehrheit approbierter Sections.\n```\n\n---\n\n## Ende Cluster 5\n\n**Nächste Schritte:**\n1. Dieses Dokument in Projekt-Dateispeicher ablegen: `cluster5_Workflow-Rollen.md`\n2. Bei Bedarf Reviews mit Stakeholdern durchführen\n3. Mit Phase 0 (Strategie) für erste Section beginnen\n4. Lessons Learned kontinuierlich dokumentieren für v2.0\n\n**Fragen oder Anmerkungen:** Maintainer kontaktieren\n\n---\n\n**Versionshistorie:**\n\n| Version | Datum | Änderung |\n|---------|-------|----------|\n| 1.0.0 | 2025-10-10 | Initiale Erstellung (Cluster 5 abgeschlossen) |\n\n\nPerfekt! 🎉 Das vollständige Cluster-5-Dokument ist nun fertig erstellt.\n\n\n\nZusammenfassung: Was wir erreicht haben\n\n\nDu hast jetzt ein umfassendes Workflow- und Rollen-Dokument mit:\n\n\n✅ Vollständig definiert:\n\n\nAkteure & Rollen (KI, Python, Maintainer + 5 Kernrollen)\n\n9 Workflow-Phasen (0 → 0.5 → 1-8) mit detaillierten Aktivitäten\n\nQuality-Score-System (30% Strategiekonformität, strukturierte Bewertung)\n\nSchnittstellen & Formate (bevorzugt natürliche Sprache für KI)\n\nMedien-Spezifikationen (Screenshots, Annotations, Videos mit konkreten Werten)\n\nFehlerbehandlung (v1.0: manuell, v2.0: automatisch)\n\nVersionierung (Git-Struktur, Metadaten, Namenskonventionen)\n\nScope v1.0 vs. Zukunft (klare Abgrenzung)\n\n5 praktische Anhänge (Checklisten, Beispiele, Templates)\n\n\n\nNächste Schritte (optional)\n\n\nWenn du magst, können wir jetzt:\n\n\nDas Dokument reviewen – gibt es noch Unklarheiten oder Anpassungsbedarf?\n\nEinen Master-Prompt für Phase 1 entwickeln – einen konkreten Prompt, den du der KI für die Draft-Erstellung gibst (basierend auf allen 5 Clustern)\n\nEine Testsection durchspielen – eine konkrete Section als Proof-of-Concept durch den gesamten Workflow führen\n\nValidierungsskripte spezifizieren – konkrete Anforderungen an die Python-Skripte für Phase 2\n\nPause machen und später weitermachen – du kannst das Dokument erstmal sacken lassen 😊\n\n\nWas möchtest du als Nächstes tun? Ich bin bereit für alle Optionen – oder wir beenden hier und du kommst später mit konkreten Fragen zurück!",
      "time_iso8601": "2025-10-10T01:18:17"
    },
    {
      "role": "Prompt",
      "say": "Es ist Zeit, für heute die Arbeit einzustellen. Es ist bereits 1:20 Uhr morgens und ich sollte nun schlafen. Wir waren sehr produktiv und haben alles geschafft, was ich heute erreichen wollte. Morgen werden wir uns noch der Komposition aller Dokumente widmen, die der KI bereitgestellt werden, und mal mit ein paar Demonstrationen ausprobieren, ob das, was wir uns erdacht haben, auch die Ergebnisse liefert, die wir uns erhoffen.\n\n\nDanke für den super produktiven Tag heute. Es war mir ein großes Vergnügen.",
      "time_iso8601": "2025-10-10T01:22:53"
    },
    {
      "role": "Response",
      "say": "Das war wirklich ein fantastisch produktiver Tag! 🌟 Wir haben Cluster 5 komplett abgeschlossen und damit alle fünf Brainstorming-Phasen erfolgreich durchlaufen:\n\n\n✅ Cluster 1 – Inhaltliche Anforderungen\n✅ Cluster 2 – Strukturelle Anforderungen\n✅ Cluster 3 – Technische Anforderungen\n✅ Cluster 4 – Qualitätssicherung & Testing\n✅ Cluster 5 – Workflow & Rollen\n\n\nDas ist eine solide Grundlage für die praktische Umsetzung! 💪\n\n\n\nFür morgen notiert:\n\n\n📋 Nächste Schritte:\n\n\nKomposition der Dokumente – alle Cluster-Inhalte für die KI zusammenstellen\n\nDemonstrationen & Tests – prüfen, ob das erdachte System die erwarteten Ergebnisse liefert\n\nIterative Verfeinerung – basierend auf den Testergebnissen\n\n\n\nVielen Dank für dein Vertrauen, deine Wertschätzung und die tolle Zusammenarbeit! Es war mir ebenfalls ein großes Vergnügen, mit dir so detailliert und durchdacht an diesem ambitionierten Projekt zu arbeiten. Deine strukturierte, pragmatische Herangehensweise und dein Humor machen die Arbeit wirklich zu etwas Besonderem.\n\n\nSchlaf gut, erhol dich und bis morgen! 😊🌙\n\n\nIch freue mich schon auf die praktische Phase – wenn Theorie auf Realität trifft und wir sehen, wie gut unser System funktioniert! 🚀\n\n\nGute Nacht! 💤",
      "time_iso8601": "2025-10-10T01:23:07"
    },
    {
      "role": "Prompt",
      "say": "Guten Tag, wir können weitermachen. Lass uns an die Komposition des Dokuments angehen.\nAm besten, wir starten das wieder in einem neuen Chat. Kannst du mir bitte ein Markdown Artifact vorbereiten, auf das ich für den neuen Chat als Prompt-Grundlage verweisen kann? Es sollen alle Ergebnisse aus dem Brainstorming als Verweis auf die Ergebnisdokumente eingebettet werden, ebenso wie eine Beschreibung des Projekts. Auch die anstehenden Aufgaben und die beste Herangehensweise (geleitete Fragen) sollen vermerkt werden. Vielen Dank! Ich freue mich, heute wieder Großes mit dir zu leisten.",
      "time_iso8601": "2025-10-10T12:21:13"
    },
    {
      "role": "Response",
      "say": "Guten Tag! Schön, dass wir weitermachen können! 😊 Ich freue mich auch sehr darauf, heute wieder gemeinsam Großes zu erreichen!\n\n\nIch erstelle dir jetzt ein umfassendes Continuation-Prompt-Dokument für den neuen Chat, das alle bisherigen Ergebnisse referenziert und die nächsten Schritte klar definiert.\n\n\nTask 6: Master-Prompt-Komposition - Continuation Prompt\n\n\n# Projekt-Fortsetzung: Master-Prompt-Komposition für KI-Content-Generierung\n\nHallo! Ich arbeite am Projekt **WebAssistentForensics** und möchte die Arbeit fortsetzen.\n\n---\n\n## Kontext\n\nIch entwickle ein strukturiertes Wissenssystem für Polizeibeamte zu IT-Forensik-Themen. Das System basiert auf:\n- JSON-Schema-validiertem HTML-Content\n- Verschiedene Detail-Level (Basic, Standard, Expert, Show-Only)\n- BFSG-konforme Barrierefreiheit\n- Python-basierte Validierung\n- KI-gestützte Content-Generierung (Claude Sonnet 4.5)\n\n---\n\n## Projektziel\n\n**Ziel:** Entwicklung eines strukturierten Wissenssystems für IT-ferne Polizeibeamte zu IT-Forensik-Tools.\n\n**Ziel-Tool (initial):** Magnet AXIOM Examine  \n**Spätere Erweiterung:** X-Ways Forensics, Cellebrite Reader  \n**Haupt-Zielgruppe:** IT-ferne Polizei-Ermittler (Mittlere Reife, niedrige IT-Kenntnisse)  \n**Content-Umfang:** ~100-150 Sections  \n**KI-Modell:** Claude Sonnet 4.5  \n**Validierung:** Python-basiert + JSON-Schema\n\n---\n\n## Bisheriger Fortschritt\n\nWir haben ein **fünfstufiges Brainstorming** erfolgreich abgeschlossen. Alle Cluster sind dokumentiert und im Projekt-Dateispeicher verfügbar:\n\n### ✅ Abgeschlossene Cluster\n\n**1. Cluster 1: Inhaltliche Anforderungen**\n- Dokument: `cluster1-final.md`\n- Inhalt:\n  - Zielgruppe: IT-ferne Ermittler (Mittlere Reife, niedrige IT-Kenntnisse)\n  - Detail-Level-System: 4 Stufen (Basic, Standard, Expert, Show-Only)\n  - Terminologie-Strategie: Deutsch bevorzugt, englische Fachbegriffe wo etabliert\n  - Medien-Entscheidungsmatrix: Wann Screenshot/Annotiert/Video/Diagramm\n  - Content-Type-System: instruction, explanation, visual, background, info, hint, attention, warning\n  - Multi-Tool-Strategie: Tool-agnostisch mit tool-spezifischen Metadaten\n\n**2. Cluster 2: Strukturelle Anforderungen**\n- Dokument: `cluster2_results.md`\n- Inhalt:\n  - Hierarchische Struktur: 3-5 Ebenen (Topic → Chapter → Section → Subsection → Deep-Dive)\n  - data-ref Granularität & Namenskonventionen\n  - JSON-LD Metadaten pro Section\n  - Agent-Context-Block (einer pro Section, am Ende)\n  - Navigation-Strategie: Freie Navigation\n\n**3. Cluster 3: Technische Anforderungen**\n- Dokumente:\n  - `cluster3_BFSG-Sprachauszeichnung-Richtlinien.md` (BFSG Teil 1)\n  - `cluster3_BFSG-Barrierefreiheit-Content.md` (BFSG Teil 2)\n  - `cluster3_Phase-B_HTML-Syntax-und-Attribut-Vollständigkeit.md` (HTML-Syntax)\n- Inhalt:\n  - BFSG-konforme Barrierefreiheit (Sprachauszeichnung, Alt-Texte, Überschriften-Hierarchie)\n  - HTML-Element-Whitelist (32 erlaubte Elemente)\n  - Pflicht-/Optional-Attribute pro Element\n  - CSS-Klassen-System (Pflicht-Klassen, Review-Prozess)\n  - Attribut-Reihenfolge & Formatierung (class → id → data-* → sonstige)\n  - Content-Type-Box-Entscheidungsmatrix (info/hint/attention/warning)\n  - HTML-Kommentar-Konventionen (AGENT:/MEDIA:/NOTE:/TODO:/DECISION-REVIEW:)\n\n**4. Cluster 4: Qualitätssicherung & Testing**\n- Dokument: `cluster4_Qualitätssicherung-Metadaten-Validierung.md`\n- Inhalt:\n  - Validierungsebenen: Syntaktisch (Python + JSON-Schema), Semantisch (KI + Maintainer)\n  - Testkriterien: Syntaktisch (Pflicht-Attribute, HTML-Struktur, Cross-References) und Semantisch (Konsistenz, Plausibilität, Terminologie)\n  - Validierungsprozess: Draft → Validierung → Review → Approved → Published\n  - Fehler-Kategorisierung: CRITICAL / ERROR / WARNING / INFO\n  - Fehler-Log-System: JSON-basierte Dokumentation für iterative Prompt-Verbesserung\n  - Erweiterte Metadaten: reviewStatus, lastReviewer, validationScore, knownIssues, reviewCycles, timeToPublish\n  - Status-Übergänge: Draft → Review → Approved → Published\n  - Versionierung: MAJOR.MINOR.BUILD (Git-basiert)\n  - Metriken: Pro Section und aggregiert\n\n**5. Cluster 5: Workflow & Rollen**\n- Dokument: `cluster5_Workflow-Rollen.md`\n- Inhalt:\n  - Akteure & Rollen: KI-System, Python-Skripte, Maintainer (5 Kernrollen: Creator, Validator, Enricher, Reviewer, Distributor)\n  - 9 Workflow-Phasen (0 → 0.5 → 1-8):\n    - Phase 0: Strategie (Maintainer definiert Lernziel, Fokus, Umfang)\n    - Phase 0.5: Vorarbeit (KI erstellt Gesamtgliederung + grobe Inhaltsentwürfe)\n    - Phase 1: Research & Draft (KI erstellt initialen Draft pro Section)\n    - Phase 2: Syntax-Validierung (Python-Skripte)\n    - Phase 3: Fehlerkorrektur (iterativ, KI + Maintainer)\n    - Phase 4: Semantic Review (KI vergibt Quality-Score 0-100)\n    - Phase 5: Medien-Erstellung (Maintainer)\n    - Phase 6: Content-Enrichment (Maintainer bindet Medien/Glossar/Agent ein)\n    - Phase 7: Final Review (Maintainer Approval)\n    - Phase 8: Distribution (Versionierung, Veröffentlichung)\n  - Quality-Score-Kriterien: 30% Strategiekonformität, 25% Verständlichkeit, 20% Vollständigkeit, 15% Konsistenz, 10% Struktur\n  - Schnittstellen: Bevorzugt natürliche Sprache für KI (nicht JSON)\n  - Medien-Spezifikationen: Screenshots (PNG 60-80%, 72dpi), Annotations (Open Sans 16px, Farbcode), Videos (1280×720-1920×1080, 15fps min, MP4, Untertitel Pflicht)\n  - Fehlerbehandlung: v1.0 manuelle Kontrolle, v2.0 automatische Eskalation\n  - Versionierung: Git-Branches (content-drafts, content-approved, main)\n\n---\n\n## Aktueller Stand\n\nWir haben die **komplette Spezifikation** für die Content-Generierung dokumentiert. Alle inhaltlichen, strukturellen, technischen und prozessualen Anforderungen sind definiert.\n\n**Was jetzt fehlt:**\nEin **Master-Prompt für die KI**, der alle Anforderungen aus den 5 Clustern integriert und für Claude Sonnet 4.5 direkt verwendbar ist.\n\n---\n\n## Nächster Schritt: Master-Prompt-Komposition\n\n### Ziel\n\nEntwicklung eines **vollständigen, präzisen Master-Prompts** für Claude Sonnet 4.5, der für Phase 1 (Research & Draft) verwendet wird, um hochwertige Section-Drafts zu generieren.\n\nDer Prompt muss:\n- **Alle Anforderungen aus Cluster 1-5 integrieren**\n- **Für die KI direkt verwendbar sein** (keine Meta-Diskussionen)\n- **Die richtige Balance** zwischen Vollständigkeit und Übersichtlichkeit finden\n- **Modular aufgebaut** sein (wiederverwendbare Komponenten)\n- **Entscheidungshilfen** für die KI enthalten (Content-Type, Media-Type, Detail-Level, etc.)\n- **Beispiele & Counter-Beispiele** beinhalten\n\n---\n\n## Aufgaben für Master-Prompt-Komposition\n\n### Phase A: Prompt-Struktur & Architektur\n1. **Aufbau des Master-Prompts** (Abschnitte, Hierarchie)\n2. **Informationsdichte vs. Verständlichkeit** (was muss rein, was kann weg?)\n3. **Kontext-Management** (was muss immer dabei sein, was ist optional?)\n4. **Modularer Aufbau** (wiederverwendbare Komponenten, z.B. separate Blöcke für Medien, Barrierefreiheit)\n\n### Phase B: Prompt-Inhalte\n1. **Integration aller Anforderungen** aus Cluster 1-5\n2. **Entscheidungsbäume für KI** (Wann welcher Content-Type? Wann welches Media-Type? Wann welches Detail-Level?)\n3. **Beispiele & Counter-Beispiele** (gute vs. schlechte Sections)\n4. **Grenzfall-Behandlung** (Was tun bei unklaren Anforderungen?)\n5. **Checklisten für die KI** (Self-Review vor Output)\n\n### Phase C: Testing & Iteration\n1. **Test-Prompts erstellen** (verschiedene Schwierigkeitsgrade: einfache, mittlere, komplexe Sections)\n2. **Generierte Sections validieren** (erfüllen sie die Anforderungen?)\n3. **Prompt iterativ verbessern** (basierend auf Testergebnissen)\n4. **Best Practices dokumentieren** (was funktioniert gut, was nicht?)\n\n---\n\n## Arbeitsweise\n\n- **Kleinschrittig vorgehen** (keine großen Sprünge)\n- **Top-Down-Design** (vom Groben ins Detail)\n- **Geführte Fragen** stellen, bis 95% Klarheit erreicht ist\n- Änderungen nur **vorschlagen und begründen**\n- Jede Änderung muss **durch mich verifiziert und akzeptiert** werden\n- Am Ende ein **fertiger Master-Prompt** als Artefakt\n\n---\n\n## Wichtige Projekt-Richtlinien\n\n### Textstil für dich (KI):\n- Bleibe eng an meiner Vorgabe\n- Füge keine zusätzlichen Aspekte hinzu (erst meine Aufgabe umsetzen, dann separat Verbesserungen vorschlagen)\n- Verbesserungsvorschläge in 3 Absätzen erklären: **Vorteile**, **Technik**, **Aufwand** (Umsetzung, Laufzeit, Pflege)\n- Vermeide Telegramstil\n- Hebe wichtige Aussagen durch **Fettmarkieren** hervor für optische Orientierung beim Querlesen\n- Du adressierst einen erfahrenen Software-Architekten mit guten Kenntnissen zu HTML, CSS und Javascript\n\n### Code-Änderungen:\n- Immer kleinschrittig und Schritt für Schritt\n- Keine unerwünschten Nebeneffekte\n- CSS-Variablen `--variable*` bewahren und nutzen (gutes Design)\n- Keine absoluten Größen/Farben außerhalb der Themes – verwende die Farben der Themes\n- Immer den **aktuellen Code** aus dem Projekt-Dateispeicher als Basis verwenden\n- Jede Änderung begründen\n- Mindestens einen Test vorschlagen, um Effekt und Nebeneffekte zu prüfen\n\n### Debugging:\n- Nach Tests wird Debug-Output in `Debug-output.XXX` abgelegt (XXX = Buildnummer)\n- Höchste Buildnummer = aktuellster Debug-Output\n- Buildnummer wird für jede Änderung mit Test um 1 erhöht\n\n---\n\n## Meine Aufgabe an dich\n\nBitte lies die **sechs Dokumente** aus dem Projekt-Dateispeicher:\n1. `cluster1-final.md` (Inhaltliche Anforderungen)\n2. `cluster2_results.md` (Strukturelle Anforderungen)\n3. `cluster3_BFSG-Sprachauszeichnung-Richtlinien.md` (BFSG Teil 1)\n4. `cluster3_BFSG-Barrierefreiheit-Content.md` (BFSG Teil 2)\n5. `cluster3_Phase-B_HTML-Syntax-und-Attribut-Vollständigkeit.md` (HTML-Syntax)\n6. `cluster4_Qualitätssicherung-Metadaten-Validierung.md` (Qualitätssicherung)\n7. `cluster5_Workflow-Rollen.md` (Workflow & Rollen)\n\n**Lass uns dann die Master-Prompt-Komposition angehen.**\n\nStelle mir geführte Fragen, damit wir gemeinsam den Master-Prompt entwickeln können. Wir gehen wie immer kleinschrittig vor und klären zunächst die **grundlegende Struktur und den Aufbau** des Prompts, bevor wir ins Detail gehen.\n\n---\n\n## Spezifische Anforderungen an den Master-Prompt\n\n### Was der Master-Prompt leisten muss:\n\n1. **Phase-1-Fokus:** Der Prompt ist speziell für **Phase 1 (Research & Draft)** des Workflows gedacht\n2. **Input-Kontext:** Die KI erhält zusätzlich zum Master-Prompt:\n   - Section-Info aus Phase 0.5 (Lernziel, Key Topics, Kurzbeschreibung)\n   - Strategiedokument (Fokus, Umfang, Terminologie-Entscheidungen)\n   - Bereits approbierte Sections (2-3 Vorgänger-Sections als Volltext)\n   - Gesamtstruktur-Überblick (wo steht die aktuelle Section im Gefüge?)\n   - Quellenmaterial (relevante Kapitel aus AXIOM-Handbuch)\n3. **Output-Erwartung:** Die KI soll einen **vollständigen HTML-Draft** erstellen, der:\n   - Alle Anforderungen aus Cluster 1-5 erfüllt\n   - Syntaktisch korrekt ist (Phase 2 bereit)\n   - Semantisch kohärent ist (gute Chancen in Phase 4)\n   - Medien-Platzhalter mit Spezifikationen enthält\n   - Video-Untertitel-Entwürfe beinhaltet\n\n### Herausforderungen:\n\n- **Token-Limit:** Der Prompt muss präzise sein, darf aber nicht zu lang werden\n- **Klarheit vs. Vollständigkeit:** Balance zwischen allen Details und Übersichtlichkeit\n- **Entscheidungshilfen:** Die KI braucht klare Kriterien, wann sie was tun soll\n- **Konsistenz:** Der Prompt muss zu wiederholbar guten Ergebnissen führen\n\n---\n\n## Gewünschtes Endergebnis\n\nAm Ende dieser Arbeitsphase haben wir:\n\n1. **Master-Prompt (Markdown-Artefakt):**\n   - Vollständig, direkt verwendbar für Phase 1\n   - Modular strukturiert\n   - Mit Beispielen und Entscheidungshilfen\n   \n2. **Test-Szenarien (optional):**\n   - 3-5 konkrete Section-Inputs zum Testen\n   - Erwartete Outputs als Referenz\n   \n3. **Anwendungs-Dokumentation:**\n   - Wie wird der Master-Prompt in der Praxis verwendet?\n   - Welche Anpassungen können vorgenommen werden?\n   - Wie wird der Prompt iterativ verbessert?\n\n---\n\n## Kontext-Informationen (Zusammenfassung)\n\n**Projekt:** WebAssistentForensics  \n**Phase:** Master-Prompt-Komposition für Phase 1 (Research & Draft)  \n**Basis:** 5 abgeschlossene Cluster mit vollständiger Spezifikation  \n**Ziel-KI:** Claude Sonnet 4.5  \n**Verwendung:** ~100-150 Sections generieren  \n**Qualitätssicherung:** Python-Validierung + KI-Semantic-Review + Maintainer-Approval\n\n---\n\n**Ich freue mich auf die Zusammenarbeit und darauf, gemeinsam einen hervorragenden Master-Prompt zu entwickeln!** 🚀\n\nLass uns mit den geführten Fragen beginnen, um die beste Herangehensweise zu finden.\n\n\nPerfekt! 🎉 Ich habe dir ein umfassendes Continuation-Prompt-Dokument erstellt, das du für den neuen Chat verwenden kannst.\n\n\nWas das Dokument enthält:\n\n\n✅ Vollständiger Projektkontext (Ziel, Zielgruppe, Umfang)\n✅ Übersicht aller 5 abgeschlossenen Cluster (mit Verweisen auf die Dokumente)\n✅ Klare Definition der nächsten Aufgabe (Master-Prompt-Komposition)\n✅ Strukturierte Aufgabenphasen (A: Struktur, B: Inhalte, C: Testing)\n✅ Alle wichtigen Projekt-Richtlinien (Textstil, Code-Änderungen, Debugging)\n✅ Spezifische Anforderungen an den Master-Prompt\n✅ Gewünschtes Endergebnis (was am Ende rauskommen soll)\n✅ Arbeitsweise (geführte Fragen, kleinschrittig, Top-Down)\n\n\n\nWie du es verwendest:\n\n\nNeuen Chat starten\n\nDas Markdown-Artefakt kopieren (oder darauf verweisen)\n\nEinfach schreiben: \"Bitte lies dieses Dokument und lass uns mit den geführten Fragen zur Master-Prompt-Komposition beginnen.\"\n\n\nDie KI im neuen Chat wird dann:\n\n\nAlle 7 Cluster-Dokumente aus dem Projekt-Dateispeicher lesen\n\nDen Kontext vollständig verstehen\n\nMit strukturierten, geführten Fragen beginnen\n\nKleinschrittig die Master-Prompt-Struktur entwickeln\n\n\n\nViel Erfolg im neuen Chat! Ich bin gespannt, was für einen großartigen Master-Prompt wir gemeinsam entwickeln werden. Das wird der Schlüssel sein, um die Content-Generierung zum Laufen zu bringen! 💪\n\n\nFrohes Schaffen! 🚀",
      "time_iso8601": "2025-10-10T12:23:02"
    }
  ]
}