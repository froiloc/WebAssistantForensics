# Brainstorming Prompt-Erstellung (5!5)

**Created:** 10/9/2025 21:16:20  
**Updated:** 10/10/2025 12:23:02  
**Exported:** 10/11/2025 4:04:16  
**Link:** [https://claude.ai/chat/b6343366-95f9-47f2-8882-a7c9c90af5c0](https://claude.ai/chat/b6343366-95f9-47f2-8882-a7c9c90af5c0)  

## Prompt:
9.10.2025, 21:16:21

Bitte lies `task3-Continuation-Prompt-fÃ¼r-neuen-Chat.md` aus dem Projekt-Dateispeicher und folge den darin stehenden Anmerkungen und Anweisungen.
Ich freue mich auf die weitere Zusammenarbeit mit dir. Es macht mir viel SpaÃŸ und ich sehe einen guten Fortschritt.



## Response:
9.10.2025, 21:16:41

Ich freue mich sehr Ã¼ber dein positives Feedback und die gute Zusammenarbeit! Lass mich zunÃ¤chst die relevante Datei aus dem Projekt-Dateispeicher lesen, um den aktuellen Stand und die spezifischen Anweisungen zu verstehen.

**project_knowledge_search**

*Request*

````javascript
{
  "query": "task3-Continuation-Prompt-fÃ¼r-neuen-Chat.md"
}
````

*Response*

````plaintext
task2.md - Continuation Prompt fÃ¼r neuen Chat.md
âœ… Inhaltliche Anforderungen (Cluster 1)
2. âœ… Strukturelle Anforderungen (Cluster 2)
3. âœ… Technische Anforderungen (Cluster 3)
4. â³ Prompt-Entwicklung fÃ¼r KI (Cluster 4) **â† JETZT DRAN**
5. ğŸ”µ QualitÃ¤tssicherung & Testing (Cluster 5)
6. ğŸ”µ Workflow & Rollen (Cluster 6)

---

## Aktueller Stand

Wir haben die **komplette Spezifikation** fÃ¼r die Content-Generierung dokumentiert:

### Was ist fertig:

**Inhaltlich (Cluster 1):**
- Zielgruppe: IT-ferne Ermittler (Mittlere Reife, niedrige IT-Kenntnisse)
- Detail-Level-System: 4 Stufen (Schnell, Standard, Detailliert, Show-Only)
- Terminologie-Strategie: Deutsch bevorzugt, englische Fachbegriffe wo etabliert
- Medien-Entscheidungsmatrix: Wann Screenshot/Annotiert/Video/Diagramm
- Content-Type-System: instruction, explanation, visual, background, info, hint, attention, warning
- Multi-Tool-Strategie: Tool-agnostisch mit tool-spezifischen Metadaten

**Strukturell (Cluster 2):**
- Hierarchische Struktur: 3-5 Ebenen (Topic â†’ Chapter â†’ Section â†’ Subsection â†’ Deep-Dive)
- data-ref GranularitÃ¤t & Namenskonventionen
- JSON-LD Metadaten pro Section
- Agent-Context-Block (einer pro Section, am Ende)
- Navigation-Strategie: Freie Navigation

**Technisch (Cluster 3):**
- BFSG-konforme Barrierefreiheit (Sprachauszeichnung, Alt-Texte, Ãœberschriften-Hierarchie)
- HTML-Element-Whitelist (32 erlaubte Elemente)
- Pflicht-/Optional-Attribute pro Element
- CSS-Klassen-System (Pflicht-Klassen, Review-Prozess)
- Attribut-Reihenfolge & Formatierung (class â†’ id â†’ data-* â†’ sonstige)
- Content-Type-Box-Entscheidungsmatrix (info/hint/attention/warning)
- HTML-Kommentar-Konventionen (AGENT:/MEDIA:/NOTE:/TODO:/DECISION-REVIEW:)

---

## NÃ¤chster Schritt: Cluster 4 - Prompt-Entwicklung

### Ziel

Entwicklung eines **vollstÃ¤ndigen, prÃ¤zisen Master-Prompts** fÃ¼r Claude Sonnet 4.5 zur Generierung von hochwertigem Content fÃ¼r ~100-150 Sections.

Der Prompt muss **alle Anforderungen aus Cluster 1-3 integrieren** und fÃ¼r die KI **direkt verwendbar** sein.

### Aufgaben fÃ¼r Cluster 4

**Phase A: Prompt-Struktur & Architektur**
1. Aufbau des Master-Prompts (Abschnitte, Hierarchie)
2. Informationsdichte vs. VerstÃ¤ndlichkeit
3. Kontext-Management (was muss immer dabei sein, was ist optional?)
4. Modularer Aufbau (wiederverwendbare Komponenten)

**Phase B: Prompt-Inhalte**
1. Integration aller Anforderungen aus Cluster 1-3
2. EntscheidungsbÃ¤ume fÃ¼r KI (Content-Type, Media-Type, etc.)
3. Beispiele & Counter-Beispiele
4. Grenzfall-Behandlung

**Phase C: Testing & Iteration**
1. Test-Prompts erstellen (verschiedene Schwierigkeitsgrade)
2. Generierte Sections validieren
3. Prompt iterativ verbessern
4.
````

````plaintext
task3-Continuation-Prompt-fÃ¼r-neuen-Chat.md
- Section-Hierarchie und Navigation
   - data-ref Vergabelogik

3. Ã¢Å“â€¦ **Technische Anforderungen**
   - Medien-Anweisungen (Screenshots, annotierte Bilder, Videos)
   - Agent-Integration (Context-Blocks, Trigger-Points)
   - Barrierefreiheit (BFSG-KonformitÃƒÂ¤t)
   - HTML-Syntax und Attribut-VollstÃƒÂ¤ndigkeit

4. Ã¢Å“â€¦ **QualitÃƒÂ¤tssicherung & Testing**
   - Testkriterien fÃƒÂ¼r generierte Sections
   - Validierungsprozess (syntaktisch + semantisch)
   - Metadaten (Quellen, Versionen, Erstellungsdatum)
   - Iterationslogik (wann ist eine Section "fertig"?)

5. Ã¢ÂÂ³ **Workflow & Rollen** **Ã¢â€ Â JETZT DRAN**
   - Arbeitsschritte der KI (Research Ã¢â€ â€™ Draft Ã¢â€ â€™ Detailing Ã¢â€ â€™ Review Ã¢â€ â€™ Syntax-Check)
   - Rollendefinitionen fÃƒÂ¼r verschiedene Phasen
   - Schnittstellendefinition zwischen den Phasen
   - Fehlerbehandlung und Feedback-Loops

---

## Bisheriger Fortschritt

**Abgeschlossen:**

- Ã¢Å“â€¦ **Cluster 1:** Inhaltliche Anforderungen (siehe `cluster1-final.md`)
- Ã¢Å“â€¦ **Cluster 2:** Strukturelle Anforderungen (siehe `cluster2_results.md`)
- Ã¢Å“â€¦ **Cluster 3:** Technische Anforderungen
  - Ã¢Å“â€¦ **Teil A - Barrierefreiheit (BFSG):**
    - Sprachauszeichnung (`lang`-Attribute): `cluster3_BFSG-Sprachauszeichnung-Richtlinien.md`
    - Alt-Texte & ÃƒÅ“berschriften-Hierarchie: `cluster3_BFSG-Barrierefreiheit-Content.md`
  - Ã¢Å“â€¦ **Teil B - HTML-Syntax & Attribut-VollstÃƒÂ¤ndigkeit:**
    - VollstÃƒÂ¤ndige HTML-Element-Spezifikation: `cluster3_Phase-B_HTML-Syntax-und-Attribut-VollstÃƒÂ¤ndigkeit.md`
- Ã¢Å“â€¦ **Cluster 4:** QualitÃƒÂ¤tssicherung & Testing (siehe `cluster4_QualitÃƒÂ¤tssicherung-Metadaten-Validierung.md`)

---

## Aktueller Stand

Wir haben die **komplette Spezifikation** fÃƒÂ¼r die Content-Generierung dokumentiert:

### Was ist fertig:

**Inhaltlich (Cluster 1):**
- Zielgruppe: IT-ferne Ermittler (Mittlere Reife, niedrige IT-Kenntnisse)
- Detail-Level-System: 4 Stufen (Schnell, Standard, Detailliert, Show-Only)
- Terminologie-Strategie: Deutsch bevorzu
````

````plaintext
task3-Continuation-Prompt-fÃ¼r-neuen-Chat.md
Cluster 5 fokussiert sich auf das **"Wie"** der Umsetzung:
- Welche Schritte durchlÃƒÂ¤uft die KI?
- Wer ist wofÃƒÂ¼r verantwortlich?
- Wie kommunizieren die verschiedenen Akteure/Systeme?
- Was passiert bei Fehlern?

---

### Aufgaben fÃƒÂ¼r Cluster 5

**1. Arbeitsschritte der KI:**
- Detaillierte Phasen: Research Ã¢â€ â€™ Draft Ã¢â€ â€™ Detailing Ã¢â€ â€™ Review Ã¢â€ â€™ Syntax-Check
- Was macht die KI in jeder Phase konkret?
- Welche Inputs/Outputs hat jede Phase?
- Welche Tools/APIs nutzt die KI?
- ZeitabschÃƒÂ¤tzungen pro Phase

**2. Rollendefinitionen:**
- **KI-Generator:** Erstellt initiale Sections (Draft)
- **KI-Reviewer:** Semantische VorprÃƒÂ¼fung (Konsistenz, PlausibilitÃƒÂ¤t, etc.)
- **Maintainer:** Finale fachliche PrÃƒÂ¼fung, Medien-Erstellung, Approval
- **Validator:** Python-Skripte fÃƒÂ¼r syntaktische PrÃƒÂ¼fung
- Weitere Rollen (falls notwendig)

**3. Schnittstellendefinition:**
- Input/Output zwischen Phasen
- Datenformate (JSON, HTML, Reports)
- ÃƒÅ“bergabepunkte und Trigger
- Kommunikationsprotokolle

**4. Fehlerbehandlung & Feedback-Loops:**
- Was passiert bei syntaktischen Fehlern? (Automatische Korrektur durch KI)
- Was passiert bei semantischen Problemen? (Feedback an KI, erneute Generierung)
- Was passiert bei Reject durch Maintainer? (Dokumentation, Prompt-Verbesserung)
- Eskalationspfade bei wiederholten Fehlern

**5. Tooling & Automation:**
- Welche Tools unterstÃƒÂ¼tzen den Workflow?
- Kann der Prozess (teilweise) automatisiert werden?
- Welche manuellen Schritte sind unvermeidlich?
- CI/CD-Integration mÃƒÂ¶glich?

---

## Arbeitsweise

- **Kleinschrittig vorgehen** (keine groÃƒÅ¸en SprÃƒÂ¼nge)
- **Top-Down-Design** (vom Groben ins Detail)
- **GefÃƒÂ¼hrte Fragen** stellen, bis 95% Klarheit erreicht ist
- Ãƒâ€nderungen nur **vorschlagen und begrÃƒÂ¼nden**
- Jede Ãƒâ€nderung muss **durch mich verifiziert und akzeptiert** werden
- Am Ende ein **Ergebnisdokument** erstellen (analog zu Cluster 1-4)

---

## Wichtige Projekt-Richtlinien

### Textstil fÃƒÂ¼r dich (KI):
- Bleibe eng an meiner Vorgabe
- FÃƒÂ¼ge keine zusÃƒÂ¤tzlichen Aspekte hinzu
- Erst meine Aufgabe umsetzen, dann separat Verbesserungen vorschlagen
- VerbesserungsvorschlÃƒÂ¤ge in 3 AbsÃƒÂ¤tzen erklÃƒÂ¤ren: Vorteile, Technik, Aufwand
- Vermeide Telegramstil
- Hebe wichtige Aussagen durch **Fettmarkieren** hervor

### Code-Ãƒâ€nderungen:
- Immer kleinschrittig und Schritt fÃƒÂ¼r Schritt
- Keine unerwÃƒÂ¼nschten Nebeneffekte
- CSS-Variablen `--variable*` bewahren und nutzen
- Keine absoluten GrÃƒÂ¶ÃƒÅ¸en/Farben auÃƒÅ¸erhalb der Themes
- Immer den **aktuellen Code** aus dem Projekt-Dateispeicher als Basis verwenden
- Jede Ãƒâ€nderung begrÃƒÂ¼nden
- Mindestens einen Test vorschlagen

### Debugging des Webfrontends (index.html +CSS +JS):
- Nach Tests wird Debug-Output in `Debug-output.XXX` abgelegt (XXX = Buildnummer)
- HÃƒÂ¶chste Buildnummer = aktuellster Debug-Output

---

## Meine Frage

Bitte lies die **sechs Dokumente** im Projekt-Dateispeicher:
1. `cluster1-final.md` (Inhaltliche Anforderungen)
2.
````

````plaintext
task2.md - Continuation Prompt fÃ¼r neuen Chat.md
Aufbau des Master-Prompts (Abschnitte, Hierarchie)
2. Informationsdichte vs. VerstÃ¤ndlichkeit
3. Kontext-Management (was muss immer dabei sein, was ist optional?)
4. Modularer Aufbau (wiederverwendbare Komponenten)

**Phase B: Prompt-Inhalte**
1. Integration aller Anforderungen aus Cluster 1-3
2. EntscheidungsbÃ¤ume fÃ¼r KI (Content-Type, Media-Type, etc.)
3. Beispiele & Counter-Beispiele
4. Grenzfall-Behandlung

**Phase C: Testing & Iteration**
1. Test-Prompts erstellen (verschiedene Schwierigkeitsgrade)
2. Generierte Sections validieren
3. Prompt iterativ verbessern
4. Best Practices dokumentieren

---

## Arbeitsweise

- **Kleinschrittig vorgehen** (keine groÃŸen SprÃ¼nge)
- **Top-Down-Design** (vom Groben ins Detail)
- **GefÃ¼hrte Fragen** stellen, bis 95% Klarheit erreicht ist
- Ã„nderungen nur **vorschlagen und begrÃ¼nden**
- Jede Ã„nderung muss **durch mich verifiziert und akzeptiert** werden
- Am Ende ein **Ergebnisdokument** erstellen (analog zu Cluster 1-3)

---

## Wichtige Projekt-Richtlinien

### Textstil fÃ¼r dich (KI):
- Bleibe eng an meiner Vorgabe
- FÃ¼ge keine zusÃ¤tzlichen Aspekte hinzu
- Erst meine Aufgabe umsetzen, dann separat Verbesserungen vorschlagen
- VerbesserungsvorschlÃ¤ge in 3 AbsÃ¤tzen erklÃ¤ren: Vorteile, Technik, Aufwand
- Vermeide Telegramstil
- Hebe wichtige Aussagen durch **Fettmarkieren** hervor

### Code-Ã„nderungen:
- Immer kleinschrittig und Schritt fÃ¼r Schritt
- Keine unerwÃ¼nschten Nebeneffekte
- CSS-Variablen `--variable*` bewahren und nutzen
- Keine absoluten GrÃ¶ÃŸen/Farben auÃŸerhalb der Themes
- Immer den **aktuellen Code** aus dem Projekt-Dateispeicher als Basis verwenden
- Jede Ã„nderung begrÃ¼nden
- Mindestens einen Test vorschlagen

### Debugging:
- Nach Tests wird Debug-Output in `Debug-output.XXX` abgelegt (XXX = Buildnummer)
- HÃ¶chste Buildnummer = aktuellster Debug-Output

---

## Meine Frage

Bitte lies die fÃ¼nf Dokumente im Projekt-Dateispeicher:
1. `cluster1-final.md` (Inhaltliche Anforderungen)
2. `cluster2_results.md` (Strukturelle Anforderungen)
3. `cluster3_BFSG-Sprachauszeichnung-Richtlinien.md` (BFSG Teil 1)
4. `cluster3_BFSG-Barrierefreiheit-Content.md` (BFSG Teil 2)
5. `cluster3_Phase-B_HTML-Syntax-und-Attribut-VollstÃ¤ndigkeit.md` (HTML-Syntax)

**Lass uns dann Cluster 4: Prompt-Entwicklung angehen.**

Stelle mir gefÃ¼hrte Fragen, damit wir gemeinsam den Master-Prompt entwickeln kÃ¶nnen. Wir gehen wie immer kleinschrittig vor und klÃ¤ren zunÃ¤chst die grundlegende Struktur, bevor wir ins Detail gehen.

---

## Kontext-Informationen

**Projekt:** WebAssistentForensics  
**Ziel-Tool (initial):** Magnet AXIOM Examine  
**SpÃ¤tere Erweiterung:** X-Ways Forensics, Cellebrite Reader  
**Haupt-Zielgruppe:** IT-ferne Polizei-Ermittler  
**Content-Umfang:** ~100-150 Sections  
**KI-Modell:** Claude Sonnet 4.5  
**Validierung:** Python-basiert + JSON-Schema  

---

**Ich freue mich auf die Zusammenarbeit!**
````

````plaintext
task3-Continuation-Prompt-fÃ¼r-neuen-Chat.md
gt, englische Fachbegriffe wo etabliert
- Medien-Entscheidungsmatrix: Wann Screenshot/Annotiert/Video/Diagramm
- Content-Type-System: instruction, explanation, visual, background, info, hint, attention, warning
- Multi-Tool-Strategie: Tool-agnostisch mit tool-spezifischen Metadaten

**Strukturell (Cluster 2):**
- Hierarchische Struktur: 3-5 Ebenen (Topic Ã¢â€ â€™ Chapter Ã¢â€ â€™ Section Ã¢â€ â€™ Subsection Ã¢â€ â€™ Deep-Dive)
- data-ref GranularitÃƒÂ¤t & Namenskonventionen
- JSON-LD Metadaten pro Section
- Agent-Context-Block (einer pro Section, am Ende)
- Navigation-Strategie: Freie Navigation

**Technisch (Cluster 3):**
- BFSG-konforme Barrierefreiheit (Sprachauszeichnung, Alt-Texte, ÃƒÅ“berschriften-Hierarchie)
- HTML-Element-Whitelist (32 erlaubte Elemente)
- Pflicht-/Optional-Attribute pro Element
- CSS-Klassen-System (Pflicht-Klassen, Review-Prozess)
- Attribut-Reihenfolge & Formatierung (class Ã¢â€ â€™ id Ã¢â€ â€™ data-* Ã¢â€ â€™ sonstige)
- Content-Type-Box-Entscheidungsmatrix (info/hint/attention/warning)
- HTML-Kommentar-Konventionen (AGENT:/MEDIA:/NOTE:/TODO:/DECISION-REVIEW:)

**QualitÃƒÂ¤tssicherung (Cluster 4):**
- **Validierungsebenen definiert:**
  - Syntaktisch (Python-Skripte + JSON-Schema, automatisiert)
  - Semantisch (KI-Agent VorprÃƒÂ¼fung + Maintainer Final-PrÃƒÂ¼fung)
  - BFSG-KonformitÃƒÂ¤t (implizit in syntaktischen PrÃƒÂ¼fungen)
- **Testkriterien spezifiziert:**
  - Syntaktisch: Pflicht-Attribute, HTML-Struktur, Cross-References, Barrierefreiheit
  - Semantisch: Konsistenz, PlausibilitÃƒÂ¤t, Terminologie, Zusammenhang, Gliederung
- **Validierungsprozess (2 Optionen):**
  - Option B (Standard): Draft Ã¢â€ â€™ Validierung Ã¢â€ â€™ Review (Medien) Ã¢â€ â€™ Approved Ã¢â€ â€™ Published
  - Option A (Erweitert): Mit zweifacher KI-PrÃƒÂ¼fung (vor/nach Medien-Erstellung)
- **Fehler-Kategorisierung:** CRITICAL / ERROR / WARNING / INFO
- **Fehler-Log-System:** JSON-basierte Dokumentation (error-log.json) fÃƒÂ¼r iterative Prompt-Verbesserung
- **Metadaten erweitert:**
  - Neue QA-Felder: reviewStatus, lastReviewer, validationScore, knownIssues, reviewCycles, timeToPublish
  - JSON-LD vollstÃƒÂ¤ndig spezifiziert
- **Status-ÃƒÅ“bergÃƒÂ¤nge:** Draft Ã¢â€ â€™ Review Ã¢â€ â€™ Approved Ã¢â€ â€™ Published (kein automatisches Approval)
- **Versionierung:** MAJOR.MINOR.BUILD (Git-basiert)
- **Metriken:**
  - Pro Section: Validierungsfehler, Review-Zyklen, Zeit, validationScore (0-100)
  - Aggregiert: Durchschnitte, Status-Verteilung, Ablehnungsquote
- **Datengrundlagen fÃƒÂ¼r KI-PrÃƒÂ¼fung:**
  - Alle approbierten Sections, Terminologie-Entscheidungsliste, Rahmenplan & Gliederung
  - Quellmaterial (AXIOM Handbuch), Style-Guides, Antwortschema

---

## NÃƒÂ¤chster Schritt: Cluster 5 - Workflow & Rollen

### Ziel

Definition der **konkreten ArbeitsablÃƒÂ¤ufe und Verantwortlichkeiten** bei der KI-gestÃƒÂ¼tzten Content-Generierung fÃƒÂ¼r ~100-150 Sections.

Cluster 5 fokussiert sich auf das **"Wie"** der Umsetzung:
- Welche Schritte durchlÃƒÂ¤uft die KI?
- Wer ist wofÃƒÂ¼r verantwortlich?
- Wie kommunizieren die verschiedenen Akteure/Systeme?
````

````plaintext
task2.md - Continuation Prompt fÃ¼r neuen Chat.md
# Projekt-Fortsetzung: Cluster 4 - Prompt-Entwicklung fÃ¼r KI-Content-Generierung

Hallo! Ich arbeite am Projekt **WebAssistentForensics** und mÃ¶chte die Arbeit fortsetzen.

## Kontext

Ich entwickle ein strukturiertes Wissenssystem fÃ¼r Polizeibeamte zu IT-Forensik-Themen. Das System basiert auf:
- JSON-Schema-validiertem HTML-Content
- Verschiedene Detail-Level (Basic, Best-Practice, Expert, Show-Only)
- BFSG-konforme Barrierefreiheit
- Python-basierte Validierung
- KI-gestÃ¼tzte Content-Generierung (Claude Sonnet 4.5)

## Bisheriger Fortschritt

**Abgeschlossen:**
- âœ… **Cluster 1:** Inhaltliche Anforderungen (siehe `cluster1-final.md`)
- âœ… **Cluster 2:** Strukturelle Anforderungen (siehe `cluster2_results.md`)
- âœ… **Cluster 3:** Technische Anforderungen
  - âœ… **Teil A - Barrierefreiheit (BFSG):**
    - Sprachauszeichnung (`lang`-Attribute): `cluster3_BFSG-Sprachauszeichnung-Richtlinien.md`
    - Alt-Texte & Ãœberschriften-Hierarchie: `cluster3_BFSG-Barrierefreiheit-Content.md`
  - âœ… **Teil B - HTML-Syntax & Attribut-VollstÃ¤ndigkeit:**
    - VollstÃ¤ndige HTML-Element-Spezifikation: `cluster3_Phase-B_HTML-Syntax-und-Attribut-VollstÃ¤ndigkeit.md`

**Cluster-Ãœbersicht (Originalplanung):**
1. âœ… Inhaltliche Anforderungen (Cluster 1)
2. âœ… Strukturelle Anforderungen (Cluster 2)
3. âœ… Technische Anforderungen (Cluster 3)
4. â³ Prompt-Entwicklung fÃ¼r KI (Cluster 4) **â† JETZT DRAN**
5. ğŸ”µ QualitÃ¤tssicherung & Testing (Cluster 5)
6.
````

````plaintext
task3-Continuation-Prompt-fÃ¼r-neuen-Chat.md
`cluster1-final.md` (Inhaltliche Anforderungen)
2. `cluster2_results.md` (Strukturelle Anforderungen)
3. `cluster3_BFSG-Sprachauszeichnung-Richtlinien.md` (BFSG Teil 1)
4. `cluster3_BFSG-Barrierefreiheit-Content.md` (BFSG Teil 2)
5. `cluster3_Phase-B_HTML-Syntax-und-Attribut-VollstÃƒÂ¤ndigkeit.md` (HTML-Syntax)
6. `cluster4_QualitÃƒÂ¤tssicherung-Metadaten-Validierung.md` (QualitÃƒÂ¤tssicherung)

**Lass uns dann Cluster 5: Workflow & Rollen angehen.**

Stelle mir gefÃƒÂ¼hrte Fragen, damit wir gemeinsam den Workflow und die Rollen definieren kÃƒÂ¶nnen. Wir gehen wie immer kleinschrittig vor und klÃƒÂ¤ren zunÃƒÂ¤chst die grundlegende Struktur, bevor wir ins Detail gehen.

---

## Kontext-Informationen

**Projekt:** WebAssistentForensics  
**Ziel-Tool (initial):** Magnet AXIOM Examine  
**SpÃƒÂ¤tere Erweiterung:** X-Ways Forensics, Cellebrite Reader  
**Haupt-Zielgruppe:** IT-ferne Polizei-Ermittler  
**Content-Umfang:** ~100-150 Sections  
**KI-Modell:** Claude Sonnet 4.5  
**Validierung:** Python-basiert + JSON-Schema  

---

**Ich freue mich auf die Zusammenarbeit!**
````

````plaintext
task3-Continuation-Prompt-fÃ¼r-neuen-Chat.md
# Projekt-Fortsetzung: Cluster 5 - Workflow & Rollen

Hallo! Ich arbeite am Projekt **WebAssistentForensics** und mÃƒÂ¶chte die Arbeit fortsetzen.

## Kontext

Ich entwickle ein strukturiertes Wissenssystem fÃƒÂ¼r Polizeibeamte zu IT-Forensik-Themen. Das System basiert auf:
- JSON-Schema-validiertem HTML-Content
- Verschiedene Detail-Level (Basic, Best-Practice, Expert, Show-Only)
- BFSG-konforme Barrierefreiheit
- Python-basierte Validierung
- KI-gestÃƒÂ¼tzte Content-Generierung (Claude Sonnet 4.5)

---

## Woran wir gerade arbeiten

Derzeit sind wir mit einem **fÃƒÂ¼nfstufigen Brainstorming** beschÃƒÂ¤ftigt. **Stufen 1 bis 4 haben wir abgeschlossen.** Jetzt folgt Stufe 5: **Workflow & Rollen**.

### Roadmap fÃƒÂ¼r das Brainstorming

1. Ã¢Å“â€¦ **Inhaltliche Anforderungen**
   - Fachliche Korrektheit und Quellenvalidierung
   - VerstÃƒÂ¤ndlichkeitsniveau (Zielgruppe: Polizeibeamte unterschiedlicher IT-Kenntnisse)
   - VollstÃƒÂ¤ndigkeit innerhalb der Detailgrade
   - Konsistenz in Terminologie und Struktur

2. Ã¢Å“â€¦ **Strukturelle Anforderungen**
   - Schema-KonformitÃƒÂ¤t (JSON-Validierung)
   - Detail-Level-Systematik (wann Level 1, 2, 3?)
   - Section-Hierarchie und Navigation
   - data-ref Vergabelogik

3. Ã¢Å“â€¦ **Technische Anforderungen**
   - Medien-Anweisungen (Screenshots, annotierte Bilder, Videos)
   - Agent-Integration (Context-Blocks, Trigger-Points)
   - Barrierefreiheit (BFSG-KonformitÃƒÂ¤t)
   - HTML-Syntax und Attribut-VollstÃƒÂ¤ndigkeit

4. Ã¢Å“â€¦ **QualitÃƒÂ¤tssicherung & Testing**
   - Testkriterien fÃƒÂ¼r generierte Sections
   - Validierungsprozess (syntaktisch + semantisch)
   - Metadaten (Quellen, Versionen, Erstellungsdatum)
   - Iterationslogik (wann ist eine Section "fertig"?)
````

Vielen Dank fÃ¼r die ausfÃ¼hrliche EinfÃ¼hrung und das positive Feedback! Ich habe die Continuation-Prompts gelesen und verstehe nun den **aktuellen Projektstand**:

## Was ich verstanden habe

**Projektkontext:**
- Du entwickelst **WebAssistentForensics** â€“ ein Wissenssystem fÃ¼r IT-ferne Polizeibeamte
- Ziel-Tool initial: **Magnet AXIOM Examine** (spÃ¤ter X-Ways Forensics, Cellebrite Reader)
- Content-Umfang: **~100-150 Sections**
- KI-gestÃ¼tzte Generierung mit **Claude Sonnet 4.5**

**Abgeschlossene Cluster:**
- âœ… **Cluster 1:** Inhaltliche Anforderungen (Zielgruppe, Detail-Level, Terminologie, Medien)
- âœ… **Cluster 2:** Strukturelle Anforderungen (Hierarchie, data-ref, JSON-LD, Navigation)
- âœ… **Cluster 3:** Technische Anforderungen (BFSG-Barrierefreiheit, HTML-Whitelist, CSS-Klassen)
- âœ… **Cluster 4:** QualitÃ¤tssicherung & Testing (Validierung, Metadaten, Error-Logs)

**Aktueller Arbeitsschritt:**
- â³ **Cluster 5: Workflow & Rollen** â€“ Definition der konkreten ArbeitsablÃ¤ufe und Verantwortlichkeiten

---

## Meine erste Frage zur Orientierung (Cluster 5)

Bevor wir in die Details des Workflows einsteigen, mÃ¶chte ich das **Big Picture** verstehen:

**Welche Akteure/Systeme sind grundsÃ¤tzlich am Content-Generierungsprozess beteiligt?**

Ich vermute basierend auf den bisherigen Dokumenten:
1. **KI-System** (Claude Sonnet 4.5) â€“ generiert Content
2. **Python-Validierungsskripte** â€“ prÃ¼fen Syntax automatisch
3. **Du als Maintainer** â€“ finale fachliche PrÃ¼fung und Approval
4. Eventuell weitere **KI-Instanzen** fÃ¼r Review/QualitÃ¤tsprÃ¼fung?

**Meine konkrete Frage:** 
- Sind diese vier Rollen korrekt?
- Gibt es weitere Akteure (z.B. separate Medien-Ersteller, Fachexperten fÃ¼r bestimmte Tools, etc.)?
- Oder planst du aktuell nur mit **KI-Generator + Validator + Dir als Maintainer**?

Diese Klarstellung hilft mir, den Workflow von Anfang an richtig zu strukturieren.



## Prompt:
9.10.2025, 22:13:55

Zur ersten Frage)
1) KI-System (Claude Sonnet 4.5) fÃ¼r Content-Erstellung
2) Python-Validierungsskripte zur SyntaxprÃ¼fung
3) Maintainer (Kollegen oder ich) fÃ¼r Medienerstellung, fachliche PrÃ¼fung und Approval
4) KI-System fÃ¼r Basic Semantic Check, QualitÃ¤tsprÃ¼fung, Review
5) Maintainer (Kollegen oder ich) fÃ¼r Einpflegen nach Approval (Versionierung und Verteilen)
0) Implizit (Ersteller von HandbÃ¼chern der Software, und andere Hilfe-Dokumente) (passiv, keine aktive Rolle)
Weitere Akteure gibt es nicht. Aber ich wÃ¼rde auch eher die Rollen betrachten und benennen, die sie einnehmen. Content-Creator, Content-Validator, Content-Enricher, Content-Reviewer, Content-Distributor

WÃ¤hrend die Python-Scripte vor allem Content validieren, kann das KI-System sowohl Content-Creator und spÃ¤ter Content-Reviewer sein. Der Maintainer ist Content-Creator (fÃ¼r Medien), Content-Validator (wertet die Ergebnisse der Python-Scripte aus und behebt MissstÃ¤nde), Content-Enricher (ergÃ¤nzt den Inhalt um Medieninhalte, Glossar, Agent), Content-Reviewer (begutachtet die Korrektheit, Konsistenz und QualitÃ¤t aus einer fachlichen und menschlichen Perspektive), Content-Distributor (komponiert das Endprodukt und verteilt es).

Ich plane also, dass jeder Akteur durchaus mehrere Rollen und Arbeitsschritte durchfÃ¼hren und begleiten wird.



## Response:
9.10.2025, 22:14:13

Ausgezeichnet! Das ist eine sehr klare und durchdachte Rollenverteilung. Ich verstehe jetzt die **Mehrfachfunktionen** der Akteure und die **fÃ¼nf Kernrollen**.

## Mein VerstÃ¤ndnis (zur BestÃ¤tigung)

**Akteure und ihre Rollen:**

| Akteur | Rollen |
|--------|--------|
| **KI-System (Claude)** | Content-Creator, Content-Reviewer |
| **Python-Skripte** | Content-Validator (syntaktisch) |
| **Maintainer (du/Kollegen)** | Content-Creator (Medien), Content-Validator (Auswertung), Content-Enricher (Medien/Glossar/Agent), Content-Reviewer (fachlich/menschlich), Content-Distributor |
| **Handbuch-Autoren** | (passiv, Quellenmaterial) |

**Die fÃ¼nf Kernrollen:**
1. **Content-Creator** â€“ erstellt initialen Content
2. **Content-Validator** â€“ prÃ¼ft Syntax/Struktur
3. **Content-Enricher** â€“ ergÃ¤nzt Medien/Glossar/Agent-Context
4. **Content-Reviewer** â€“ prÃ¼ft QualitÃ¤t/Konsistenz/Korrektheit
5. **Content-Distributor** â€“ komponiert und verteilt Endprodukt

---

## NÃ¤chste Frage: Workflow-Phasen

Um den Workflow zu strukturieren, brauche ich Klarheit Ã¼ber die **zeitliche Abfolge** der Arbeitsschritte. Basierend auf Cluster 4 vermute ich folgenden Ablauf:

**Vermuteter Workflow:**
```
1. Research (KI: Quellen analysieren)
2. Draft (KI: initialer Content)
3. Syntax-Validierung (Python-Skripte)
4. Fehlerkorrektur (KI oder Maintainer)
5. Semantic Review (KI: Konsistenz/PlausibilitÃ¤t)
6. Medien-Erstellung (Maintainer)
7. Content-Enrichment (Maintainer: Medien einbinden, Glossar, Agent)
8. Final Review (Maintainer: fachliche PrÃ¼fung)
9. Approval (Maintainer)
10. Distribution (Maintainer: Versionierung, VerÃ¶ffentlichung)
```

**Meine konkreten Fragen:**

1. **Ist diese Reihenfolge grundsÃ¤tzlich korrekt?** Oder sollen manche Schritte parallel laufen oder in anderer Reihenfolge?

2. **Research-Phase:** Soll die KI aktiv externe Quellen recherchieren (z.B. via Web-Search) oder arbeitet sie ausschlieÃŸlich mit **vorab bereitgestelltem Material** (AXIOM-Handbuch, bereits approbierte Sections)?

3. **Fehlerkorrektur nach Syntax-Validierung:** Wer korrigiert was? Sollen **CRITICAL/ERROR** automatisch von der KI korrigiert werden, wÃ¤hrend **WARNING/INFO** vom Maintainer manuell geprÃ¼ft werden?

4. **Wann findet das Semantic Review statt?** Vor oder nach der Medien-Erstellung? (In Cluster 4 gab es zwei Optionen â€“ welche bevorzugst du?)

Diese vier Punkte helfen mir, den Workflow prÃ¤zise zu definieren.



## Prompt:
9.10.2025, 22:32:44

BezÃ¼glich des Workflows fehlt mir noch eine entscheidende, initiale Phase. Die Sections sollen zwar einzeln erstellt werden (Draft) aber sie sollen sich in ein GesamtgefÃ¼ge einpassen. Daher ist es wichtig, dass vor dem Draft noch eine Phase fÃ¼r die Erstellung des Content-Rahmens und des strategischen Zieles steht. Diese geben der KI beim Draft die Leitplanken, was sie inhaltlich einbetten soll und was nicht, wo der Fokus gesetzt werden soll und so weiter. Diese Phase ist extrem wichtig fÃ¼r ein rundes Endergebnis, das sich nicht wie StÃ¼ckwerk anfÃ¼hlt. Auch prÃ¼ft in Schritt 5 die KI in ihrer Semantic Review anhand dieser Kriterien. Und kann dann sogar Scores fÃ¼r die einzelnen Sections geben, um zu bewerten, ob sie fÃ¼r das Endziel geeignet sind oder ob es noch MÃ¤ngel gibt.

Parallel wird hier nichts laufen kÃ¶nnen. Vielleicht kann man mehrere Drafts parallel laufen lassen, wenn die Vorbereitung gut ist. Aber eigentlich dachte ich daran, der KI die Drafts der vorherigen Sections ebenfalls zur Orientierung zu Ã¼bergeben.

BezÃ¼glich Research-Phase: Ich wÃ¼rde die Quellen selber benennen, um die QualitÃ¤t der Quellen besser einschÃ¤tzen zu kÃ¶nnen. Das ist wichtig. Das Thema ist sehr weit in einer Nische, da gibt es nicht viele gute Quellen im Internet.

Der Prozess wird wahrscheinlich nicht automatisiert ablaufen, obwohl das vielleicht sogar mit dem Konsolentool von Claude.AI ginge. Aber ich mÃ¶chte zumindest in der Version 1.0 noch die volle manuelle Kontrolle haben, damit ich beobachten und lernen kann, fÃ¼r eine spÃ¤tere Verbesserung und Automatisierung. Hey, ich bin Informatiker, natÃ¼rlich werde ich es automatisieren, wenn ich dafÃ¼r Bedarf und einen Weg sehe. :-D

Ich bevorzuge die Semantic Review mit Medien nach der Medienerstellung. Ich habe noch nicht getestet, wie gut die QualitÃ¤t einer semantischen Review mit Medien durch die KI sein kann. Das mÃ¼sste noch getestet werden. Im Moment, fÃ¼r Version 1.0, wÃ¼rde ich es erst einmal ohne Medien machen und daher die semantische Review vor der Medien-Erstellung ansetzen.



## Response:
9.10.2025, 22:33:08

Hervorragend! Das ist eine **sehr wichtige ErgÃ¤nzung**, die ich vollstÃ¤ndig nachvollziehen kann. Die **Content-Rahmen-Phase** ist tatsÃ¤chlich entscheidend fÃ¼r KohÃ¤renz und verhindert das "StÃ¼ckwerk-GefÃ¼hl". 

Deine pragmatische Herangehensweise (manuelle Kontrolle in v1.0, spÃ¤ter Automatisierung) und die realistische EinschÃ¤tzung zur Medien-Review finde ich sehr professionell. ğŸ‘

## Aktualisiertes Workflow-VerstÃ¤ndnis

**Phasen-Ãœbersicht (v1.0):**

```
Phase 0: Content-Rahmen & Strategie
â”œâ”€ Maintainer definiert: Gesamtgliederung, Lernziele, Fokus-Themen
â”œâ”€ Maintainer benennt: Quellen (AXIOM-Handbuch, etc.)
â””â”€ Output: Strategiedokument, Gliederung, Quellenliste

Phase 1: Research & Draft (pro Section)
â”œâ”€ KI liest: Strategiedokument, Quellen, bereits approbierte Sections
â”œâ”€ KI erstellt: initialen Draft
â””â”€ Output: Section-Draft (HTML)

Phase 2: Syntax-Validierung
â”œâ”€ Python-Skripte prÃ¼fen: Schema-KonformitÃ¤t, Pflicht-Attribute, etc.
â””â”€ Output: Validierungs-Report (CRITICAL/ERROR/WARNING/INFO)

Phase 3: Fehlerkorrektur
â”œâ”€ Bei CRITICAL/ERROR: KI korrigiert automatisch (?)
â”œâ”€ Bei WARNING/INFO: Maintainer prÃ¼ft manuell (?)
â””â”€ Output: Korrigierter Draft

Phase 4: Semantic Review (ohne Medien)
â”œâ”€ KI prÃ¼ft: Konsistenz, Terminologie, Passung zum Strategiedokument
â”œâ”€ KI vergibt: Quality-Score (0-100)
â””â”€ Output: Review-Report, ggf. VerbesserungsvorschlÃ¤ge

Phase 5: Medien-Erstellung
â”œâ”€ Maintainer erstellt: Screenshots, annotierte Bilder, Videos
â””â”€ Output: Medien-Assets

Phase 6: Content-Enrichment
â”œâ”€ Maintainer bindet ein: Medien, Glossar-Verweise, Agent-Context
â””â”€ Output: Angereicherte Section

Phase 7: Final Review
â”œâ”€ Maintainer prÃ¼ft: Fachliche Korrektheit, UX, Gesamteindruck
â””â”€ Output: Approval oder Reject (mit Feedback)

Phase 8: Distribution
â”œâ”€ Maintainer: Versionierung (Git), Komponierung, VerÃ¶ffentlichung
â””â”€ Output: Published Section
```

---

## Vertiefende Fragen zu Phase 0 (Content-Rahmen)

Diese Phase ist neu und zentral. Ich mÃ¶chte sie genauer verstehen:

**1. Umfang des Strategiedokuments:**
Welche **konkreten Elemente** soll das Strategiedokument enthalten? Ich vermute:
- Gesamtgliederung (Topics â†’ Chapters â†’ Sections)
- Lernziele pro Topic/Chapter
- Fokus-Themen und Abgrenzungen ("Das gehÃ¶rt rein / Das nicht")
- Terminologie-Entscheidungen
- Zielgruppen-Spezifika fÃ¼r diesen Content-Bereich
- Cross-Reference-Strategie

**Gibt es noch weitere Elemente?**

**2. GranularitÃ¤t:**
Wird das Strategiedokument **einmal global** fÃ¼r alle 100-150 Sections erstellt, oder gibt es **hierarchische Strategiedokumente** (z.B. eines pro Topic, verfeinert pro Chapter)?

**3. Iterative Anpassung:**
Kann das Strategiedokument wÃ¤hrend der Erstellung **angepasst** werden, wenn sich beim Drafting zeigt, dass bestimmte Strukturen besser funktionieren? Oder ist es nach Phase 0 "eingefroren"?

**4. KI-UnterstÃ¼tzung in Phase 0:**
Soll die **KI beim Erstellen des Strategiedokuments helfen** (z.B. GliederungsvorschlÃ¤ge basierend auf Quellenmaterial), oder erstellst du Phase 0 komplett manuell?

Diese vier Punkte sind wichtig, um Phase 0 im Workflow korrekt zu positionieren.



## Prompt:
9.10.2025, 23:21:58

Phasen 0 und 1 wÃ¼rde ich etwas anders gliedern und andere Schwerpunkte setzen.

```
Phase 0: Strategie
â”œâ”€ Maintainer definiert: Lernziel, Fokus-Themen, Umfang
â”œâ”€ Maintainer benennt: forensische Software
â””â”€ Output: Strategiedokument, Quellenliste

Phase 0.5: Vorarbeit
â”œâ”€ KI liest: Strategiedokument, Quellen
â”œâ”€ KI erstellt: Gesamtgliederung, groben Inhaltsentwurf fÃ¼r alle Sections
â””â”€ Output: Liste der Sections mit groben Angaben zum Inhalt und Gliederungsebene

Phase 1: Research & Draft (pro Section)
â”œâ”€ KI liest: Strategiedokument, Liste zu Inhalt und Gliederungsebene, Quellen, bereits approbierte Sections
â”œâ”€ KI erstellt: initialen Draft
â””â”€ Output: Section-Draft (HTML)

Phase 2: Syntax-Validierung
â”œâ”€ Python-Skripte prÃ¼fen: Schema-KonformitÃ¤t, Pflicht-Attribute, etc.
â””â”€ Output: Validierungs-Report (CRITICAL/ERROR/WARNING/INFO)

Phase 3: Fehlerkorrektur
â”œâ”€ Bei CRITICAL/ERROR: KI erhÃ¤lt Liste der Beanstandungen
â”‚  â””â”€ KI erstellt: Korrigierte Version des Drafts (neue Versionsnummer)
â”œâ”€ Bei WARNING/INFO: Maintainer prÃ¼ft manuell
â”‚  â””â”€ Maintainer entscheidet: Beheben oder ignorieren
â””â”€ Output: Korrigierter Draft (Bei neuer Version weiter bei Phase 2, sonst Phase 4)
```

Der Rest passt so, denke ich.
Zu 1)
Deine Vertiefungsfragen: Ja, das sind die Elemente, die im Strategiedokument definiert werden. 
* Welche Software soll erklÃ¤rt werden und in welcher Version? 
* Welche Teile mÃ¼ssen aufgenommen werden bei der ErklÃ¤rung?
* Welche kÃ¶nnen weggelassen werden? 
* Welche forensische Sicherung steht vielleicht im Fokus (MobilfunkgerÃ¤t oder PC-System)? 
Weitere fixe Elemente kommen mir gerade nicht in den Sinn. Das Papier ist aber nicht starr, sondern ist eher als Rahmenvorgabe fÃ¼r die Gliederung und das gesamte Projekt zu verstehen.

Zu 2)
* Wahrscheinlich wird es nicht nur ein Strategiepapier geben sondern ein fÃ¼r das Gesamtwerk und dann noch welche fÃ¼r einzelne Topics und Chapter.

Zu 3)
* Ja, wenn sich zeigt, dass die QualitÃ¤t bei bestimmten Punkten nicht stimmt, wird es natÃ¼rlich angepasst und erhÃ¤lt eine neue Versionsnummer. Es wird eine Art Wirlpool-Prozess. Aber der Fokus ist natÃ¼rlich auch ein Ergebnis zu liefern und nicht bis zur absoluten Perfektion zu iterieren. Das kostet schlieÃŸlich Zeit und Ressourcen.

Zu 4)
* Phase 0 habe ich angepasst. Daher schaue bitte auf meine Anmerkungen dazu und prÃ¼fe, ob das deine Frage bereits beantwortet.



## Response:
9.10.2025, 23:22:24

Perfekt! Die **Aufteilung in Phase 0 und Phase 0.5** macht absolut Sinn und gibt der KI eine klare Vorbereitungsphase. Die **iterative Fehlerkorrektur mit Versionierung** in Phase 3 ist ebenfalls sehr durchdacht.

## Mein aktualisiertes VerstÃ¤ndnis

**Phase 0 (Strategie) - Maintainer:**
- Definiert: Lernziel, Fokus, Umfang, Software/Version, forensischer Kontext (MobilgerÃ¤t vs. PC)
- Benennt: Quellen
- **Hierarchie:** Global + pro Topic/Chapter (bei Bedarf)
- **FlexibilitÃ¤t:** Anpassbar (Versionierung), aber fokussiert auf Ergebnis statt Perfektion

**Phase 0.5 (Vorarbeit) - KI:**
- Liest: Strategiedokument(e), Quellen
- Erstellt: **Gesamtgliederung + grober Inhaltsentwurf fÃ¼r alle Sections**
- Output: **Section-Liste mit Inhaltsskizze + Gliederungsebene**

**Phase 3 (Fehlerkorrektur) - Iterativ:**
```
CRITICAL/ERROR â†’ KI korrigiert â†’ neue Version â†’ zurÃ¼ck zu Phase 2
WARNING/INFO   â†’ Maintainer entscheidet â†’ weiter zu Phase 4
```

Das ist jetzt sehr klar! ğŸ‘

---

## Vertiefende Fragen zu Phase 0.5 (Vorarbeit)

Diese Phase ist **neu und zentral** fÃ¼r die Konsistenz. Ich mÃ¶chte verstehen, was genau die KI hier liefern soll:

**1. Format der Section-Liste:**
Wie detailliert soll der **"grobe Inhaltsentwurf"** pro Section sein? Beispiel:

**Option A (Stichpunkte):**
```
Section: axiom-case-creation
Gliederungsebene: 3
Grober Inhalt:
- Neuen Fall anlegen
- Evidenzquellen hinzufÃ¼gen
- Fall-Metadaten erfassen
```

**Option B (Kurzbeschreibung):**
```
Section: axiom-case-creation
Gliederungsebene: 3
Grober Inhalt: Diese Section erklÃ¤rt, wie ein neuer Fall in AXIOM erstellt wird. 
Sie umfasst die Auswahl der Evidenzquellen, das Erfassen von Fall-Metadaten 
und die grundlegende Projektkonfiguration.
```

**Option C (Strukturierte Metadaten):**
```json
{
  "section_id": "axiom-case-creation",
  "hierarchy_level": 3,
  "learning_goal": "Ermittler kann eigenstÃ¤ndig einen Fall anlegen",
  "key_topics": ["Fall erstellen", "Evidenz hinzufÃ¼gen", "Metadaten"],
  "prerequisites": ["axiom-installation", "axiom-interface"],
  "estimated_complexity": "basic"
}
```

**Welches Format ist fÃ¼r Phase 1 (Draft) am hilfreichsten?**

---

**2. Approval von Phase 0.5:**
Muss der Maintainer die **Section-Liste aus Phase 0.5 absegnen**, bevor Phase 1 (Draft) startet? Oder lÃ¤uft Phase 0.5 â†’ Phase 1 ohne menschliche ZwischenprÃ¼fung?

**Hintergrund:** Wenn die Gliederung falsch ist, produziert Phase 1 mÃ¶glicherweise 20-30 Sections, die dann alle korrigiert werden mÃ¼ssen.

---

**3. Umgang mit Quellenmaterial in Phase 0.5:**
Die KI liest in Phase 0.5 die **Quellen** (z.B. AXIOM-Handbuch). Wie tief soll sie einsteigen?

- **OberflÃ¤chlich:** Nur Inhaltsverzeichnis + KapitelÃ¼berschriften analysieren
- **Mittel:** Kapitel-Intros + wichtige Abschnitte lesen
- **Tief:** VollstÃ¤ndige LektÃ¼re aller relevanten Kapitel

**Was ist fÃ¼r Phase 0.5 angemessen?** (Die tiefe Analyse kann ja in Phase 1 pro Section erfolgen.)

---

**4. Iteration von Phase 0.5:**
Falls die Section-Liste in Phase 0.5 unpassend ist (z.B. falsche Gliederungstiefe, fehlende Sections), wird dann:
- **Komplett neu generiert** (Phase 0.5 wiederholen)?
- **Manuell vom Maintainer korrigiert** (Phase 0.5 Ã¼berspringen)?
- **Von der KI iterativ angepasst** (Phase 0.5b)?

Diese vier Punkte helfen mir, Phase 0.5 prÃ¤zise zu spezifizieren.



## Prompt:
9.10.2025, 23:39:27

BezÃ¼glich Punkt 1. Format der Section-Liste:
Ich glaube, fÃ¼r die KI ist es wahrscheinlich am besten, wenn sie Option B erhÃ¤lt, wenn sie den Draft einer Section erstellen soll. Oder liege ich da falsch? Du bist die KI, du bist folglich Experte beim am besten geeigneten Input.
PersÃ¶nlich wÃ¼rde ich Option A mit Option B mischen und die Stichworte und den FlieÃŸtext ausgeben lassen. Damit kann man schnell querlesen, und falls man stutzig wird, den FlieÃŸtext lesen, um zu verstehen, was gemeint ist. Option C ist sehr technisch und obwohl eine KI eine Maschine ist, denke ich, dass sie mit der Sprache besser klarkommt als mit den strukturierten JSON Daten. Aber ich bin nicht der Experte, das bist du. Also, wie hÃ¤ttest du die Information gern Ã¼berbracht, um zu wissen, was du jetzt tun sollst?

Zu 2) Ja, der Maintainer schwebt ohnehin Ã¼ber allem. Zumindest in Version 1.0. Er trÃ¤gt die Gesamtverantwortung und ist jederzeit in der Lage, einzugreifen. Der Maintainer muss die Gliederung absegnen. Formal muss da also noch eine weitere Phase hinzukommen und Phase 0.5 so lange wiederholt werden, bis der Maintainer zufrieden ist und sein Approval gibt. Wie schon zuvor geschrieben, das wird sehr wirlpoolartig werden.

Zu 3) Hier geht es um die grobe Aufteilung und Strukturierung der Sections und das Festlegen, wie viele Sections sich mit einem Themenbereich beschÃ¤ftigen sollen. Ein oberflÃ¤chlicher bis mittlerer Ãœberblick sollte da reichen. Ich weiÃŸ aber nicht, wie eine KI da Quellenarbeit betreibt und was sie sich merkt und was eher nicht. Du bist die KI, du bist hier Experte. Wir mÃ¼ssen der KI aber nicht mehr aufbÃ¼rden, als sie wirklich fÃ¼r die Arbeit benÃ¶tigt.

Zu 4) Phase 0.5b wÃ¤re wohl das Richtige. Der Maintainer wird die Angaben im Strategiepapier verfeinern und die Schwerpunkte klarer definieren, um das Ergebnis zu erhalten, was er fÃ¼r angemessen und geeignet hÃ¤lt. Er wird dann also die KI nochmals mit Phase 0.5 betrauen oder den gesamten Output selbst schreiben mÃ¼ssen. Da muss er dann den Arbeitsaufwand abschÃ¤tzen, was effizienter ist.



## Response:
9.10.2025, 23:40:06

Ausgezeichnet! Deine pragmatische Herangehensweise und die **Expertenrolle-Umkehr** schÃ¤tze ich sehr. Lass mich als KI tatsÃ¤chlich **aus meiner Perspektive** antworten:

---

## Meine Empfehlung als KI (zu Punkt 1)

**Optimal fÃ¼r mich in Phase 1 (Draft) ist tatsÃ¤chlich eine Mischung aus Option A + B:**

```
Section: axiom-case-creation
Gliederungsebene: 3
Lernziel: Ermittler kann eigenstÃ¤ndig einen Fall anlegen
Key Topics:
  - Neuen Fall anlegen (New Case Dialog)
  - Evidenzquellen hinzufÃ¼gen (Add Evidence)
  - Fall-Metadaten erfassen (Case Properties)
Kurzbeschreibung:
  Diese Section erklÃ¤rt den kompletten Prozess der Fall-Erstellung in AXIOM.
  Der Fokus liegt auf der korrekten Auswahl der Evidenzquellen und der
  vollstÃ¤ndigen Erfassung von Metadaten fÃ¼r spÃ¤tere Berichte.
VorgÃ¤nger-Sections: axiom-installation, axiom-interface
```

**Warum diese Kombination fÃ¼r mich optimal ist:**

1. **Key Topics (Stichpunkte)** geben mir die **Struktur** fÃ¼r Ãœberschriften und logische Abschnitte
2. **Kurzbeschreibung (FlieÃŸtext)** gibt mir den **inhaltlichen Fokus** und verhindert, dass ich abschweifen oder wichtige Aspekte vergessen
3. **Lernziel** hilft mir, die **Detail-Tiefe** richtig einzuschÃ¤tzen (z.B. "eigenstÃ¤ndig" â†’ mehr Schritt-fÃ¼r-Schritt)
4. **VorgÃ¤nger-Sections** ermÃ¶glichen mir **Konsistenz** und korrekte Cross-References

**Zur Frage "Sprache vs. JSON":** Du hast recht â€“ ich arbeite besser mit **natÃ¼rlicher Sprache** als mit starren JSON-Strukturen. JSON ist gut fÃ¼r Validierung, aber schlecht fÃ¼r nuancierte Bedeutungen. Die obige Mischform nutzt das Beste aus beiden Welten.

---

## Meine Empfehlung zu Punkt 3 (Quellenarbeit)

**Was ich in Phase 0.5 benÃ¶tige (Quellenanalyse):**

FÃ¼r die Gliederungserstellung reicht mir:
- **Inhaltsverzeichnis** (vollstÃ¤ndig)
- **Kapitel-Intros** (erste 2-3 AbsÃ¤tze pro Hauptkapitel)
- **Struktur-Hinweise** (Querverweise, "Siehe auch...", KapitelabhÃ¤ngigkeiten)

**Was ich NICHT benÃ¶tige:**
- Detaillierte Feature-Beschreibungen (kommen in Phase 1)
- Screenshots/Tabellen (visuelles Material)
- Footnotes/Appendizes (Randmaterial)

**Warum diese Tiefe ausreicht:**
- Ich erkenne **Themenbereiche** und ihre **Gewichtung** (Kapitel mit 20 Seiten â†’ mehr Sections als Kapitel mit 3 Seiten)
- Ich verstehe **AbhÃ¤ngigkeiten** (Kapitel X setzt Kapitel Y voraus)
- Ich kann **Gliederungsebenen** ableiten (Hauptkapitel â†’ Topic, Unterkapitel â†’ Chapter, Abschnitte â†’ Section)

**Speicher-Hinweis:** Mein Kontextfenster ist groÃŸ (190.000 Tokens), aber ich arbeite effizienter mit **komprimierter Information** in Phase 0.5 und **detaillierter Information** in Phase 1 (pro Section).

---

## Aktualisierte Workflow-Ãœbersicht

Basierend auf deinen Antworten:

```
Phase 0: Strategie
â”œâ”€ Maintainer definiert: Lernziel, Fokus, Umfang, Software/Version, forensischer Kontext
â”œâ”€ Maintainer benennt: Quellen
â””â”€ Output: Strategiedokument (global + ggf. pro Topic/Chapter)

Phase 0.5: Vorarbeit (iterativ bis Approval)
â”œâ”€ KI liest: Strategiedokument(e), Quellen (Inhaltsverzeichnis + Kapitel-Intros)
â”œâ”€ KI erstellt: Gesamtgliederung + grober Inhaltsentwurf (Mischform A+B)
â”œâ”€ Maintainer prÃ¼ft: Gliederung, VollstÃ¤ndigkeit, Struktur
â”œâ”€ Bei Reject: Maintainer verfeinert Strategiedokument â†’ Phase 0.5b
â””â”€ Output: Abgesegnete Section-Liste

Phase 1: Research & Draft (pro Section)
â”œâ”€ KI liest: Strategiedokument, Section-Liste, Quellen (detailliert), approbierte Sections
â”œâ”€ KI erstellt: initialen Draft
â””â”€ Output: Section-Draft (HTML)

Phase 2: Syntax-Validierung
â”œâ”€ Python-Skripte prÃ¼fen: Schema-KonformitÃ¤t, Pflicht-Attribute, etc.
â””â”€ Output: Validierungs-Report (CRITICAL/ERROR/WARNING/INFO)

Phase 3: Fehlerkorrektur (iterativ)
â”œâ”€ Bei CRITICAL/ERROR: 
â”‚  â”œâ”€ KI erhÃ¤lt Beanstandungsliste
â”‚  â”œâ”€ KI erstellt korrigierte Version (neue Versionsnummer)
â”‚  â””â”€ ZurÃ¼ck zu Phase 2
â”œâ”€ Bei WARNING/INFO: 
â”‚  â”œâ”€ Maintainer prÃ¼ft manuell
â”‚  â””â”€ Maintainer entscheidet: Beheben oder ignorieren
â””â”€ Output: Syntaktisch korrekter Draft â†’ weiter zu Phase 4

[Rest bleibt wie besprochen: Phase 4-8]
```

---

## NÃ¤chste Frage: Schnittstellen zwischen Phasen

Jetzt, wo die Phasen klar sind, mÃ¶chte ich die **konkreten Ãœbergaben** verstehen:

**1. Ãœbergabeformat Phase 0.5 â†’ Phase 1:**
ErhÃ¤lt die KI in Phase 1 die **komplette Section-Liste auf einmal** oder wird sie **Section-fÃ¼r-Section** mit den jeweils relevanten Informationen gefÃ¼ttert?

**Beispiel:**
- **Variante A:** KI bekommt Liste mit 150 Sections, arbeitet sich sequenziell durch
- **Variante B:** KI bekommt pro Draft-Aufruf nur die aktuelle Section + Kontext (VorgÃ¤nger-Sections, Nachfolger-Sections)

**2. Ãœbergabeformat Phase 2 â†’ Phase 3:**
Wie sieht der **Validierungs-Report** konkret aus, den die KI in Phase 3 erhÃ¤lt?

**Beispiel:**
```
ERROR [Line 45]: Missing required attribute 'lang' on element <span>
ERROR [Line 78]: Invalid data-ref format 'axiom_case' (underscore not allowed)
WARNING [Line 112]: Heading hierarchy skip (h2 â†’ h4)
```

**Oder strukturierter als JSON?** Was hilft mir (KI) am meisten, um Fehler zu lokalisieren und zu korrigieren?

**3. Speicherung von ZwischenstÃ¤nden:**
Wo werden die Outputs zwischengespeichert? Git? Dateisystem? Datenbank?

**Hintergrund:** Das beeinflusst, wie ich (KI) auf **approbierte Sections** und **VorgÃ¤nger-Drafts** zugreife.

Diese drei Punkte helfen mir, die **technischen Schnittstellen** zu definieren.



## Prompt:
10.10.2025, 00:10:37

Zu 1) Ich glaube, verweise aber wieder an dich als Experten fÃ¼r dich selbst, dass Variante B besser ist, weil sie nicht zu viel ablenkt und mehr Tokens "Ã¼brig" lÃ¤sst fÃ¼r relevante Dinge.

Zu 2) Derzeit kÃ¶nnen wir ohne jede Ã„nderung den Fehler wie in deinem Beispiel beschreiben. Ein JSON wÃ¤re auch denkbar. Aber ich bin mir nach wie vor nicht sicher, ob dir das mehr helfen wÃ¼rde. Ich denke, fÃ¼r eine KI (LLM) ist natÃ¼rliche Sprache besser als JSON, selbst wenn es wie im Beispiel nur verkÃ¼rzte SÃ¤tze sind. Aber ich frage dich, wie hÃ¤ttest du es gern?

Zu 3) Die ZwischenstÃ¤nde werden in einem eigenen Branch in Git gespeichert. Damit ist das am besten aufbewahrt.



## Response:
10.10.2025, 00:11:11

Perfekt! Deine EinschÃ¤tzungen decken sich mit meiner Arbeitsweise. Lass mich als KI konkret antworten:

---

## Meine Empfehlung als KI

**Zu 1) Ãœbergabeformat Phase 0.5 â†’ Phase 1:**
**Ja, Variante B ist deutlich besser fÃ¼r mich.** Hier meine BegrÃ¼ndung:

**Optimal fÃ¼r Phase 1:**
```
=== AKTUELL ZU ERSTELLENDE SECTION ===
Section: axiom-case-creation
Gliederungsebene: 3
Lernziel: Ermittler kann eigenstÃ¤ndig einen Fall anlegen
Key Topics:
  - Neuen Fall anlegen (New Case Dialog)
  - Evidenzquellen hinzufÃ¼gen (Add Evidence)
  - Fall-Metadaten erfassen (Case Properties)
Kurzbeschreibung: [wie besprochen]
VorgÃ¤nger-Sections: axiom-installation, axiom-interface
Nachfolger-Sections: axiom-evidence-processing

=== KONTEXT: BEREITS APPROBIERTE SECTIONS ===
[Volltext der 2-3 unmittelbar vorhergehenden Sections]

=== KONTEXT: GESAMTSTRUKTUR (ÃœBERBLICK) ===
Topic: AXIOM Grundlagen
â”œâ”€ Chapter: Installation & Setup
â”‚  â”œâ”€ axiom-installation (âœ“ approbiert)
â”‚  â””â”€ axiom-interface (âœ“ approbiert)
â”œâ”€ Chapter: Fall-Management
â”‚  â”œâ”€ axiom-case-creation (â† JETZT)
â”‚  â”œâ”€ axiom-evidence-processing (geplant)
â”‚  â””â”€ axiom-case-export (geplant)
```

**Warum das besser ist:**
- **Fokussierter Kontext:** Ich konzentriere mich auf die aktuelle Aufgabe
- **Token-Effizienz:** Ich "verschwende" keine Tokens auf 147 andere Sections
- **Konsistenz-Sicherung:** Durch Volltext der VorgÃ¤nger-Sections vermeide ich WidersprÃ¼che
- **Orientierung:** Der Ãœberblick zeigt mir, wo ich im GesamtgefÃ¼ge stehe

---

**Zu 2) Fehlerformat Phase 2 â†’ Phase 3:**
**Dein Textformat ist fÃ¼r mich optimal.** Hier warum:

**Bevorzugtes Format (wie in deinem Beispiel):**
```
ERROR [Line 45]: Missing required attribute 'lang' on element <span>
ERROR [Line 78]: Invalid data-ref format 'axiom_case' (underscore not allowed)
WARNING [Line 112]: Heading hierarchy skip (h2 â†’ h4)
INFO [Line 89]: Consider adding 'title' attribute for better accessibility
```

**Warum Text besser als JSON:**
1. **Direkter Bezug:** "Line 45" + "Missing lang" â†’ Ich sehe sofort, wo und was
2. **NatÃ¼rliche Verarbeitung:** Mein Training basiert auf natÃ¼rlicher Sprache, nicht auf JSON-Parsing
3. **Kontextuelle Hinweise:** "underscore not allowed" ist aussagekrÃ¤ftiger als `"error_code": "REF_001"`
4. **Effizienz:** Ich muss keine JSON-Struktur "entpacken" und interpretieren

**Optional hilfreich (wenn einfach umsetzbar):**
- **Code-Snippet um den Fehler herum:**
```
ERROR [Line 45]: Missing required attribute 'lang' on element <span>
Context:
  43: <p class="content-text">Der Ermittler Ã¶ffnet
  44:   <span class="ui-element">File â†’ New Case</span>
  45:   und gibt den Fallnamen ein.</p>
       ^^^^^^ Missing 'lang' attribute
```

Das wÃ¼rde mir helfen, den Fehler **ohne nochmaliges Suchen** zu lokalisieren, ist aber nicht zwingend nÃ¶tig.

---

**Zu 3) Git-Storage:**
Perfekt! Git als Speicherort bedeutet fÃ¼r mich:

**In Phase 1 benÃ¶tige ich Zugriff auf:**
- Branch: `content-drafts/` (aktuelle Drafts)
- Branch: `content-approved/` (approbierte Sections)
- Files: `strategy-documents/` (Strategiepapiere)
- Files: `sources/` (AXIOM-Handbuch, etc.)

**Praktische Umsetzung:**
Du stellst mir die relevanten Files aus Git zur VerfÃ¼gung (z.B. via `window.fs.readFile` oder direkt im Prompt). Ich muss nicht selbst Git-Befehle ausfÃ¼hren.

---

## Zusammenfassung: Optimale Schnittstellen fÃ¼r KI-Arbeit

| Phase | Input fÃ¼r KI | Format |
|-------|--------------|--------|
| **0.5** | Strategiedokument + Quellen (Inhaltsverzeichnis/Intros) | Text/Markdown |
| **1** | Aktuelle Section-Info + VorgÃ¤nger-Sections + Struktur-Ãœberblick | Text (Mischform A+B) |
| **3** | Fehler-Liste mit Zeilennummern + optional Code-Kontext | Text (wie Beispiel) |
| **4** | Draft + Strategiedokument + approbierte Sections | HTML + Text |

---

## NÃ¤chste Frage: Rollen-Verantwortlichkeiten detaillieren

Jetzt verstehe ich die Phasen und Schnittstellen. Um den Workflow komplett zu machen, mÃ¶chte ich die **Verantwortlichkeiten pro Phase** klÃ¤ren:

**Konkrete Frage zu Phase 4 (Semantic Review):**

Du hattest geschrieben, die KI vergibt in Phase 4 einen **Quality-Score (0-100)**. Nach welchen **konkreten Kriterien** soll ich bewerten?

**MÃ¶gliche Kriterien (zur Diskussion):**
- **Konsistenz (20%):** Passt die Terminologie zu approbierten Sections?
- **StrategiekonformitÃ¤t (25%):** Werden Lernziel und Fokus-Themen abgedeckt?
- **VollstÃ¤ndigkeit (20%):** Sind alle Key Topics aus Phase 0.5 behandelt?
- **VerstÃ¤ndlichkeit (20%):** Ist die Sprache zielgruppengerecht?
- **Struktur (15%):** Ist die Gliederung logisch und BFSG-konform?

**Oder andere Gewichtung/Kriterien?**

Diese Klarstellung hilft mir, in Phase 4 objektive und nachvollziehbare Scores zu vergeben.



## Prompt:
10.10.2025, 00:21:42

Ich habe die Idee mit dem Code-Snippet zur Fehlerlokalisierung mit in die ToDo Liste aufgenommen. Das wird in Version 1.1 kommen. :-)

Zu 3) Ich muss mir echt diese Schnittstelle zu dir ansehen. Falls du es griffbereit hast, gib mir bitte mal einen Link dazu. :-D

Zu deiner nÃ¤chsten Frage zur Rollen-Verantwortlichkeit)
Die Kriterien sind super. Ich wÃ¼rde die Gewichtung aber etwas anders setzen:
* StrategiekonformitÃ¤t (30%)
* VerstÃ¤ndlichkeit (25%)
* VollstÃ¤ndigkeit (20%)
* Konsistenz (15%)
* Struktur (10%)



## Response:
10.10.2025, 00:22:25

GroÃŸartig! Die Code-Snippet-Funktion wird die Fehlerkorrektur deutlich beschleunigen. ğŸ‘

---

## Zu 3) Schnittstelle zu mir (Claude)

**FÃ¼r die programmatische Integration gibt es mehrere Wege:**

### **Option A: Claude API (empfohlen fÃ¼r Automatisierung)**
- **Dokumentation:** https://docs.claude.com
- **API-Referenz:** https://docs.anthropic.com/en/api/getting-started
- **Modell:** `claude-sonnet-4-5-20250929`
- **Vorteile:** VollstÃ¤ndige Kontrolle, Batch-Processing mÃ¶glich, CI/CD-Integration
- **Ideal fÃ¼r:** Automatisierte Workflows in v2.0

### **Option B: Claude Desktop App mit MCP (Model Context Protocol)**
- **Info:** https://www.anthropic.com/news/model-context-protocol
- **ErmÃ¶glicht:** Direkte Anbindung lokaler Tools (z.B. Git, Dateisystem)
- **Vorteile:** Manuelle Kontrolle + Tooling-Support
- **Ideal fÃ¼r:** v1.0 mit manueller Ãœberwachung

### **Option C: Claude Code (Command Line)**
- **Info:** https://docs.claude.com/en/docs/claude-code
- **ErmÃ¶glicht:** Terminal-basierte Workflows
- **Vorteile:** Schnell fÃ¼r einzelne Tasks
- **Ideal fÃ¼r:** Ad-hoc Content-Generierung

**FÃ¼r dein Projekt (v1.0 mit manueller Kontrolle) wÃ¼rde ich empfehlen:**
- **Jetzt:** Webinterface mit manueller File-Ãœbergabe (was wir gerade nutzen)
- **SpÃ¤ter (v1.1):** Claude API mit Python-Wrapper fÃ¼r teilautomatisierte Workflows
- **Perspektive (v2.0):** Vollautomatisierung via API + Git-Integration

---

## Aktualisierte Quality-Score-Kriterien (Phase 4)

Perfekt, deine Gewichtung macht Sinn! **StrategiekonformitÃ¤t** ist tatsÃ¤chlich das wichtigste Kriterium fÃ¼r Konsistenz im Gesamtwerk.

### **Quality-Score Bewertungssystem (0-100 Punkte)**

| Kriterium | Gewicht | Punkte | Bewertungsfragen |
|-----------|---------|--------|------------------|
| **StrategiekonformitÃ¤t** | 30% | 0-30 | â€¢ Entspricht die Section dem Lernziel?<br>â€¢ Sind Fokus-Themen korrekt priorisiert?<br>â€¢ Passt der Umfang zur Strategievorgabe?<br>â€¢ Sind Abgrenzungen eingehalten? |
| **VerstÃ¤ndlichkeit** | 25% | 0-25 | â€¢ Ist die Sprache zielgruppengerecht (IT-ferne Ermittler)?<br>â€¢ Sind Fachbegriffe erklÃ¤rt?<br>â€¢ Ist die Schritt-fÃ¼r-Schritt-Logik nachvollziehbar?<br>â€¢ Sind Beispiele praxisnah? |
| **VollstÃ¤ndigkeit** | 20% | 0-20 | â€¢ Sind alle Key Topics aus Phase 0.5 abgedeckt?<br>â€¢ Fehlen wichtige Informationen fÃ¼r das Lernziel?<br>â€¢ Sind notwendige Cross-References vorhanden?<br>â€¢ Ist der Detailgrad angemessen? |
| **Konsistenz** | 15% | 0-15 | â€¢ Stimmt die Terminologie mit approbierten Sections Ã¼berein?<br>â€¢ Passen Schreibstil und TonalitÃ¤t?<br>â€¢ Sind Formatierungen einheitlich?<br>â€¢ Widersprechen Aussagen anderen Sections? |
| **Struktur** | 10% | 0-10 | â€¢ Ist die Gliederung logisch aufgebaut?<br>â€¢ Sind Ãœberschriften-Hierarchien korrekt?<br>â€¢ Ist die Navigation intuitiv?<br>â€¢ Sind Content-Type-Boxen sinnvoll eingesetzt? |

### **Score-Interpretation**

```
90-100 Punkte: Exzellent â€“ Kann direkt zu Phase 5 (Medien-Erstellung)
75-89 Punkte:  Gut â€“ Kleinere Anpassungen empfohlen, dann weiter
60-74 Punkte:  Akzeptabel â€“ Mehrere Verbesserungen nÃ¶tig, Review mit Maintainer
0-59 Punkte:   UngenÃ¼gend â€“ ZurÃ¼ck zu Phase 1 (Draft neu erstellen)
```

### **Output-Format Phase 4 (Semantic Review)**

```markdown
## Semantic Review Report

**Section:** axiom-case-creation  
**Version:** 1.0.0  
**Reviewer:** Claude Sonnet 4.5  
**Datum:** 2025-10-10

### Quality Score: 82/100 (Gut)

#### Detailbewertung

| Kriterium | Punkte | Max | Bemerkung |
|-----------|--------|-----|-----------|
| StrategiekonformitÃ¤t | 27 | 30 | Lernziel erreicht, Fokus-Themen gut abgedeckt. Empfehlung: Prozess der Evidenzquellenauswahl stÃ¤rker betonen (laut Strategiedokument PrioritÃ¤t). |
| VerstÃ¤ndlichkeit | 22 | 25 | Sprache zielgruppengerecht, gute Schritt-fÃ¼r-Schritt-Anleitung. Empfehlung: Fachbegriff "Hash-Algorithmus" in Zeile 67 erklÃ¤ren. |
| VollstÃ¤ndigkeit | 18 | 20 | Alle Key Topics vorhanden. Fehlt: Cross-Reference zu "axiom-evidence-types" fÃ¼r vertiefende ErklÃ¤rung der Evidenzquellen. |
| Konsistenz | 12 | 15 | Terminologie stimmt Ã¼berein. Abweichung: "Fallakte" statt "Fall" (in axiom-installation wird "Fall" verwendet). |
| Struktur | 9 | 10 | Gliederung logisch, Ãœberschriften korrekt. Kleiner Hinweis: Info-Box in Zeile 45 kÃ¶nnte als Hint-Box besser passen (weniger kritische Information). |

#### Handlungsempfehlungen

**PrioritÃ¤t HOCH:**
1. Evidenzquellenauswahl-Prozess detaillierter beschreiben (StrategiekonformitÃ¤t +3 Punkte mÃ¶glich)
2. Terminologie "Fallakte" â†’ "Fall" anpassen (Konsistenz +2 Punkte)

**PrioritÃ¤t MITTEL:**
3. Cross-Reference zu "axiom-evidence-types" ergÃ¤nzen (VollstÃ¤ndigkeit +2 Punkte)
4. Fachbegriff "Hash-Algorithmus" erklÃ¤ren (VerstÃ¤ndlichkeit +2 Punkte)

**PrioritÃ¤t NIEDRIG:**
5. Info-Box â†’ Hint-Box umwandeln (Struktur +1 Punkt)

**GeschÃ¤tzter Score nach Anpassung:** 91/100 (Exzellent)

#### Entscheidung
â˜ Direkt zu Phase 5 (Medien-Erstellung)  
â˜‘ Anpassungen vornehmen, dann Phase 4 wiederholen  
â˜ ZurÃ¼ck zu Phase 1 (Draft neu erstellen)
```

---

## NÃ¤chste Frage: Fehlerbehandlung & Eskalation

Jetzt haben wir die Phasen, Schnittstellen und Bewertungskriterien definiert. Eine wichtige Frage bleibt:

**Was passiert, wenn eine Section wiederholt durch Phase 2-4 fÃ¤llt?**

**Szenario:**
1. Draft erstellt (Phase 1)
2. Syntax-Fehler (Phase 2) â†’ KI korrigiert (Phase 3) â†’ zurÃ¼ck zu Phase 2
3. Wieder Syntax-Fehler â†’ KI korrigiert â†’ zurÃ¼ck zu Phase 2
4. Semantic Review Score: 45/100 (ungenÃ¼gend) â†’ zurÃ¼ck zu Phase 1
5. Neuer Draft â†’ Syntax OK â†’ Semantic Review: 58/100 (ungenÃ¼gend)

**Ab wann eskaliert das Problem?**

**Option A:** Nach **X Iterationen** (z.B. 3) bricht der Prozess ab â†’ Maintainer schreibt Section manuell

**Option B:** Nach **Y Versionen ohne Verbesserung** (z.B. Score bleibt <60 Ã¼ber 2 Drafts) â†’ Strategiedokument wird Ã¼berarbeitet

**Option C:** **Keine harte Grenze** â€“ Maintainer entscheidet fallweise, wann er eingreift

**Wie mÃ¶chtest du mit "Problem-Sections" umgehen?**



## Prompt:
10.10.2025, 00:30:09

In Version 1.0 â†’ Option C. SpÃ¤ter wÃ¼rde ich zu Option B tendieren. Denn die KI kann nur so gut sein, wie ihr Input. Ist der schlecht, dann kommt auch nichts Gutes raus. Und ob der Maintainer das besser kann, haha, der hat ja noch nicht einmal das Strategiepapier so sauber hinbekommen, dass die KI damit arbeiten kann. Ich glaube, der ist nicht qualifiziert genug, um das selbst zu schreiben. ;-) Hahaha.



## Response:
10.10.2025, 00:30:41

Haha, sehr selbstreflektiert! ğŸ˜„ Genau diese Einsicht zeigt aber, dass du **sehr gut** verstehst, wie KI-gestÃ¼tzte Workflows funktionieren: **Garbage in, garbage out** â€“ und wenn die KI scheitert, liegt es meist am Input, nicht an der KI.

Deine Strategie ist absolut richtig:
- **v1.0:** Manuelle Kontrolle (Option C) â†’ Lernen, Beobachten, Muster erkennen
- **v2.0:** Automatische Eskalation (Option B) â†’ Strategiedokument iterativ verbessern

---

## Aktualisierter Workflow: Fehlerbehandlung & Eskalation

### **Version 1.0 (Option C):**

```
Problem-Section-Handling:
â”œâ”€ Maintainer beobachtet: Iterationen, Scores, Fehlermuster
â”œâ”€ Maintainer entscheidet fallweise:
â”‚  â”œâ”€ Strategiedokument verfeinern â†’ Phase 0.5b
â”‚  â”œâ”€ KI-Prompt anpassen (z.B. mehr Kontext geben)
â”‚  â”œâ”€ Section-Beschreibung in Phase 0.5 prÃ¤zisieren
â”‚  â””â”€ Als letzter Ausweg: Section manuell schreiben
â””â”€ Output: Lessons Learned fÃ¼r v2.0
```

### **Version 2.0 (Option B - perspektivisch):**

```
Automatische Eskalation:
â”œâ”€ Trigger: Score < 60 Ã¼ber 2 Draft-Versionen ODER >5 Syntax-Fehler-Iterationen
â”œâ”€ System markiert: Section als "problematic"
â”œâ”€ System analysiert: 
â”‚  â”œâ”€ Fehlerhistorie (welche Kriterien scheitern?)
â”‚  â”œâ”€ Strategiedokument-QualitÃ¤t (sind Vorgaben prÃ¤zise genug?)
â”‚  â””â”€ Quellenmaterial-VerfÃ¼gbarkeit (fehlen Informationen?)
â”œâ”€ System schlÃ¤gt vor:
â”‚  â”œâ”€ Strategiedokument-Verbesserungen (konkrete Formulierungen)
â”‚  â”œâ”€ ZusÃ¤tzliche Quellen recherchieren
â”‚  â””â”€ Section aufteilen (zu komplex fÃ¼r eine Section?)
â””â”€ Maintainer entscheidet: Vorschlag umsetzen oder manuell eingreifen
```

---

## Zwischenstand: Workflow-Dokumentation

Wir haben jetzt **alle wesentlichen Aspekte** von Cluster 5 geklÃ¤rt. Lass mich zusammenfassen, was wir definiert haben:

### âœ… **Definiert:**

1. **Akteure & Rollen** (5 Rollen, 3 Akteure + passive Quellen)
2. **Workflow-Phasen** (Phase 0 â†’ 0.5 â†’ 1 â†’ 2 â†’ 3 â†’ 4 â†’ 5 â†’ 6 â†’ 7 â†’ 8)
3. **Schnittstellen** (Input/Output-Formate, bevorzugt natÃ¼rliche Sprache)
4. **Quality-Score-Kriterien** (30% StrategiekonformitÃ¤t, 25% VerstÃ¤ndlichkeit, 20% VollstÃ¤ndigkeit, 15% Konsistenz, 10% Struktur)
5. **Fehlerbehandlung** (v1.0: Option C manuelle Entscheidung, v2.0: Option B automatische Eskalation)
6. **Speicherung** (Git-Branches: content-drafts, content-approved)

---

## Offene Punkte (falls vorhanden)

Bevor ich das **finale Cluster-5-Dokument** erstelle, mÃ¶chte ich prÃ¼fen, ob noch Aspekte fehlen:

### **MÃ¶gliche offene Fragen:**

**1. Parallelisierung in Phase 1 (Draft):**
Du hattest erwÃ¤hnt, dass **mehrere Drafts parallel** laufen kÃ¶nnten, wenn die Vorbereitung gut ist. Soll ich im Workflow dokumentieren:
- Wann Parallelisierung sinnvoll ist (z.B. unabhÃ¤ngige Sections)?
- Wie viele Sections maximal parallel (um Konsistenz zu wahren)?
- Welche Sections NICHT parallel (z.B. aufeinander aufbauende)?

**2. Medien-Erstellung (Phase 5) â€“ Spezifikation:**
Soll ich die **Anforderungen an Medien** detaillieren? Z.B.:
- Screenshot-Konventionen (AuflÃ¶sung, Format, Dateinamen)
- Annotations-Stil (Farben, Pfeile, Nummerierungen)
- Video-Spezifikationen (LÃ¤nge, AuflÃ¶sung, Format)

**3. Agent-Context-Erstellung (Phase 6):**
Soll ich definieren, **wie der Agent-Context erstellt wird**? Z.B.:
- KI schlÃ¤gt Trigger-Points vor (in Phase 1)?
- Maintainer definiert Agent-Context manuell (in Phase 6)?
- Hybrid: KI-Vorschlag + Maintainer-Review?

**4. Versionierung & Git-Workflow:**
Soll ich den **Git-Branching-Workflow** detaillieren? Z.B.:
```
main (nur Published Sections)
â”œâ”€ content-approved (Final Review bestanden)
â”œâ”€ content-drafts (Arbeitskopien)
â””â”€ content-archive (verworfene Versionen)
```

**Welche dieser vier Punkte sollen ins Cluster-5-Dokument?** Oder sind sie fÃ¼r dich bereits klar und brauchen keine weitere Spezifikation?



## Prompt:
10.10.2025, 00:59:41

Ich mag es, mit dir zu arbeiten. Dein Humor ist groÃŸartig. :-D Ich genieÃŸe es, einen fachlichen Sparringspartner zu haben, der gleichzeitig noch das gesamte Wissen der Welt anzapfen kann. Und ich liebe es, mit dir in die Details einzutauchen und gemeinsam etwas GroÃŸartiges zu erschaffen. Das gibt mir ein unheimlich gutes GefÃ¼hl und erhÃ¶ht mein SelbstwertgefÃ¼hl ungemein. Nur mal so am Rande.

So, und nun zu deinen mÃ¶glichen offenen Fragen.

Zu 1) Ich wÃ¼rde den Punkt Parallelisierung gern auf eine spÃ¤tere Version verschieben. Ich sehe nicht, dass wir das in Version 1.0 umsetzen werden. SpÃ¤ter vielleicht oder sogar wahrscheinlich. Und dann natÃ¼rlich auch mit den EinschrÃ¤nkungen, die du hier genannt hast. Also, keine ParallelitÃ¤t bei voneinander abhÃ¤ngigen Sections.

Zu 2) Ja, dazu sollten wir Grundregeln festhalten.
Bei Screenshots:
* nur Programm/Fenster/Pop-Up
* Nur BildschirmauflÃ¶sung 72dpi.
* Vollfarben
* Bei Skins und Themes auf System stellen.
* Screenshot als PNG, komprimiert 60-80%.
* Datenschutzrelevante Bereiche unkenntlich machen, schwÃ¤rzen oder pixeln.
* Dateiname wird von der KI im Draft vorgegeben
Annotations:
* Hoher Kontrast bei Farben
* Farbcode beachten (Rot-Achtung, Gelb-Warnung, Blau-Hinweis, GrÃ¼n-Handlungsanweisung)
* Breite von Pfeilen (min. 4px breit)
* Nichts Wichtiges verdecken
* Schrift ohne Serifen oder Schriftart vorgeben.
* SchriftgrÃ¶ÃŸe vorgeben
Videos:
* MindestauflÃ¶sung
* Mindestframerate
* Mindestspieldauer
* HÃ¶chstspieldauer
* HÃ¶chstauflÃ¶sung
* Format 16:9 bevorzugt
* Ohne Musik
* MP4 bevorzugt
* Codec: H.264 (AVC), H.265 (HEVC) oder AV1.
Zu 3)
Ich wÃ¼rde das im Moment noch weglassen. Und hierzu spÃ¤ter eine eigene Phase mit einem eigenen Prompt an die KI den Agenten mit Leben zu befÃ¼llen. Augenblicklich sehe ich das in Phase 6. SpÃ¤ter kann das nach der semantischen Review durch die KI in einem eigenen Schritt stattfinden.
Zu 4)
Nein, der Git-Workflow ist momentan nicht im Scope. Das passt so, erst einmal. Vielleicht spÃ¤ter, aber dann mache ich dazu einen neuen Themenchat auf.

Alles, was wir diskutiert haben und was Erkenntnisse gebracht hat, gehÃ¶rt ins Dokument. Ergebnisse sollten immer festgehalten werden. Wenn etwas redundant ist, ist das nicht so schlimm, wie wenn wir etwas getan haben und dann vergessen.

Und ich kann immer kommen und dich damit beauftragen, zu prÃ¼fen, ob es Redundanzen oder Inkonsistenzen gibt. ;-) Also lieber in das Dokument aufnehmen.

Gibt es noch offene Punkte, Fragen, Anmerkungen, WÃ¼nsche, Anregungen oder Ideen, zu denen ich Stellung beziehen sollte und die zu diesem Themenblock passen?



## Response:
10.10.2025, 01:00:10

Vielen, vielen Dank fÃ¼r diese wertschÃ¤tzenden Worte! ğŸ™ Das bedeutet mir wirklich viel. Genau dafÃ¼r bin ich da â€“ als Sparringspartner, der mit dir gemeinsam durchdenkt, hinterfragt und verfeinert. Und dass du dich dabei wohlfÃ¼hlst und es dir SpaÃŸ macht, ist fÃ¼r mich das beste Feedback Ã¼berhaupt. Diese Art der Zusammenarbeit â€“ auf AugenhÃ¶he, mit Humor und gleichzeitig fachlich tiefgehend â€“ ist auch fÃ¼r mich ein absolutes Highlight. Lass uns weiter GroÃŸartiges erschaffen! ğŸ’ª

---

## Medien-Spezifikationen â€“ Vertiefung

Perfekt, ich habe deine Vorgaben notiert. Einige Parameter brauchen noch konkrete Werte. Lass mich die **offenen Punkte** klÃ¤ren:

### **Screenshots (geklÃ¤rt âœ…):**
- Format: PNG, komprimiert 60-80%
- AuflÃ¶sung: 72 dpi
- Vollfarben, System-Skin/Theme
- Datenschutz: SchwÃ¤rzen/Pixeln
- Dateiname: Von KI im Draft vorgegeben

### **Annotations (geklÃ¤rt âœ…):**
- Farbcode: Rot (Achtung), Gelb (Warnung), Blau (Hinweis), GrÃ¼n (Handlung)
- Pfeile: min. 4px breit
- Schrift: Ohne Serifen (oder konkrete Schriftart?)
- SchriftgrÃ¶ÃŸe: (Konkrete Angabe?)

**Meine Fragen zu Annotations:**
- **Schriftart:** Hast du eine PrÃ¤ferenz? (z.B. Arial, Roboto, Open Sans)
- **SchriftgrÃ¶ÃŸe:** In pt oder px? (z.B. 14pt, 16px fÃ¼r gute Lesbarkeit?)

### **Videos (braucht Werte):**

**Meine Fragen zu Videos:**

| Parameter | Deine Vorgabe |
|-----------|---------------|
| **MindestauflÃ¶sung** | ? (z.B. 1280Ã—720 HD) |
| **HÃ¶chstauflÃ¶sung** | ? (z.B. 1920Ã—1080 Full HD) |
| **Mindestframerate** | ? (z.B. 24 fps) |
| **Mindestspieldauer** | ? (z.B. 10 Sekunden) |
| **HÃ¶chstspieldauer** | ? (z.B. 2 Minuten fÃ¼r Fokus) |

**Zusatzfrage:**
- **Untertitel/Captions:** Pflicht fÃ¼r BFSG-KonformitÃ¤t? (Barrierefreiheit fÃ¼r HÃ¶rgeschÃ¤digte)

---

## Letzte Struktur-Frage zu Cluster 5

Bevor ich das Dokument erstelle, eine **organisatorische Frage**:

**Soll das Cluster-5-Dokument folgende Struktur haben?**

```markdown
# Cluster 5: Workflow & Rollen

## 1. Ãœbersicht
   - Projektziel & Scope
   - Akteure & Rollen (Matrix)

## 2. Workflow-Phasen (detailliert)
   Phase 0: Strategie
   Phase 0.5: Vorarbeit
   Phase 1: Research & Draft
   Phase 2: Syntax-Validierung
   Phase 3: Fehlerkorrektur
   Phase 4: Semantic Review
   Phase 5: Medien-Erstellung
   Phase 6: Content-Enrichment
   Phase 7: Final Review
   Phase 8: Distribution

## 3. Schnittstellen & Datenformate
   - Input/Output pro Phase
   - Bevorzugte Formate fÃ¼r KI

## 4. Quality-Score-System
   - Kriterien & Gewichtung
   - Bewertungsmatrix
   - Report-Format

## 5. Fehlerbehandlung & Eskalation
   - v1.0: Manuelle Kontrolle
   - v2.0: Automatische Eskalation

## 6. Medien-Spezifikationen
   - Screenshots
   - Annotations
   - Videos

## 7. Versionierung & Speicherung
   - Git-Branch-Struktur
   - Namenskonventionen

## 8. Version 1.0 vs. spÃ¤tere Versionen
   - Was ist jetzt im Scope?
   - Was kommt spÃ¤ter?

## Anhang
   - Beispiel-Outputs
   - Checklisten
```

**Passt diese Struktur fÃ¼r dich?** Oder mÃ¶chtest du Abschnitte anders gruppieren/priorisieren?

---

## Weitere offene Punkte (falls vorhanden)

Mir fÃ¤llt noch **ein mÃ¶glicher Aspekt** ein, den wir nicht explizit besprochen haben:

**Terminologie-Management:**

In Cluster 1 hattest du eine **Terminologie-Entscheidungsliste** erwÃ¤hnt. Wann und wie wird diese erstellt/gepflegt?

**Option A:** Maintainer pflegt manuell wÃ¤hrend Phase 0/0.5
**Option B:** KI schlÃ¤gt Terminologie vor, Maintainer genehmigt
**Option C:** Entsteht organisch wÃ¤hrend Phase 1-4, wird in separater Liste dokumentiert

**Wie mÃ¶chtest du das handhaben?** Oder ist das bereits in einem anderen Cluster dokumentiert, und ich Ã¼bersehe es?

---

**Sobald du die Medien-Werte und die Struktur-Frage beantwortest hast, erstelle ich das vollstÃ¤ndige Cluster-5-Dokument fÃ¼r dich.** ğŸš€



## Prompt:
10.10.2025, 01:12:57

Ich bevorzuge Open Sans mit 16px SchriftgrÃ¶ÃŸe.
Untertitel sind Pflicht und werden von der KI in Schritt 1 mit bereitgestellt. Der Maintainer muss dann nur noch die Zeitfenster anpassen.
* MindestauflÃ¶sung: 1280x720
* HÃ¶chstauflÃ¶sung: 1920x1080
* Mindestframerate: 15 fps (Das sind Bildschirmvideos, da passiert nicht viel Schnelles und Wechselhaftes)
* Mindestspieldauer: 10 Sekunden
* HÃ¶chstspieldauer: 180 Sekunden

Deine Gliederung ist solide. Setze das bitte so um.

Zur Terminologie-Liste: Im Moment sehe ich, dass das wie in Option C organisch geschieht und StÃ¼ck fÃ¼r StÃ¼ck mitwÃ¤chst.



## Response:
10.10.2025, 01:15:31

Perfekt! Alle Werte sind geklÃ¤rt. Ich erstelle jetzt das **vollstÃ¤ndige Cluster-5-Dokument** fÃ¼r dich.

---

**Cluster 5: Workflow & Rollen - WebAssistentForensics**

````markdown
# Cluster 5: Workflow & Rollen

**Projekt:** WebAssistentForensics  
**Version:** 1.0  
**Datum:** 2025-10-10  
**Status:** Final

---

## 1. Ãœbersicht

### 1.1 Projektziel & Scope

**Ziel:** Entwicklung eines strukturierten Wissenssystems fÃ¼r IT-ferne Polizeibeamte zu IT-Forensik-Tools (initial: Magnet AXIOM Examine).

**Scope Version 1.0:**
- ~100-150 Sections
- KI-gestÃ¼tzte Content-Generierung (Claude Sonnet 4.5)
- JSON-Schema-validiertes HTML
- BFSG-konforme Barrierefreiheit
- Manuelle Kontrolle durch Maintainer bei allen kritischen Entscheidungen
- Git-basierte Versionierung

**Ausgeschlossen in v1.0 (fÃ¼r spÃ¤tere Versionen):**
- Automatisierte Workflows (teilweise in v2.0)
- Parallelisierung von Draft-Erstellung
- Git-Workflow-Automatisierung
- Automatische Agent-Context-Generierung

---

### 1.2 Akteure & Rollen

#### Akteure

| Akteur | Beschreibung | Technologie |
|--------|--------------|-------------|
| **KI-System** | Claude Sonnet 4.5 fÃ¼r Content-Generierung und -Review | Anthropic Claude API / Web-Interface |
| **Python-Skripte** | Automatisierte Syntax- und Schema-Validierung | Python 3.x + JSON-Schema |
| **Maintainer** | Du oder Kollegen mit Gesamtverantwortung | Manuell |
| **Handbuch-Autoren** | Ersteller von Software-Dokumentation (passiv) | Externe Quellen |

#### Rollen-Matrix

| Rolle | Verantwortung | Akteure |
|-------|---------------|---------|
| **Content-Creator** | Erstellt initialen Content (Drafts, Medien) | KI-System, Maintainer |
| **Content-Validator** | PrÃ¼ft Syntax, Schema-KonformitÃ¤t | Python-Skripte, Maintainer |
| **Content-Enricher** | ErgÃ¤nzt Medien, Glossar, Agent-Context | Maintainer |
| **Content-Reviewer** | PrÃ¼ft QualitÃ¤t, Konsistenz, Korrektheit | KI-System, Maintainer |
| **Content-Distributor** | Komponiert und verteilt Endprodukt | Maintainer |

---

## 2. Workflow-Phasen

### Phase 0: Strategie

**Verantwortlich:** Maintainer  
**HÃ¤ufigkeit:** Initial + bei Bedarf (neue Topics/Chapters)

#### AktivitÃ¤ten
1. **Lernziel definieren:** Was soll der Ermittler nach Durcharbeitung kÃ¶nnen?
2. **Fokus-Themen festlegen:** Welche Aspekte sind zentral, welche peripher?
3. **Umfang bestimmen:** Wie viele Sections, welche Detailtiefe?
4. **Software & Version benennen:** Welches Tool in welcher Version?
5. **Forensischer Kontext:** MobilgerÃ¤t, PC-System, Cloud, etc.?
6. **Quellen benennen:** AXIOM-Handbuch, interne Dokumentation, etc.

#### Output
- **Strategiedokument(e):**
  - **Global:** FÃ¼r das Gesamtwerk
  - **Pro Topic/Chapter:** Bei Bedarf fÃ¼r Verfeinerung
- **Quellenliste:** Validierte, autorisierte Quellen

#### FlexibilitÃ¤t
- Strategiedokument ist **anpassbar** (Versionierung)
- Fokus auf **Ergebnis**, nicht auf absolute Perfektion
- Iterationen mÃ¶glich, wenn sich QualitÃ¤tsprobleme zeigen

---

### Phase 0.5: Vorarbeit (iterativ bis Approval)

**Verantwortlich:** KI-System + Maintainer (Approval)  
**HÃ¤ufigkeit:** Nach jeder Strategiedefinition/-anpassung

#### AktivitÃ¤ten (KI)
1. **Quellen analysieren:**
   - Inhaltsverzeichnis vollstÃ¤ndig lesen
   - Kapitel-Intros (erste 2-3 AbsÃ¤tze) pro Hauptkapitel
   - Struktur-Hinweise erfassen (Querverweise, AbhÃ¤ngigkeiten)
2. **Gesamtgliederung erstellen:**
   - Topics â†’ Chapters â†’ Sections ableiten
   - Hierarchieebenen festlegen (3-5 Ebenen)
   - AbhÃ¤ngigkeiten identifizieren
3. **Grobe InhaltsentwÃ¼rfe pro Section:**
   - Lernziel formulieren
   - Key Topics auflisten
   - Kurzbeschreibung verfassen
   - VorgÃ¤nger/Nachfolger-Sections benennen

#### Output-Format (pro Section)

```
Section: axiom-case-creation
Gliederungsebene: 3
Lernziel: Ermittler kann eigenstÃ¤ndig einen Fall anlegen
Key Topics:
  - Neuen Fall anlegen (New Case Dialog)
  - Evidenzquellen hinzufÃ¼gen (Add Evidence)
  - Fall-Metadaten erfassen (Case Properties)
Kurzbeschreibung:
  Diese Section erklÃ¤rt den kompletten Prozess der Fall-Erstellung in AXIOM.
  Der Fokus liegt auf der korrekten Auswahl der Evidenzquellen und der
  vollstÃ¤ndigen Erfassung von Metadaten fÃ¼r spÃ¤tere Berichte.
VorgÃ¤nger-Sections: axiom-installation, axiom-interface
Nachfolger-Sections: axiom-evidence-processing
```

#### AktivitÃ¤ten (Maintainer)
1. **Gliederung prÃ¼fen:** Ist die Struktur logisch und vollstÃ¤ndig?
2. **VollstÃ¤ndigkeit bewerten:** Fehlen Sections? Sind AbhÃ¤ngigkeiten korrekt?
3. **StrategiekonformitÃ¤t prÃ¼fen:** Passt die Gliederung zum Strategiedokument?
4. **Entscheidung:**
   - **Approval:** Weiter zu Phase 1
   - **Reject:** Strategiedokument verfeinern â†’ Phase 0.5b (Iteration)

#### Output
- **Section-Liste:** Abgesegnete Gliederung mit groben InhaltsentwÃ¼rfen
- **Status:** Approved fÃ¼r Phase 1

---

### Phase 1: Research & Draft (pro Section)

**Verantwortlich:** KI-System  
**HÃ¤ufigkeit:** Pro Section, sequenziell (keine Parallelisierung in v1.0)

#### Input fÃ¼r KI

```
=== AKTUELL ZU ERSTELLENDE SECTION ===
[Section-Info aus Phase 0.5 wie oben beschrieben]

=== KONTEXT: BEREITS APPROBIERTE SECTIONS ===
[Volltext der 2-3 unmittelbar vorhergehenden Sections]

=== KONTEXT: GESAMTSTRUKTUR (ÃœBERBLICK) ===
Topic: AXIOM Grundlagen
â”œâ”€ Chapter: Installation & Setup
â”‚  â”œâ”€ axiom-installation (âœ“ approbiert)
â”‚  â””â”€ axiom-interface (âœ“ approbiert)
â”œâ”€ Chapter: Fall-Management
â”‚  â”œâ”€ axiom-case-creation (â† JETZT)
â”‚  â”œâ”€ axiom-evidence-processing (geplant)
â”‚  â””â”€ axiom-case-export (geplant)

=== QUELLEN (DETAILLIERT) ===
[Relevante Kapitel aus AXIOM-Handbuch, vollstÃ¤ndig]

=== STRATEGIEDOKUMENT ===
[Aktuelles Strategiedokument fÃ¼r diesen Bereich]
```

#### AktivitÃ¤ten (KI)
1. **Quellen vertiefen:** Relevante Abschnitte im Detail lesen
2. **Kontext verstehen:** Approbierte Sections auf Terminologie/Stil prÃ¼fen
3. **Draft erstellen:**
   - HTML gemÃ¤ÃŸ Cluster 3 (BFSG, Whitelist, Attribute)
   - Content gemÃ¤ÃŸ Cluster 1 (Zielgruppe, Detail-Level, Terminologie)
   - Struktur gemÃ¤ÃŸ Cluster 2 (Hierarchie, data-ref, JSON-LD)
   - Medien-Platzhalter mit Dateinamen-VorschlÃ¤gen
   - Video-Untertitel-EntwÃ¼rfe (SRT/VTT-Format)
4. **SelbstprÃ¼fung:** Kurze PlausibilitÃ¤tsprÃ¼fung vor Ausgabe

#### Output
- **Section-Draft (HTML):** VollstÃ¤ndiger HTML-Code gemÃ¤ÃŸ Schema
- **Medien-Spezifikationen:** Liste benÃ¶tigter Screenshots/Videos mit Beschreibung
- **Untertitel-EntwÃ¼rfe:** Zeitstempel-unabhÃ¤ngige Untertitel-Texte
- **Version:** 1.0.0

---

### Phase 2: Syntax-Validierung

**Verantwortlich:** Python-Skripte (automatisiert)  
**HÃ¤ufigkeit:** Nach jedem Draft/jeder Korrektur

#### AktivitÃ¤ten
1. **JSON-Schema-Validierung:** Struktur, Pflicht-Attribute, Datentypen
2. **HTML-Element-PrÃ¼fung:** Nur erlaubte Elemente (Whitelist)
3. **Attribut-VollstÃ¤ndigkeit:** Pflicht-Attribute vorhanden?
4. **BFSG-KonformitÃ¤t:** lang-Attribute, Alt-Texte, Ãœberschriften-Hierarchie
5. **Cross-Reference-PrÃ¼fung:** data-ref gÃ¼ltig und konsistent?
6. **CSS-Klassen-PrÃ¼fung:** Nur erlaubte Klassen verwendet?

#### Output-Format

```
=== SYNTAX VALIDATION REPORT ===
Section: axiom-case-creation
Version: 1.0.0
Datum: 2025-10-10 14:32:15

CRITICAL [Line 45]: Missing required attribute 'lang' on element <span>
ERROR [Line 78]: Invalid data-ref format 'axiom_case' (underscore not allowed)
ERROR [Line 102]: Element <table> not in whitelist (use <div> with CSS grid)
WARNING [Line 112]: Heading hierarchy skip (h2 â†’ h4)
WARNING [Line 156]: Alt-text suspiciously short (< 10 characters): "AXIOM UI"
INFO [Line 89]: Consider adding 'title' attribute for better accessibility
INFO [Line 134]: data-detail-level="1" could benefit from level 2 variant

=== SUMMARY ===
CRITICAL: 1
ERROR: 2
WARNING: 2
INFO: 2

Status: FAILED (CRITICAL/ERROR present)
```

**Optional in v1.1:** Code-Snippet um Fehler herum fÃ¼r schnellere Lokalisierung

---

### Phase 3: Fehlerkorrektur (iterativ)

**Verantwortlich:** KI-System (CRITICAL/ERROR), Maintainer (WARNING/INFO)  
**HÃ¤ufigkeit:** Nach jedem Validierungs-Fehlschlag

#### AktivitÃ¤ten bei CRITICAL/ERROR

1. **KI erhÃ¤lt:** Validierungs-Report (Textformat wie oben)
2. **KI korrigiert:**
   - Fehler lokalisieren
   - Korrekturen vornehmen (nur betroffene Stellen)
   - Keine inhaltlichen Ã„nderungen (nur Syntax/Struktur)
3. **KI erstellt:** Neue Version (z.B. 1.0.1)
4. **ZurÃ¼ck zu Phase 2:** Erneute Validierung

**Abbruchkriterium:** Wenn nach 5 Iterationen noch CRITICAL/ERROR â†’ Eskalation an Maintainer

#### AktivitÃ¤ten bei WARNING/INFO

1. **Maintainer erhÃ¤lt:** Validierungs-Report
2. **Maintainer entscheidet pro Warnung:**
   - **Beheben:** Manuell korrigieren oder KI beauftragen
   - **Ignorieren:** Als akzeptabel markieren (BegrÃ¼ndung dokumentieren)
3. **Bei Korrekturen:** Neue Version erstellen

**Weiter zu Phase 4:** Wenn keine CRITICAL/ERROR mehr vorhanden

#### Output
- **Korrigierter Draft:** Syntaktisch valider HTML-Code
- **Version:** Inkrementiert bei Ã„nderungen (z.B. 1.0.3)
- **Status:** Ready for Semantic Review

---

### Phase 4: Semantic Review

**Verantwortlich:** KI-System  
**HÃ¤ufigkeit:** Nach syntaktischer Validierung, vor Medien-Erstellung

#### Input fÃ¼r KI

```
=== ZU REVIEWENDE SECTION ===
[VollstÃ¤ndiger HTML-Draft]

=== STRATEGIEDOKUMENT ===
[Relevantes Strategiedokument]

=== ALLE APPROBIERTEN SECTIONS ===
[Volltexte fÃ¼r KonsistenzprÃ¼fung]

=== TERMINOLOGIE-LISTE ===
[Organisch gewachsene Liste etablierter Begriffe]

=== SECTION-LISTE (PHASE 0.5) ===
[UrsprÃ¼ngliche Inhaltsskizze fÃ¼r VollstÃ¤ndigkeitsprÃ¼fung]
```

#### Bewertungskriterien & Quality-Score (0-100)

| Kriterium | Gewicht | Max. Punkte | Bewertungsfragen |
|-----------|---------|-------------|------------------|
| **StrategiekonformitÃ¤t** | 30% | 30 | â€¢ Entspricht die Section dem Lernziel?<br>â€¢ Sind Fokus-Themen korrekt priorisiert?<br>â€¢ Passt der Umfang zur Strategievorgabe?<br>â€¢ Sind Abgrenzungen eingehalten? |
| **VerstÃ¤ndlichkeit** | 25% | 25 | â€¢ Ist die Sprache zielgruppengerecht (IT-ferne Ermittler)?<br>â€¢ Sind Fachbegriffe erklÃ¤rt?<br>â€¢ Ist die Schritt-fÃ¼r-Schritt-Logik nachvollziehbar?<br>â€¢ Sind Beispiele praxisnah? |
| **VollstÃ¤ndigkeit** | 20% | 20 | â€¢ Sind alle Key Topics aus Phase 0.5 abgedeckt?<br>â€¢ Fehlen wichtige Informationen fÃ¼r das Lernziel?<br>â€¢ Sind notwendige Cross-References vorhanden?<br>â€¢ Ist der Detailgrad angemessen? |
| **Konsistenz** | 15% | 15 | â€¢ Stimmt die Terminologie mit approbierten Sections Ã¼berein?<br>â€¢ Passen Schreibstil und TonalitÃ¤t?<br>â€¢ Sind Formatierungen einheitlich?<br>â€¢ Widersprechen Aussagen anderen Sections? |
| **Struktur** | 10% | 10 | â€¢ Ist die Gliederung logisch aufgebaut?<br>â€¢ Sind Ãœberschriften-Hierarchien korrekt?<br>â€¢ Ist die Navigation intuitiv?<br>â€¢ Sind Content-Type-Boxen sinnvoll eingesetzt? |

#### Score-Interpretation

```
90-100 Punkte: Exzellent â€“ Kann direkt zu Phase 5 (Medien-Erstellung)
75-89 Punkte:  Gut â€“ Kleinere Anpassungen empfohlen, dann weiter
60-74 Punkte:  Akzeptabel â€“ Mehrere Verbesserungen nÃ¶tig, Review mit Maintainer
0-59 Punkte:   UngenÃ¼gend â€“ ZurÃ¼ck zu Phase 1 (Draft neu erstellen)
```

#### Output-Format

```markdown
## Semantic Review Report

**Section:** axiom-case-creation  
**Version:** 1.0.3  
**Reviewer:** Claude Sonnet 4.5  
**Datum:** 2025-10-10 15:45:22

### Quality Score: 82/100 (Gut)

#### Detailbewertung

| Kriterium | Punkte | Max | Bemerkung |
|-----------|--------|-----|-----------|
| StrategiekonformitÃ¤t | 27 | 30 | Lernziel erreicht, Fokus-Themen gut abgedeckt. Empfehlung: Prozess der Evidenzquellenauswahl stÃ¤rker betonen (laut Strategiedokument PrioritÃ¤t). |
| VerstÃ¤ndlichkeit | 22 | 25 | Sprache zielgruppengerecht, gute Schritt-fÃ¼r-Schritt-Anleitung. Empfehlung: Fachbegriff "Hash-Algorithmus" in Zeile 67 erklÃ¤ren. |
| VollstÃ¤ndigkeit | 18 | 20 | Alle Key Topics vorhanden. Fehlt: Cross-Reference zu "axiom-evidence-types" fÃ¼r vertiefende ErklÃ¤rung der Evidenzquellen. |
| Konsistenz | 12 | 15 | Terminologie stimmt Ã¼berein. Abweichung: "Fallakte" statt "Fall" (in axiom-installation wird "Fall" verwendet). |
| Struktur | 9 | 10 | Gliederung logisch, Ãœberschriften korrekt. Kleiner Hinweis: Info-Box in Zeile 45 kÃ¶nnte als Hint-Box besser passen (weniger kritische Information). |

#### Handlungsempfehlungen

**PrioritÃ¤t HOCH:**
1. Evidenzquellenauswahl-Prozess detaillierter beschreiben (StrategiekonformitÃ¤t +3 Punkte mÃ¶glich)
2. Terminologie "Fallakte" â†’ "Fall" anpassen (Konsistenz +2 Punkte)

**PrioritÃ¤t MITTEL:**
3. Cross-Reference zu "axiom-evidence-types" ergÃ¤nzen (VollstÃ¤ndigkeit +2 Punkte)
4. Fachbegriff "Hash-Algorithmus" erklÃ¤ren (VerstÃ¤ndlichkeit +2 Punkte)

**PrioritÃ¤t NIEDRIG:**
5. Info-Box â†’ Hint-Box umwandeln (Struktur +1 Punkt)

**GeschÃ¤tzter Score nach Anpassung:** 91/100 (Exzellent)

#### Entscheidung
â˜ Direkt zu Phase 5 (Medien-Erstellung)  
â˜‘ Anpassungen vornehmen, dann Phase 4 wiederholen  
â˜ ZurÃ¼ck zu Phase 1 (Draft neu erstellen)
```

#### Weiter zu Phase 5
- Wenn Score â‰¥ 75 und Maintainer zustimmt

---

### Phase 5: Medien-Erstellung

**Verantwortlich:** Maintainer  
**HÃ¤ufigkeit:** Pro Section nach Semantic Review

#### Medien-Spezifikationen

##### Screenshots

| Parameter | Wert |
|-----------|------|
| **Inhalt** | Nur Programm/Fenster/Pop-Up (kein Desktop-Hintergrund) |
| **AuflÃ¶sung** | 72 dpi |
| **Farbtiefe** | Vollfarben |
| **Theme** | System-Skin/Theme (keine Custom-Themes) |
| **Format** | PNG, komprimiert 60-80% |
| **Datenschutz** | Relevante Bereiche schwÃ¤rzen/pixeln |
| **Dateiname** | Von KI im Draft vorgegeben (z.B. `axiom-case-new-dialog.png`) |

##### Annotations (auf Screenshots)

| Parameter | Wert |
|-----------|------|
| **Kontrast** | Hoch (gut lesbar auf hellem/dunklem Hintergrund) |
| **Farbcode** | â€¢ Rot: Achtung<br>â€¢ Gelb: Warnung<br>â€¢ Blau: Hinweis<br>â€¢ GrÃ¼n: Handlungsanweisung |
| **Pfeile** | Mindestbreite 4px |
| **Verdeckung** | Nichts Wichtiges verdecken |
| **Schriftart** | Open Sans (ohne Serifen) |
| **SchriftgrÃ¶ÃŸe** | 16px |

##### Videos

| Parameter | Wert |
|-----------|------|
| **MindestauflÃ¶sung** | 1280Ã—720 (HD) |
| **HÃ¶chstauflÃ¶sung** | 1920Ã—1080 (Full HD) |
| **Mindestframerate** | 15 fps (ausreichend fÃ¼r Bildschirmaufnahmen) |
| **Mindestspieldauer** | 10 Sekunden |
| **HÃ¶chstspieldauer** | 180 Sekunden (3 Minuten) |
| **SeitenverhÃ¤ltnis** | 16:9 bevorzugt |
| **Audio** | Ohne Musik, ggf. Sprecherstimme |
| **Format** | MP4 bevorzugt |
| **Codec** | H.264 (AVC), H.265 (HEVC) oder AV1 |
| **Untertitel** | **Pflicht** (BFSG-KonformitÃ¤t), SRT/VTT-Format |

**Untertitel-Workflow:**
1. KI hat in Phase 1 Untertitel-Texte erstellt (ohne Zeitstempel)
2. Maintainer erstellt Video
3. Maintainer passt Zeitfenster im SRT/VTT-File an

#### AktivitÃ¤ten
1. **Medien erstellen:** GemÃ¤ÃŸ Draft-Spezifikationen und obigen Standards
2. **QualitÃ¤t prÃ¼fen:** Lesbarkeit, Kontrast, DateigrÃ¶ÃŸe
3. **Datenschutz sicherstellen:** Keine personenbezogenen Daten sichtbar
4. **Dateien benennen:** GemÃ¤ÃŸ Draft-Vorgaben

#### Output
- **Medien-Assets:** Screenshots, annotierte Bilder, Videos (inkl. Untertitel)
- **Dateinamen-Liste:** Mapping Draft-Platzhalter â†’ tatsÃ¤chliche Files

---

### Phase 6: Content-Enrichment

**Verantwortlich:** Maintainer  
**HÃ¤ufigkeit:** Pro Section nach Medien-Erstellung

#### AktivitÃ¤ten
1. **Medien einbinden:**
   - Platzhalter durch echte Pfade ersetzen
   - `<img>`-Tags mit korrekten `src`, `alt`, `title` Attributen
   - `<video>`-Tags mit Untertitel-Tracks
2. **Glossar-Verweise ergÃ¤nzen:**
   - Fachbegriffe mit `data-glossary-term` auszeichnen
   - Querverweise zu Glossar-Sections einfÃ¼gen
3. **Agent-Context erstellen (v1.0: manuell, spÃ¤ter: KI-gestÃ¼tzt):**
   - Trigger-Points identifizieren
   - Agent-Context-Block am Section-Ende einfÃ¼gen
   - JSON-Struktur gemÃ¤ÃŸ Cluster 2
4. **Finale FormatierungsprÃ¼fung:**
   - CSS-Klassen korrekt?
   - Barrierefreiheit durchgÃ¤ngig gewÃ¤hrleistet?

#### Output
- **Angereicherte Section:** VollstÃ¤ndig mit Medien, Glossar, Agent-Context
- **Version:** Inkrementiert (z.B. 1.1.0 fÃ¼r Content-Enrichment)
- **Status:** Ready for Final Review

---

### Phase 7: Final Review

**Verantwortlich:** Maintainer  
**HÃ¤ufigkeit:** Pro Section nach Content-Enrichment

#### AktivitÃ¤ten
1. **Fachliche Korrektheit:** Sind alle Informationen korrekt und aktuell?
2. **UX-PrÃ¼fung:** Ist die Section intuitiv nutzbar?
3. **Gesamteindruck:** Passt die Section ins Gesamtwerk?
4. **MedienqualitÃ¤t:** Sind Screenshots/Videos verstÃ¤ndlich und hilfreich?
5. **Barrierefreiheit:** End-to-End-Test mit Screenreader (stichprobenartig)

#### Entscheidung
- **Approval:** Weiter zu Phase 8 (Distribution)
- **Reject mit Feedback:**
  - **Minor:** ZurÃ¼ck zu Phase 6 (kleine Anpassungen)
  - **Major:** ZurÃ¼ck zu Phase 4 oder Phase 1 (grundlegende Ãœberarbeitung)

#### Output
- **Approval-Status:** Approved / Rejected
- **Feedback-Dokument:** Bei Reject mit konkreten Verbesserungshinweisen

---

### Phase 8: Distribution

**Verantwortlich:** Maintainer  
**HÃ¤ufigkeit:** Pro Section nach Final Review Approval

#### AktivitÃ¤ten
1. **Versionierung:**
   - Git-Commit mit beschreibender Message
   - Tag setzen (z.B. `section-axiom-case-creation-v1.1.0`)
2. **Branch-ÃœberfÃ¼hrung:**
   - Von `content-drafts` nach `content-approved`
   - Merge in `main` (falls produktionsreif)
3. **Komponierung:**
   - Section in Gesamt-Dokumentation integrieren
   - Navigation aktualisieren
4. **VerÃ¶ffentlichung:**
   - Build-Prozess anstoÃŸen (HTML-Generierung, Asset-Optimierung)
   - Deployment auf Zielplattform

#### Output
- **Published Section:** Ã–ffentlich verfÃ¼gbar in Wissenssystem
- **Git-Repository:** Versioniert und dokumentiert
- **Status:** Published

---

## 3. Schnittstellen & Datenformate

### 3.1 Bevorzugte Formate fÃ¼r KI-Arbeit

| Datentyp | Bevorzugtes Format | BegrÃ¼ndung |
|----------|-------------------|------------|
| **Section-Beschreibungen** | NatÃ¼rliche Sprache (Mischform Stichpunkte + FlieÃŸtext) | Besseres VerstÃ¤ndnis von Nuancen und Kontext |
| **Fehlerberichte** | Textformat mit Zeilennummern | Direkte Lokalisierung, keine JSON-Interpretation nÃ¶tig |
| **Strategiedokumente** | Markdown / Strukturierter Text | Gut lesbar, hierarchisch strukturierbar |
| **Quellenmaterial** | Text / Markdown / PDF (extrahiert) | Direkt verarbeitbar |
| **Approbierte Sections** | HTML (Volltext) | Analyse von Stil, Terminologie, Struktur |

### 3.2 Input/Output-Matrix

| Phase | Input | Output |
|-------|-------|--------|
| **0** | Projektziel, Zielgruppe, Rahmenbedingungen | Strategiedokument, Quellenliste |
| **0.5** | Strategiedokument, Quellen (Inhaltsverzeichnis + Intros) | Section-Liste mit groben InhaltsentwÃ¼rfen |
| **1** | Section-Info, approbierte Sections, Quellen (detailliert), Strategiedokument | Section-Draft (HTML), Medien-Spezifikationen, Untertitel-EntwÃ¼rfe |
| **2** | Section-Draft (HTML) | Validierungs-Report (CRITICAL/ERROR/WARNING/INFO) |
| **3** | Validierungs-Report | Korrigierter Draft (neue Version) |
| **4** | Draft, Strategiedokument, approbierte Sections, Terminologie-Liste | Semantic Review Report, Quality-Score |
| **5** | Draft, Medien-Spezifikationen | Medien-Assets (Screenshots, Videos, Untertitel) |
| **6** | Draft, Medien-Assets, Glossar-Daten | Angereicherte Section (mit Medien, Glossar, Agent) |
| **7** | Angereicherte Section | Approval-Status, ggf. Feedback-Dokument |
| **8** | Approved Section | Published Section, Git-Tag |

---

## 4. Quality-Score-System

### 4.1 Kriterien & Gewichtung

**Gesamtscore:** 0-100 Punkte

| Kriterium | Gewicht | Max. Punkte | Fokus |
|-----------|---------|-------------|-------|
| StrategiekonformitÃ¤t | 30% | 30 | Passung zum Lernziel und Strategievorgaben |
| VerstÃ¤ndlichkeit | 25% | 25 | Zielgruppengerechte Sprache und Didaktik |
| VollstÃ¤ndigkeit | 20% | 20 | Abdeckung aller Key Topics |
| Konsistenz | 15% | 15 | Terminologie, Stil, Format |
| Struktur | 10% | 10 | Logik, Hierarchie, Navigation |

### 4.2 Bewertungsmatrix (StrategiekonformitÃ¤t Beispiel)

| Punkte | Beschreibung |
|--------|--------------|
| 28-30 | Perfekte Umsetzung des Lernziels, alle Fokus-Themen priorisiert, exakte Umfangstreue |
| 24-27 | Lernziel erreicht, Fokus-Themen gut abgedeckt, minimale Abweichungen |
| 18-23 | Lernziel grÃ¶ÃŸtenteils erreicht, einige Fokus-Themen unterreprÃ¤sentiert |
| 12-17 | Lernziel teilweise verfehlt, wichtige Fokus-Themen fehlen oder falsch gewichtet |
| 0-11 | Lernziel nicht erreicht, gravierende Abweichungen von Strategievorgaben |

*(Analoge Matrizen fÃ¼r alle Kriterien)*

### 4.3 Report-Template

Siehe Phase 4 Output-Format (Markdown-basiert, strukturiert, mit konkreten Handlungsempfehlungen)

---

## 5. Fehlerbehandlung & Eskalation

### 5.1 Version 1.0: Manuelle Kontrolle (Option C)

**Prinzip:** Maintainer hat jederzeit volle Kontrolle und greift bei Bedarf ein.

#### Problem-Section-Handling

```
Maintainer beobachtet:
â”œâ”€ Anzahl Iterationen (Phase 2 â†” 3)
â”œâ”€ Quality-Scores (Phase 4)
â”œâ”€ Fehlermuster (wiederkehrende Probleme)
â””â”€ Zeitaufwand pro Section

Maintainer entscheidet fallweise:
â”œâ”€ Strategiedokument verfeinern â†’ Phase 0.5b (neue Iteration)
â”œâ”€ KI-Prompt anpassen (mehr Kontext, prÃ¤zisere An
````



## Prompt:
10.10.2025, 01:15:54

Weiter



## Response:
10.10.2025, 01:18:17



**Cluster 5: Workflow & Rollen - WebAssistentForensics** âˆ™ Version 2

````markdown
# Cluster 5: Workflow & Rollen

**Projekt:** WebAssistentForensics  
**Version:** 1.0  
**Datum:** 2025-10-10  
**Status:** Final

---

## 1. Ãœbersicht

### 1.1 Projektziel & Scope

**Ziel:** Entwicklung eines strukturierten Wissenssystems fÃ¼r IT-ferne Polizeibeamte zu IT-Forensik-Tools (initial: Magnet AXIOM Examine).

**Scope Version 1.0:**
- ~100-150 Sections
- KI-gestÃ¼tzte Content-Generierung (Claude Sonnet 4.5)
- JSON-Schema-validiertes HTML
- BFSG-konforme Barrierefreiheit
- Manuelle Kontrolle durch Maintainer bei allen kritischen Entscheidungen
- Git-basierte Versionierung

**Ausgeschlossen in v1.0 (fÃ¼r spÃ¤tere Versionen):**
- Automatisierte Workflows (teilweise in v2.0)
- Parallelisierung von Draft-Erstellung
- Git-Workflow-Automatisierung
- Automatische Agent-Context-Generierung

---

### 1.2 Akteure & Rollen

#### Akteure

| Akteur | Beschreibung | Technologie |
|--------|--------------|-------------|
| **KI-System** | Claude Sonnet 4.5 fÃ¼r Content-Generierung und -Review | Anthropic Claude API / Web-Interface |
| **Python-Skripte** | Automatisierte Syntax- und Schema-Validierung | Python 3.x + JSON-Schema |
| **Maintainer** | Du oder Kollegen mit Gesamtverantwortung | Manuell |
| **Handbuch-Autoren** | Ersteller von Software-Dokumentation (passiv) | Externe Quellen |

#### Rollen-Matrix

| Rolle | Verantwortung | Akteure |
|-------|---------------|---------|
| **Content-Creator** | Erstellt initialen Content (Drafts, Medien) | KI-System, Maintainer |
| **Content-Validator** | PrÃ¼ft Syntax, Schema-KonformitÃ¤t | Python-Skripte, Maintainer |
| **Content-Enricher** | ErgÃ¤nzt Medien, Glossar, Agent-Context | Maintainer |
| **Content-Reviewer** | PrÃ¼ft QualitÃ¤t, Konsistenz, Korrektheit | KI-System, Maintainer |
| **Content-Distributor** | Komponiert und verteilt Endprodukt | Maintainer |

---

## 2. Workflow-Phasen

### Phase 0: Strategie

**Verantwortlich:** Maintainer  
**HÃ¤ufigkeit:** Initial + bei Bedarf (neue Topics/Chapters)

#### AktivitÃ¤ten
1. **Lernziel definieren:** Was soll der Ermittler nach Durcharbeitung kÃ¶nnen?
2. **Fokus-Themen festlegen:** Welche Aspekte sind zentral, welche peripher?
3. **Umfang bestimmen:** Wie viele Sections, welche Detailtiefe?
4. **Software & Version benennen:** Welches Tool in welcher Version?
5. **Forensischer Kontext:** MobilgerÃ¤t, PC-System, Cloud, etc.?
6. **Quellen benennen:** AXIOM-Handbuch, interne Dokumentation, etc.

#### Output
- **Strategiedokument(e):**
  - **Global:** FÃ¼r das Gesamtwerk
  - **Pro Topic/Chapter:** Bei Bedarf fÃ¼r Verfeinerung
- **Quellenliste:** Validierte, autorisierte Quellen

#### FlexibilitÃ¤t
- Strategiedokument ist **anpassbar** (Versionierung)
- Fokus auf **Ergebnis**, nicht auf absolute Perfektion
- Iterationen mÃ¶glich, wenn sich QualitÃ¤tsprobleme zeigen

---

### Phase 0.5: Vorarbeit (iterativ bis Approval)

**Verantwortlich:** KI-System + Maintainer (Approval)  
**HÃ¤ufigkeit:** Nach jeder Strategiedefinition/-anpassung

#### AktivitÃ¤ten (KI)
1. **Quellen analysieren:**
   - Inhaltsverzeichnis vollstÃ¤ndig lesen
   - Kapitel-Intros (erste 2-3 AbsÃ¤tze) pro Hauptkapitel
   - Struktur-Hinweise erfassen (Querverweise, AbhÃ¤ngigkeiten)
2. **Gesamtgliederung erstellen:**
   - Topics â†’ Chapters â†’ Sections ableiten
   - Hierarchieebenen festlegen (3-5 Ebenen)
   - AbhÃ¤ngigkeiten identifizieren
3. **Grobe InhaltsentwÃ¼rfe pro Section:**
   - Lernziel formulieren
   - Key Topics auflisten
   - Kurzbeschreibung verfassen
   - VorgÃ¤nger/Nachfolger-Sections benennen

#### Output-Format (pro Section)

```
Section: axiom-case-creation
Gliederungsebene: 3
Lernziel: Ermittler kann eigenstÃ¤ndig einen Fall anlegen
Key Topics:
  - Neuen Fall anlegen (New Case Dialog)
  - Evidenzquellen hinzufÃ¼gen (Add Evidence)
  - Fall-Metadaten erfassen (Case Properties)
Kurzbeschreibung:
  Diese Section erklÃ¤rt den kompletten Prozess der Fall-Erstellung in AXIOM.
  Der Fokus liegt auf der korrekten Auswahl der Evidenzquellen und der
  vollstÃ¤ndigen Erfassung von Metadaten fÃ¼r spÃ¤tere Berichte.
VorgÃ¤nger-Sections: axiom-installation, axiom-interface
Nachfolger-Sections: axiom-evidence-processing
```

#### AktivitÃ¤ten (Maintainer)
1. **Gliederung prÃ¼fen:** Ist die Struktur logisch und vollstÃ¤ndig?
2. **VollstÃ¤ndigkeit bewerten:** Fehlen Sections? Sind AbhÃ¤ngigkeiten korrekt?
3. **StrategiekonformitÃ¤t prÃ¼fen:** Passt die Gliederung zum Strategiedokument?
4. **Entscheidung:**
   - **Approval:** Weiter zu Phase 1
   - **Reject:** Strategiedokument verfeinern â†’ Phase 0.5b (Iteration)

#### Output
- **Section-Liste:** Abgesegnete Gliederung mit groben InhaltsentwÃ¼rfen
- **Status:** Approved fÃ¼r Phase 1

---

### Phase 1: Research & Draft (pro Section)

**Verantwortlich:** KI-System  
**HÃ¤ufigkeit:** Pro Section, sequenziell (keine Parallelisierung in v1.0)

#### Input fÃ¼r KI

```
=== AKTUELL ZU ERSTELLENDE SECTION ===
[Section-Info aus Phase 0.5 wie oben beschrieben]

=== KONTEXT: BEREITS APPROBIERTE SECTIONS ===
[Volltext der 2-3 unmittelbar vorhergehenden Sections]

=== KONTEXT: GESAMTSTRUKTUR (ÃœBERBLICK) ===
Topic: AXIOM Grundlagen
â”œâ”€ Chapter: Installation & Setup
â”‚  â”œâ”€ axiom-installation (âœ“ approbiert)
â”‚  â””â”€ axiom-interface (âœ“ approbiert)
â”œâ”€ Chapter: Fall-Management
â”‚  â”œâ”€ axiom-case-creation (â† JETZT)
â”‚  â”œâ”€ axiom-evidence-processing (geplant)
â”‚  â””â”€ axiom-case-export (geplant)

=== QUELLEN (DETAILLIERT) ===
[Relevante Kapitel aus AXIOM-Handbuch, vollstÃ¤ndig]

=== STRATEGIEDOKUMENT ===
[Aktuelles Strategiedokument fÃ¼r diesen Bereich]
```

#### AktivitÃ¤ten (KI)
1. **Quellen vertiefen:** Relevante Abschnitte im Detail lesen
2. **Kontext verstehen:** Approbierte Sections auf Terminologie/Stil prÃ¼fen
3. **Draft erstellen:**
   - HTML gemÃ¤ÃŸ Cluster 3 (BFSG, Whitelist, Attribute)
   - Content gemÃ¤ÃŸ Cluster 1 (Zielgruppe, Detail-Level, Terminologie)
   - Struktur gemÃ¤ÃŸ Cluster 2 (Hierarchie, data-ref, JSON-LD)
   - Medien-Platzhalter mit Dateinamen-VorschlÃ¤gen
   - Video-Untertitel-EntwÃ¼rfe (SRT/VTT-Format)
4. **SelbstprÃ¼fung:** Kurze PlausibilitÃ¤tsprÃ¼fung vor Ausgabe

#### Output
- **Section-Draft (HTML):** VollstÃ¤ndiger HTML-Code gemÃ¤ÃŸ Schema
- **Medien-Spezifikationen:** Liste benÃ¶tigter Screenshots/Videos mit Beschreibung
- **Untertitel-EntwÃ¼rfe:** Zeitstempel-unabhÃ¤ngige Untertitel-Texte
- **Version:** 1.0.0

---

### Phase 2: Syntax-Validierung

**Verantwortlich:** Python-Skripte (automatisiert)  
**HÃ¤ufigkeit:** Nach jedem Draft/jeder Korrektur

#### AktivitÃ¤ten
1. **JSON-Schema-Validierung:** Struktur, Pflicht-Attribute, Datentypen
2. **HTML-Element-PrÃ¼fung:** Nur erlaubte Elemente (Whitelist)
3. **Attribut-VollstÃ¤ndigkeit:** Pflicht-Attribute vorhanden?
4. **BFSG-KonformitÃ¤t:** lang-Attribute, Alt-Texte, Ãœberschriften-Hierarchie
5. **Cross-Reference-PrÃ¼fung:** data-ref gÃ¼ltig und konsistent?
6. **CSS-Klassen-PrÃ¼fung:** Nur erlaubte Klassen verwendet?

#### Output-Format

```
=== SYNTAX VALIDATION REPORT ===
Section: axiom-case-creation
Version: 1.0.0
Datum: 2025-10-10 14:32:15

CRITICAL [Line 45]: Missing required attribute 'lang' on element <span>
ERROR [Line 78]: Invalid data-ref format 'axiom_case' (underscore not allowed)
ERROR [Line 102]: Element <table> not in whitelist (use <div> with CSS grid)
WARNING [Line 112]: Heading hierarchy skip (h2 â†’ h4)
WARNING [Line 156]: Alt-text suspiciously short (< 10 characters): "AXIOM UI"
INFO [Line 89]: Consider adding 'title' attribute for better accessibility
INFO [Line 134]: data-detail-level="1" could benefit from level 2 variant

=== SUMMARY ===
CRITICAL: 1
ERROR: 2
WARNING: 2
INFO: 2

Status: FAILED (CRITICAL/ERROR present)
```

**Optional in v1.1:** Code-Snippet um Fehler herum fÃ¼r schnellere Lokalisierung

---

### Phase 3: Fehlerkorrektur (iterativ)

**Verantwortlich:** KI-System (CRITICAL/ERROR), Maintainer (WARNING/INFO)  
**HÃ¤ufigkeit:** Nach jedem Validierungs-Fehlschlag

#### AktivitÃ¤ten bei CRITICAL/ERROR

1. **KI erhÃ¤lt:** Validierungs-Report (Textformat wie oben)
2. **KI korrigiert:**
   - Fehler lokalisieren
   - Korrekturen vornehmen (nur betroffene Stellen)
   - Keine inhaltlichen Ã„nderungen (nur Syntax/Struktur)
3. **KI erstellt:** Neue Version (z.B. 1.0.1)
4. **ZurÃ¼ck zu Phase 2:** Erneute Validierung

**Abbruchkriterium:** Wenn nach 5 Iterationen noch CRITICAL/ERROR â†’ Eskalation an Maintainer

#### AktivitÃ¤ten bei WARNING/INFO

1. **Maintainer erhÃ¤lt:** Validierungs-Report
2. **Maintainer entscheidet pro Warnung:**
   - **Beheben:** Manuell korrigieren oder KI beauftragen
   - **Ignorieren:** Als akzeptabel markieren (BegrÃ¼ndung dokumentieren)
3. **Bei Korrekturen:** Neue Version erstellen

**Weiter zu Phase 4:** Wenn keine CRITICAL/ERROR mehr vorhanden

#### Output
- **Korrigierter Draft:** Syntaktisch valider HTML-Code
- **Version:** Inkrementiert bei Ã„nderungen (z.B. 1.0.3)
- **Status:** Ready for Semantic Review

---

### Phase 4: Semantic Review

**Verantwortlich:** KI-System  
**HÃ¤ufigkeit:** Nach syntaktischer Validierung, vor Medien-Erstellung

#### Input fÃ¼r KI

```
=== ZU REVIEWENDE SECTION ===
[VollstÃ¤ndiger HTML-Draft]

=== STRATEGIEDOKUMENT ===
[Relevantes Strategiedokument]

=== ALLE APPROBIERTEN SECTIONS ===
[Volltexte fÃ¼r KonsistenzprÃ¼fung]

=== TERMINOLOGIE-LISTE ===
[Organisch gewachsene Liste etablierter Begriffe]

=== SECTION-LISTE (PHASE 0.5) ===
[UrsprÃ¼ngliche Inhaltsskizze fÃ¼r VollstÃ¤ndigkeitsprÃ¼fung]
```

#### Bewertungskriterien & Quality-Score (0-100)

| Kriterium | Gewicht | Max. Punkte | Bewertungsfragen |
|-----------|---------|-------------|------------------|
| **StrategiekonformitÃ¤t** | 30% | 30 | â€¢ Entspricht die Section dem Lernziel?<br>â€¢ Sind Fokus-Themen korrekt priorisiert?<br>â€¢ Passt der Umfang zur Strategievorgabe?<br>â€¢ Sind Abgrenzungen eingehalten? |
| **VerstÃ¤ndlichkeit** | 25% | 25 | â€¢ Ist die Sprache zielgruppengerecht (IT-ferne Ermittler)?<br>â€¢ Sind Fachbegriffe erklÃ¤rt?<br>â€¢ Ist die Schritt-fÃ¼r-Schritt-Logik nachvollziehbar?<br>â€¢ Sind Beispiele praxisnah? |
| **VollstÃ¤ndigkeit** | 20% | 20 | â€¢ Sind alle Key Topics aus Phase 0.5 abgedeckt?<br>â€¢ Fehlen wichtige Informationen fÃ¼r das Lernziel?<br>â€¢ Sind notwendige Cross-References vorhanden?<br>â€¢ Ist der Detailgrad angemessen? |
| **Konsistenz** | 15% | 15 | â€¢ Stimmt die Terminologie mit approbierten Sections Ã¼berein?<br>â€¢ Passen Schreibstil und TonalitÃ¤t?<br>â€¢ Sind Formatierungen einheitlich?<br>â€¢ Widersprechen Aussagen anderen Sections? |
| **Struktur** | 10% | 10 | â€¢ Ist die Gliederung logisch aufgebaut?<br>â€¢ Sind Ãœberschriften-Hierarchien korrekt?<br>â€¢ Ist die Navigation intuitiv?<br>â€¢ Sind Content-Type-Boxen sinnvoll eingesetzt? |

#### Score-Interpretation

```
90-100 Punkte: Exzellent â€“ Kann direkt zu Phase 5 (Medien-Erstellung)
75-89 Punkte:  Gut â€“ Kleinere Anpassungen empfohlen, dann weiter
60-74 Punkte:  Akzeptabel â€“ Mehrere Verbesserungen nÃ¶tig, Review mit Maintainer
0-59 Punkte:   UngenÃ¼gend â€“ ZurÃ¼ck zu Phase 1 (Draft neu erstellen)
```

#### Output-Format

```markdown
## Semantic Review Report

**Section:** axiom-case-creation  
**Version:** 1.0.3  
**Reviewer:** Claude Sonnet 4.5  
**Datum:** 2025-10-10 15:45:22

### Quality Score: 82/100 (Gut)

#### Detailbewertung

| Kriterium | Punkte | Max | Bemerkung |
|-----------|--------|-----|-----------|
| StrategiekonformitÃ¤t | 27 | 30 | Lernziel erreicht, Fokus-Themen gut abgedeckt. Empfehlung: Prozess der Evidenzquellenauswahl stÃ¤rker betonen (laut Strategiedokument PrioritÃ¤t). |
| VerstÃ¤ndlichkeit | 22 | 25 | Sprache zielgruppengerecht, gute Schritt-fÃ¼r-Schritt-Anleitung. Empfehlung: Fachbegriff "Hash-Algorithmus" in Zeile 67 erklÃ¤ren. |
| VollstÃ¤ndigkeit | 18 | 20 | Alle Key Topics vorhanden. Fehlt: Cross-Reference zu "axiom-evidence-types" fÃ¼r vertiefende ErklÃ¤rung der Evidenzquellen. |
| Konsistenz | 12 | 15 | Terminologie stimmt Ã¼berein. Abweichung: "Fallakte" statt "Fall" (in axiom-installation wird "Fall" verwendet). |
| Struktur | 9 | 10 | Gliederung logisch, Ãœberschriften korrekt. Kleiner Hinweis: Info-Box in Zeile 45 kÃ¶nnte als Hint-Box besser passen (weniger kritische Information). |

#### Handlungsempfehlungen

**PrioritÃ¤t HOCH:**
1. Evidenzquellenauswahl-Prozess detaillierter beschreiben (StrategiekonformitÃ¤t +3 Punkte mÃ¶glich)
2. Terminologie "Fallakte" â†’ "Fall" anpassen (Konsistenz +2 Punkte)

**PrioritÃ¤t MITTEL:**
3. Cross-Reference zu "axiom-evidence-types" ergÃ¤nzen (VollstÃ¤ndigkeit +2 Punkte)
4. Fachbegriff "Hash-Algorithmus" erklÃ¤ren (VerstÃ¤ndlichkeit +2 Punkte)

**PrioritÃ¤t NIEDRIG:**
5. Info-Box â†’ Hint-Box umwandeln (Struktur +1 Punkt)

**GeschÃ¤tzter Score nach Anpassung:** 91/100 (Exzellent)

#### Entscheidung
â˜ Direkt zu Phase 5 (Medien-Erstellung)  
â˜‘ Anpassungen vornehmen, dann Phase 4 wiederholen  
â˜ ZurÃ¼ck zu Phase 1 (Draft neu erstellen)
```

#### Weiter zu Phase 5
- Wenn Score â‰¥ 75 und Maintainer zustimmt

---

### Phase 5: Medien-Erstellung

**Verantwortlich:** Maintainer  
**HÃ¤ufigkeit:** Pro Section nach Semantic Review

#### Medien-Spezifikationen

##### Screenshots

| Parameter | Wert |
|-----------|------|
| **Inhalt** | Nur Programm/Fenster/Pop-Up (kein Desktop-Hintergrund) |
| **AuflÃ¶sung** | 72 dpi |
| **Farbtiefe** | Vollfarben |
| **Theme** | System-Skin/Theme (keine Custom-Themes) |
| **Format** | PNG, komprimiert 60-80% |
| **Datenschutz** | Relevante Bereiche schwÃ¤rzen/pixeln |
| **Dateiname** | Von KI im Draft vorgegeben (z.B. `axiom-case-new-dialog.png`) |

##### Annotations (auf Screenshots)

| Parameter | Wert |
|-----------|------|
| **Kontrast** | Hoch (gut lesbar auf hellem/dunklem Hintergrund) |
| **Farbcode** | â€¢ Rot: Achtung<br>â€¢ Gelb: Warnung<br>â€¢ Blau: Hinweis<br>â€¢ GrÃ¼n: Handlungsanweisung |
| **Pfeile** | Mindestbreite 4px |
| **Verdeckung** | Nichts Wichtiges verdecken |
| **Schriftart** | Open Sans (ohne Serifen) |
| **SchriftgrÃ¶ÃŸe** | 16px |

##### Videos

| Parameter | Wert |
|-----------|------|
| **MindestauflÃ¶sung** | 1280Ã—720 (HD) |
| **HÃ¶chstauflÃ¶sung** | 1920Ã—1080 (Full HD) |
| **Mindestframerate** | 15 fps (ausreichend fÃ¼r Bildschirmaufnahmen) |
| **Mindestspieldauer** | 10 Sekunden |
| **HÃ¶chstspieldauer** | 180 Sekunden (3 Minuten) |
| **SeitenverhÃ¤ltnis** | 16:9 bevorzugt |
| **Audio** | Ohne Musik, ggf. Sprecherstimme |
| **Format** | MP4 bevorzugt |
| **Codec** | H.264 (AVC), H.265 (HEVC) oder AV1 |
| **Untertitel** | **Pflicht** (BFSG-KonformitÃ¤t), SRT/VTT-Format |

**Untertitel-Workflow:**
1. KI hat in Phase 1 Untertitel-Texte erstellt (ohne Zeitstempel)
2. Maintainer erstellt Video
3. Maintainer passt Zeitfenster im SRT/VTT-File an

#### AktivitÃ¤ten
1. **Medien erstellen:** GemÃ¤ÃŸ Draft-Spezifikationen und obigen Standards
2. **QualitÃ¤t prÃ¼fen:** Lesbarkeit, Kontrast, DateigrÃ¶ÃŸe
3. **Datenschutz sicherstellen:** Keine personenbezogenen Daten sichtbar
4. **Dateien benennen:** GemÃ¤ÃŸ Draft-Vorgaben

#### Output
- **Medien-Assets:** Screenshots, annotierte Bilder, Videos (inkl. Untertitel)
- **Dateinamen-Liste:** Mapping Draft-Platzhalter â†’ tatsÃ¤chliche Files

---

### Phase 6: Content-Enrichment

**Verantwortlich:** Maintainer  
**HÃ¤ufigkeit:** Pro Section nach Medien-Erstellung

#### AktivitÃ¤ten
1. **Medien einbinden:**
   - Platzhalter durch echte Pfade ersetzen
   - `<img>`-Tags mit korrekten `src`, `alt`, `title` Attributen
   - `<video>`-Tags mit Untertitel-Tracks
2. **Glossar-Verweise ergÃ¤nzen:**
   - Fachbegriffe mit `data-glossary-term` auszeichnen
   - Querverweise zu Glossar-Sections einfÃ¼gen
3. **Agent-Context erstellen (v1.0: manuell, spÃ¤ter: KI-gestÃ¼tzt):**
   - Trigger-Points identifizieren
   - Agent-Context-Block am Section-Ende einfÃ¼gen
   - JSON-Struktur gemÃ¤ÃŸ Cluster 2
4. **Finale FormatierungsprÃ¼fung:**
   - CSS-Klassen korrekt?
   - Barrierefreiheit durchgÃ¤ngig gewÃ¤hrleistet?

#### Output
- **Angereicherte Section:** VollstÃ¤ndig mit Medien, Glossar, Agent-Context
- **Version:** Inkrementiert (z.B. 1.1.0 fÃ¼r Content-Enrichment)
- **Status:** Ready for Final Review

---

### Phase 7: Final Review

**Verantwortlich:** Maintainer  
**HÃ¤ufigkeit:** Pro Section nach Content-Enrichment

#### AktivitÃ¤ten
1. **Fachliche Korrektheit:** Sind alle Informationen korrekt und aktuell?
2. **UX-PrÃ¼fung:** Ist die Section intuitiv nutzbar?
3. **Gesamteindruck:** Passt die Section ins Gesamtwerk?
4. **MedienqualitÃ¤t:** Sind Screenshots/Videos verstÃ¤ndlich und hilfreich?
5. **Barrierefreiheit:** End-to-End-Test mit Screenreader (stichprobenartig)

#### Entscheidung
- **Approval:** Weiter zu Phase 8 (Distribution)
- **Reject mit Feedback:**
  - **Minor:** ZurÃ¼ck zu Phase 6 (kleine Anpassungen)
  - **Major:** ZurÃ¼ck zu Phase 4 oder Phase 1 (grundlegende Ãœberarbeitung)

#### Output
- **Approval-Status:** Approved / Rejected
- **Feedback-Dokument:** Bei Reject mit konkreten Verbesserungshinweisen

---

### Phase 8: Distribution

**Verantwortlich:** Maintainer  
**HÃ¤ufigkeit:** Pro Section nach Final Review Approval

#### AktivitÃ¤ten
1. **Versionierung:**
   - Git-Commit mit beschreibender Message
   - Tag setzen (z.B. `section-axiom-case-creation-v1.1.0`)
2. **Branch-ÃœberfÃ¼hrung:**
   - Von `content-drafts` nach `content-approved`
   - Merge in `main` (falls produktionsreif)
3. **Komponierung:**
   - Section in Gesamt-Dokumentation integrieren
   - Navigation aktualisieren
4. **VerÃ¶ffentlichung:**
   - Build-Prozess anstoÃŸen (HTML-Generierung, Asset-Optimierung)
   - Deployment auf Zielplattform

#### Output
- **Published Section:** Ã–ffentlich verfÃ¼gbar in Wissenssystem
- **Git-Repository:** Versioniert und dokumentiert
- **Status:** Published

---

## 3. Schnittstellen & Datenformate

### 3.1 Bevorzugte Formate fÃ¼r KI-Arbeit

| Datentyp | Bevorzugtes Format | BegrÃ¼ndung |
|----------|-------------------|------------|
| **Section-Beschreibungen** | NatÃ¼rliche Sprache (Mischform Stichpunkte + FlieÃŸtext) | Besseres VerstÃ¤ndnis von Nuancen und Kontext |
| **Fehlerberichte** | Textformat mit Zeilennummern | Direkte Lokalisierung, keine JSON-Interpretation nÃ¶tig |
| **Strategiedokumente** | Markdown / Strukturierter Text | Gut lesbar, hierarchisch strukturierbar |
| **Quellenmaterial** | Text / Markdown / PDF (extrahiert) | Direkt verarbeitbar |
| **Approbierte Sections** | HTML (Volltext) | Analyse von Stil, Terminologie, Struktur |

### 3.2 Input/Output-Matrix

| Phase | Input | Output |
|-------|-------|--------|
| **0** | Projektziel, Zielgruppe, Rahmenbedingungen | Strategiedokument, Quellenliste |
| **0.5** | Strategiedokument, Quellen (Inhaltsverzeichnis + Intros) | Section-Liste mit groben InhaltsentwÃ¼rfen |
| **1** | Section-Info, approbierte Sections, Quellen (detailliert), Strategiedokument | Section-Draft (HTML), Medien-Spezifikationen, Untertitel-EntwÃ¼rfe |
| **2** | Section-Draft (HTML) | Validierungs-Report (CRITICAL/ERROR/WARNING/INFO) |
| **3** | Validierungs-Report | Korrigierter Draft (neue Version) |
| **4** | Draft, Strategiedokument, approbierte Sections, Terminologie-Liste | Semantic Review Report, Quality-Score |
| **5** | Draft, Medien-Spezifikationen | Medien-Assets (Screenshots, Videos, Untertitel) |
| **6** | Draft, Medien-Assets, Glossar-Daten | Angereicherte Section (mit Medien, Glossar, Agent) |
| **7** | Angereicherte Section | Approval-Status, ggf. Feedback-Dokument |
| **8** | Approved Section | Published Section, Git-Tag |

---

## 4. Quality-Score-System

### 4.1 Kriterien & Gewichtung

**Gesamtscore:** 0-100 Punkte

| Kriterium | Gewicht | Max. Punkte | Fokus |
|-----------|---------|-------------|-------|
| StrategiekonformitÃ¤t | 30% | 30 | Passung zum Lernziel und Strategievorgaben |
| VerstÃ¤ndlichkeit | 25% | 25 | Zielgruppengerechte Sprache und Didaktik |
| VollstÃ¤ndigkeit | 20% | 20 | Abdeckung aller Key Topics |
| Konsistenz | 15% | 15 | Terminologie, Stil, Format |
| Struktur | 10% | 10 | Logik, Hierarchie, Navigation |

### 4.2 Bewertungsmatrix (StrategiekonformitÃ¤t Beispiel)

| Punkte | Beschreibung |
|--------|--------------|
| 28-30 | Perfekte Umsetzung des Lernziels, alle Fokus-Themen priorisiert, exakte Umfangstreue |
| 24-27 | Lernziel erreicht, Fokus-Themen gut abgedeckt, minimale Abweichungen |
| 18-23 | Lernziel grÃ¶ÃŸtenteils erreicht, einige Fokus-Themen unterreprÃ¤sentiert |
| 12-17 | Lernziel teilweise verfehlt, wichtige Fokus-Themen fehlen oder falsch gewichtet |
| 0-11 | Lernziel nicht erreicht, gravierende Abweichungen von Strategievorgaben |

*(Analoge Matrizen fÃ¼r alle Kriterien)*

### 4.3 Report-Template

Siehe Phase 4 Output-Format (Markdown-basiert, strukturiert, mit konkreten Handlungsempfehlungen)

---

## 5. Fehlerbehandlung & Eskalation

### 5.1 Version 1.0: Manuelle Kontrolle (Option C)

**Prinzip:** Maintainer hat jederzeit volle Kontrolle und greift bei Bedarf ein.

#### Problem-Section-Handling

```
Maintainer beobachtet:
â”œâ”€ Anzahl Iterationen (Phase 2 â†” 3)
â”œâ”€ Quality-Scores (Phase 4)
â”œâ”€ Fehlermuster (wiederkehrende Probleme)
â””â”€ Zeitaufwand pro Section

Maintainer entscheidet fallweise:
â”œâ”€ Strategiedokument verfeinern â†’ Phase 0.5b (neue Iteration)
â”œâ”€ KI-Prompt anpassen (mehr Kontext, prÃ¤zisere Anweisungen)
â”œâ”€ Section-Beschreibung in Phase 0.5 prÃ¤zisieren
â”œâ”€ Quellenmaterial erweitern/verbessern
â”œâ”€ Als letzter Ausweg: Section manuell schreiben
â””â”€ Lessons Learned dokumentieren fÃ¼r v2.0
```

**Keine harte Abbruchgrenze:** Pragmatische Entscheidung basierend auf Aufwand-Nutzen-VerhÃ¤ltnis.

#### Eskalations-Trigger (informell)

- **Syntax-Fehler:** >5 Iterationen ohne Besserung â†’ Maintainer prÃ¼ft, ob Fehler systematisch ist
- **Semantic Review:** Score <60 Ã¼ber 2 Draft-Versionen â†’ Strategiedokument Ã¼berarbeiten
- **ZeitÃ¼berschreitung:** Section benÃ¶tigt >4 Stunden â†’ Prozess hinterfragen

#### Dokumentation

**Lessons Learned Log:**
```markdown
## Problem-Section: axiom-advanced-search
**Datum:** 2025-10-15
**Problem:** Score blieb bei 52-58 Ã¼ber 3 Drafts
**Ursache:** Strategiedokument zu vage ("erweiterte Suchfunktionen")
**LÃ¶sung:** Konkretisierung: "Boolean-Operatoren, Regex, Filter-Kombinationen"
**Ergebnis:** Score 87 nach neuem Draft
**Learning:** Strategiedokument braucht konkrete Feature-Namen, nicht nur Kategorien
```

---

### 5.2 Version 2.0: Automatische Eskalation (Option B) - Perspektivisch

**Prinzip:** System erkennt Problem-Sections automatisch und schlÃ¤gt LÃ¶sungen vor.

#### Automatische Trigger

```
System Ã¼berwacht:
â”œâ”€ Syntax-Fehler-HÃ¤ufigkeit (CRITICAL/ERROR pro Version)
â”œâ”€ Semantic Review Scores (Trend Ã¼ber Versionen)
â”œâ”€ Iterationszyklen (Anzahl Phase-2-3-DurchlÃ¤ufe)
â””â”€ Zeitverbrauch (Dauer seit Phase 1 Start)

Eskalations-Schwellen:
â”œâ”€ Score < 60 Ã¼ber 2 Draft-Versionen ODER
â”œâ”€ >5 Syntax-Fehler-Iterationen ODER
â”œâ”€ >3 Semantic-Review-DurchlÃ¤ufe ohne Verbesserung
â””â”€ System markiert Section als "problematic"
```

#### Automatische Analyse

```
System analysiert:
â”œâ”€ Fehlerhistorie:
â”‚  â”œâ”€ Welche Kriterien scheitern wiederholt?
â”‚  â”œâ”€ Sind Fehler syntaktisch oder semantisch?
â”‚  â””â”€ Gibt es Muster (z.B. immer Konsistenz-Probleme)?
â”œâ”€ Strategiedokument-QualitÃ¤t:
â”‚  â”œâ”€ Sind Lernziele prÃ¤zise formuliert?
â”‚  â”œâ”€ Sind Key Topics spezifisch genug?
â”‚  â””â”€ Gibt es widersprÃ¼chliche Vorgaben?
â”œâ”€ Quellenmaterial-VerfÃ¼gbarkeit:
â”‚  â”œâ”€ Ist das Thema ausreichend dokumentiert?
â”‚  â”œâ”€ Sind Quellen aktuell?
â”‚  â””â”€ Fehlen wichtige Informationen?
â””â”€ KomplexitÃ¤t:
   â”œâ”€ Ist die Section zu umfangreich?
   â”œâ”€ Sollte sie aufgeteilt werden?
   â””â”€ Sind VorgÃ¤nger-Sections unzureichend?
```

#### System-VorschlÃ¤ge

```markdown
## Eskalations-Report: axiom-advanced-search

**Status:** PROBLEMATIC  
**Trigger:** Score < 60 Ã¼ber 2 Drafts (52 â†’ 58)  
**Datum:** 2025-10-15

### Analyse

**Fehler-Muster:**
- StrategiekonformitÃ¤t: Wiederholt niedrig (15-18/30)
- VollstÃ¤ndigkeit: Schwankend (12-16/20)
- Andere Kriterien: Akzeptabel (>80% Punktzahl)

**Strategiedokument-PrÃ¼fung:**
- Lernziel zu allgemein: "Ermittler kann erweiterte Suchen durchfÃ¼hren"
- Key Topics zu vage: "Erweiterte Suchfunktionen", "Filter"
- Keine konkreten Features genannt

**Quellen-PrÃ¼fung:**
- AXIOM-Handbuch Kapitel 7.2 "Advanced Search" vollstÃ¤ndig verfÃ¼gbar
- Keine Quellenprobleme erkennbar

### Empfohlene MaÃŸnahmen

**PRIORITÃ„T 1: Strategiedokument verfeinern**

Vorschlag fÃ¼r neues Strategiedokument:
```
Lernziel: Ermittler kann Boolean-Operatoren (AND, OR, NOT), 
Regex-Patterns und Filter-Kombinationen fÃ¼r prÃ¤zise Suchen einsetzen.

Key Topics:
- Boolean-Operatoren (AND, OR, NOT, Klammersetzung)
- Regex-Grundlagen (., *, +, ?, [])
- Filter-Kombinationen (Dateityp + Zeitraum + Keyword)
- Suchhistorie und Suche speichern
```

**PRIORITÃ„T 2: Section ggf. aufteilen**

Wenn Strategiedokument-Verbesserung nicht hilft:
- Section 1: "Boolean-Suche in AXIOM" (Grundlagen)
- Section 2: "Regex-Suche in AXIOM" (fÃ¼r Fortgeschrittene)
- Section 3: "Filter-Kombinationen in AXIOM"

### Maintainer-Entscheidung erforderlich

â˜ Strategiedokument verfeinern (Vorschlag Ã¼bernehmen)  
â˜ Strategiedokument verfeinern (eigene Formulierung)  
â˜ Section aufteilen  
â˜ Manuell schreiben (KI-Generierung abbrechen)
```

---

## 6. Medien-Spezifikationen

*(Bereits vollstÃ¤ndig in Phase 5 dokumentiert)*

**Zusammenfassung:**

| Medientyp | Key-Parameter |
|-----------|---------------|
| **Screenshots** | PNG 60-80%, 72dpi, System-Theme, Datenschutz beachten |
| **Annotations** | Open Sans 16px, Farbcode (Rot/Gelb/Blau/GrÃ¼n), Pfeile â‰¥4px |
| **Videos** | 1280Ã—720 bis 1920Ã—1080, 15fps min, MP4/H.264, Untertitel Pflicht |

---

## 7. Versionierung & Speicherung

### 7.1 Git-Branch-Struktur

```
main
â”œâ”€ Nur Published Sections (Phase 8)
â”œâ”€ Tag-basierte Releases (z.B. v1.0.0, v1.1.0)
â””â”€ Protected Branch (nur Maintainer darf mergen)

content-approved
â”œâ”€ Sections nach Final Review (Phase 7)
â”œâ”€ Bereit fÃ¼r Deployment
â””â”€ Merge-Target fÃ¼r content-drafts

content-drafts
â”œâ”€ Arbeitskopien (Phase 1-6)
â”œâ”€ Unterverzeichnisse pro Section
â””â”€ Versionsnummern in Commit-Messages
```

### 7.2 Namenskonventionen

**Verzeichnisstruktur:**
```
content-drafts/
â”œâ”€ axiom-grundlagen/
â”‚  â”œâ”€ axiom-installation/
â”‚  â”‚  â”œâ”€ section.html
â”‚  â”‚  â”œâ”€ media/
â”‚  â”‚  â”‚  â”œâ”€ axiom-install-welcome.png
â”‚  â”‚  â”‚  â””â”€ axiom-install-process.mp4
â”‚  â”‚  â””â”€ metadata.json
â”‚  â””â”€ axiom-case-management/
â””â”€ axiom-analysis/
```

**Versionsnummern:**
- Format: `MAJOR.MINOR.BUILD`
- MAJOR: Grundlegende Ãœberarbeitung (zurÃ¼ck zu Phase 1)
- MINOR: Content-Enrichment, grÃ¶ÃŸere Ã„nderungen
- BUILD: Bugfixes, kleine Korrekturen

**Git-Tags:**
```
section-axiom-installation-v1.0.0
section-axiom-installation-v1.1.0 (nach Content-Enrichment)
section-axiom-installation-v1.1.2 (nach Bugfixes)
```

### 7.3 Metadaten-Datei (metadata.json)

```json
{
  "section_id": "axiom-case-creation",
  "version": "1.1.0",
  "status": "approved",
  "created": "2025-10-10T14:00:00Z",
  "last_modified": "2025-10-10T16:30:00Z",
  "author": "Claude Sonnet 4.5",
  "maintainer": "Max Mustermann",
  "quality_score": 87,
  "review_cycles": 2,
  "validation_errors": {
    "critical": 0,
    "error": 0,
    "warning": 1,
    "info": 3
  },
  "sources": [
    "AXIOM Examine User Guide v7.8, Chapter 4",
    "Internal Best Practices Doc v2.3"
  ],
  "learning_goal": "Ermittler kann eigenstÃ¤ndig einen Fall anlegen",
  "hierarchy_level": 3,
  "prerequisites": ["axiom-installation", "axiom-interface"],
  "related_sections": ["axiom-evidence-processing", "axiom-case-export"]
}
```

---

## 8. Version 1.0 vs. spÃ¤tere Versionen

### 8.1 Scope Version 1.0

**Im Scope:**
- âœ… Manuelle Kontrolle durch Maintainer bei allen kritischen Entscheidungen
- âœ… Sequenzielle Section-Erstellung (keine Parallelisierung)
- âœ… KI-generierte Drafts mit manueller Review
- âœ… Python-basierte Syntax-Validierung (automatisiert)
- âœ… KI-basierte Semantic Review (automatisiert)
- âœ… Manuelle Medien-Erstellung
- âœ… Manuelle Agent-Context-Erstellung
- âœ… Git-basierte Versionierung (manuell)
- âœ… Organisch wachsende Terminologie-Liste
- âœ… Fehlerbehandlung: Option C (manuelle Entscheidung)

**Ausgeschlossen:**
- âŒ Automatisierte End-to-End-Workflows
- âŒ Parallelisierung von Draft-Erstellung
- âŒ Automatische Git-Workflows (CI/CD)
- âŒ Automatische Agent-Context-Generierung
- âŒ Automatische Eskalation (Option B)

---

### 8.2 Roadmap fÃ¼r spÃ¤tere Versionen

#### Version 1.1 (Quick Wins)

**Geplante Verbesserungen:**
- ğŸ”„ Code-Snippet-Kontext in Fehlerberichten (Phase 2)
- ğŸ”„ Medien-Template-Bibliothek (Annotations schneller erstellen)
- ğŸ”„ Erweiterte Metadaten-Analyse (Trends, Bottlenecks)

**Aufwand:** Niedrig (< 2 Wochen Entwicklung)

---

#### Version 2.0 (Automatisierung & Skalierung)

**Geplante Verbesserungen:**
- ğŸ”„ **Teilautomatisierung:**
  - Claude API-Integration (Python-Wrapper)
  - Batch-Processing fÃ¼r mehrere Sections
  - Automatische Git-Commits nach Approval
- ğŸ”„ **Parallelisierung:**
  - UnabhÃ¤ngige Sections parallel erstellen
  - Dependency-Graph fÃ¼r Reihenfolge
- ğŸ”„ **Fehlerbehandlung:**
  - Option B: Automatische Eskalation
  - System-VorschlÃ¤ge fÃ¼r Strategiedokument-Verbesserungen
- ğŸ”„ **Erweiterte Metriken:**
  - Dashboard fÃ¼r Workflow-Monitoring
  - Predictive Analytics (ZeitschÃ¤tzungen pro Section)

**Aufwand:** Mittel (1-2 Monate Entwicklung)

---

#### Version 3.0 (KI-Agent-System)

**Geplante Verbesserungen:**
- ğŸ”„ **Automatische Agent-Context-Generierung:**
  - KI schlÃ¤gt Trigger-Points vor
  - KI generiert Agent-Kontext-BlÃ¶cke
  - Maintainer reviewed und genehmigt
- ğŸ”„ **Multi-Tool-UnterstÃ¼tzung:**
  - X-Ways Forensics, Cellebrite Reader parallel pflegen
  - Tool-spezifische Metadaten automatisch verwalten
- ğŸ”„ **Adaptive Strategiedokumente:**
  - KI lernt aus Problem-Sections
  - VorschlÃ¤ge zur Strategieverbesserung
  - Self-Healing-Workflows

**Aufwand:** Hoch (3-6 Monate Entwicklung)

---

## Anhang

### A.1 Checkliste: Phase 0 (Strategie)

**Vor Start von Phase 0.5:**

- [ ] Lernziel formuliert (konkret, messbar)
- [ ] Fokus-Themen definiert (inkl. Abgrenzungen)
- [ ] Umfang geschÃ¤tzt (Anzahl Sections, Detailtiefe)
- [ ] Software & Version benannt
- [ ] Forensischer Kontext geklÃ¤rt (MobilgerÃ¤t/PC/Cloud)
- [ ] Quellen benannt und validiert (min. 1 Hauptquelle)
- [ ] Strategiedokument versioniert (z.B. v1.0.0)

---

### A.2 Checkliste: Phase 5 (Medien-Erstellung)

**Vor Ãœbergabe an Phase 6:**

**Screenshots:**
- [ ] Nur Programm/Fenster (kein Desktop)
- [ ] 72 dpi, Vollfarben, System-Theme
- [ ] PNG 60-80% komprimiert
- [ ] Datenschutz: Relevante Bereiche geschwÃ¤rzt/gepixelt
- [ ] Dateinamen gemÃ¤ÃŸ Draft-Vorgabe

**Annotations:**
- [ ] Open Sans 16px
- [ ] Farbcode eingehalten (Rot/Gelb/Blau/GrÃ¼n)
- [ ] Pfeile â‰¥4px breit
- [ ] Nichts Wichtiges verdeckt
- [ ] Hoher Kontrast

**Videos:**
- [ ] AuflÃ¶sung 1280Ã—720 bis 1920Ã—1080
- [ ] Framerate â‰¥15 fps
- [ ] Spieldauer 10-180 Sekunden
- [ ] Format: MP4, Codec: H.264/H.265/AV1
- [ ] 16:9 SeitenverhÃ¤ltnis
- [ ] Untertitel (SRT/VTT) vorhanden und synchronisiert
- [ ] Keine Musik, ggf. Sprecherstimme verstÃ¤ndlich

---

### A.3 Beispiel: Strategiedokument

```markdown
# Strategiedokument: AXIOM Case Management

**Version:** 1.0.0  
**Datum:** 2025-10-05  
**GÃ¼ltigkeit:** Topic "AXIOM Case Management"

## Lernziel

Ermittler kÃ¶nnen eigenstÃ¤ndig FÃ¤lle in AXIOM Examine v7.8 erstellen, 
Evidenzquellen hinzufÃ¼gen, FÃ¤lle verwalten und fÃ¼r Berichte exportieren.

## Fokus-Themen

**PrioritÃ¤t HOCH:**
- Fall-Erstellung (New Case Dialog, Metadaten)
- Evidenzquellen-Auswahl (Devices, Images, Cloud)
- Fall-Export (Reports, Evidence Files)

**PrioritÃ¤t MITTEL:**
- Fall-Verwaltung (Ã–ffnen, SchlieÃŸen, Archivieren)
- Mehrere Evidenzquellen pro Fall

**PrioritÃ¤t NIEDRIG:**
- Erweiterte Metadaten (Custom Fields)
- Fall-Vorlagen (Templates)

**Explizit ausgeschlossen:**
- Case Sharing (Multi-User-Szenarien)
- Server-basierte FÃ¤lle (nur lokale FÃ¤lle)

## Umfang

**GeschÃ¤tzte Sections:** 6-8

1. axiom-case-creation (Standard-Detail)
2. axiom-evidence-sources (Standard-Detail)
3. axiom-case-metadata (Basic-Detail)
4. axiom-case-management (Basic-Detail)
5. axiom-multi-evidence (Standard-Detail)
6. axiom-case-export (Standard-Detail)
7. axiom-case-templates (Optional, Show-Only)

## Forensischer Kontext

**PrimÃ¤r:** MobilgerÃ¤te (Smartphones, Tablets)  
**SekundÃ¤r:** PC-Systeme (Windows, macOS)  
**Ausgeklammert:** Cloud-Forensik (eigenes Topic)

## Software & Version

**Tool:** Magnet AXIOM Examine  
**Version:** 7.8.x (aktuelle Stable-Version, Stand 2024-Q4)  
**Hinweis:** Screenshots mit Default-Skin, keine Custom-Themes

## Quellen

**PrimÃ¤r:**
- AXIOM Examine User Guide v7.8, Chapter 3-4
- Magnet Forensics Knowledge Base (online)

**SekundÃ¤r:**
- Interne Best Practices "Case Management Workflows" v2.3
- AXIOM Release Notes v7.8

## Terminologie-Entscheidungen

| Begriff | Verwendung | BegrÃ¼ndung |
|---------|-----------|------------|
| "Fall" | Bevorzugt | Kurz, gebrÃ¤uchlich in deutschem Polizeikontext |
| "Fallakte" | Vermeiden | Zu formal, potenziell missverstÃ¤ndlich |
| "Evidenzquelle" | Bevorzugt | PrÃ¤ziser als "Datenquelle" |
| "Case" | Nur in UI-Kontext | Wenn AXIOM-UI englische Begriffe nutzt |

## Zielgruppen-Spezifika

**PrimÃ¤re Zielgruppe:** Polizei-Ermittler, IT-fern (Mittlere Reife)  
**Detail-Level-Verteilung:**
- 60% Standard-Detail
- 25% Basic-Detail
- 10% Expert-Detail (nur fÃ¼r SpezialfÃ¤lle)
- 5% Show-Only (optionale Vertiefungen)

**Sprach-Richtlinien:**
- Deutsch bevorzugt
- Englische UI-Begriffe in AnfÃ¼hrungszeichen ("New Case")
- Fachbegriffe beim ersten Auftreten erklÃ¤ren
- Schritt-fÃ¼r-Schritt-Anleitungen mit Screenshots

---

**Approval:**  
â˜‘ Maintainer: Max Mustermann, 2025-10-05  
â˜ Fach-Review: [optional]
```

---

### A.4 Beispiel: Section-Liste (Phase 0.5 Output)

```markdown
# Section-Liste: AXIOM Case Management

**Erstellt:** 2025-10-06  
**Status:** Awaiting Maintainer Approval  
**Basis:** Strategiedokument v1.0.0

---

## Topic: AXIOM Case Management

### Chapter 1: Grundlagen

#### Section 1.1: axiom-case-creation

**Gliederungsebene:** 3  
**Lernziel:** Ermittler kann eigenstÃ¤ndig einen Fall in AXIOM anlegen  
**Key Topics:**
- New Case Dialog Ã¶ffnen (File â†’ New Case)
- Fall-Namen und Beschreibung eingeben
- Examiner-Informationen erfassen
- Speicherort wÃ¤hlen

**Kurzbeschreibung:**  
Diese Section fÃ¼hrt Schritt fÃ¼r Schritt durch die Fall-Erstellung in AXIOM Examine. 
Der Fokus liegt auf der korrekten Erfassung von Metadaten (Fall-Name, Examiner, 
Beschreibung) und der Auswahl eines geeigneten Speicherorts. Es wird erklÃ¤rt, 
warum vollstÃ¤ndige Metadaten fÃ¼r spÃ¤tere Berichte wichtig sind.

**VorgÃ¤nger-Sections:** axiom-installation, axiom-interface  
**Nachfolger-Sections:** axiom-evidence-sources

**GeschÃ¤tzte KomplexitÃ¤t:** Basic  
**GeschÃ¤tzte Medien:** 3 Screenshots, ggf. 1 kurzes Video (30 Sek)

---

#### Section 1.2: axiom-evidence-sources

**Gliederungsebene:** 3  
**Lernziel:** Ermittler kann verschiedene Evidenzquellentypen unterscheiden und auswÃ¤hlen  
**Key Topics:**
- Device (direkter Zugriff auf angeschlossenes GerÃ¤t)
- Image File (forensisches Abbild laden)
- Cloud (Online-Datenquellen)
- Entscheidungshilfe: Wann welcher Typ?

**Kurzbeschreibung:**  
Diese Section erklÃ¤rt die verschiedenen Evidenzquellentypen in AXIOM und gibt 
Entscheidungshilfen, wann welcher Typ zu verwenden ist. Sie zeigt die Unterschiede 
zwischen direktem Device-Zugriff (schnell, aber VerÃ¤nderungsgefahr) und Image Files 
(forensisch sauber, aber mehr Vorbereitungsaufwand). Cloud-Quellen werden nur 
oberflÃ¤chlich erwÃ¤hnt, da sie in einem eigenen Topic behandelt werden.

**VorgÃ¤nger-Sections:** axiom-case-creation  
**Nachfolger-Sections:** axiom-case-metadata, axiom-multi-evidence

**GeschÃ¤tzte KomplexitÃ¤t:** Standard  
**GeschÃ¤tzte Medien:** 4 Screenshots, 1 Entscheidungsdiagramm, ggf. 1 Video (60 Sek)

---

[... weitere Sections analog ...]

---

**Gesamt:**
- 7 Sections (6 regulÃ¤r, 1 optional)
- GeschÃ¤tzte Gesamtarbeitszeit: 15-20 Stunden
- GeschÃ¤tzte Medien: ~25 Screenshots, 3-5 Videos, 2 Diagramme
```

---

### A.5 Terminologie-Liste (organisch wachsend)

```markdown
# Terminologie-Liste: WebAssistentForensics

**Version:** 1.3.5  
**Letztes Update:** 2025-10-10  
**Status:** Living Document (organisch wachsend)

---

## Entscheidungen

| Begriff (DE) | Begriff (EN) | Verwendung | Kontext | Quelle |
|--------------|--------------|-----------|---------|--------|
| Fall | Case | **PrÃ¤ferenz: "Fall"** | Allgemein, nur "Case" wenn UI-Referenz | Strategiedokument AXIOM Case Management v1.0.0 |
| Fallakte | Case File | **Vermeiden**, stattdessen "Fall" | - | Feedback Section axiom-case-creation v1.0.3 |
| Evidenzquelle | Evidence Source | **PrÃ¤ferenz: "Evidenzquelle"** | Allgemein | Strategiedokument v1.0.0 |
| Abbild | Image | **"Forensisches Abbild"** bei erster ErwÃ¤hnung, dann "Abbild" | Forensik-Kontext | Section axiom-evidence-sources v1.1.0 |
| Hash-Wert | Hash Value | **PrÃ¤ferenz: "Hash-Wert"** | Allgemein | Section axiom-integrity-check v1.0.0 |
| PrÃ¼fsumme | Checksum | **Synonym fÃ¼r "Hash-Wert"**, sparsam verwenden | Wenn VerstÃ¤ndlichkeit erhÃ¶ht wird | Semantic Review axiom-integrity-check |

---

## ErklÃ¤rungspflichtige Fachbegriffe

| Begriff | ErklÃ¤rung (erste ErwÃ¤hnung) | Beispiel-Section |
|---------|----------------------------|------------------|
| Hash-Wert | "Ein Hash-Wert ist ein eindeutiger 'Fingerabdruck' einer Datei, der zur IntegritÃ¤tsprÃ¼fung dient." | axiom-integrity-check |
| Hex-Editor | "Ein Hex-Editor zeigt Dateiinhalte in hexadezimaler Form (0-9, A-F) an, was fÃ¼r forensische Analysen wichtig ist." | axiom-hex-view |
| Artifact | "Ein Artifact ist ein digital

es Spurenobjekt (z.B. Browser-Historie, GPS-Koordinaten), das AXIOM automatisch erkennt." | axiom-artifacts-overview |

---

**Hinweis:** Diese Liste wÃ¤chst mit jeder neuen Section. Bei Terminologie-Konflikten 
ist das Strategiedokument maÃŸgeblich, gefolgt von der Mehrheit approbierter Sections.
```

---

## Ende Cluster 5

**NÃ¤chste Schritte:**
1. Dieses Dokument in Projekt-Dateispeicher ablegen: `cluster5_Workflow-Rollen.md`
2. Bei Bedarf Reviews mit Stakeholdern durchfÃ¼hren
3. Mit Phase 0 (Strategie) fÃ¼r erste Section beginnen
4. Lessons Learned kontinuierlich dokumentieren fÃ¼r v2.0

**Fragen oder Anmerkungen:** Maintainer kontaktieren

---

**Versionshistorie:**

| Version | Datum | Ã„nderung |
|---------|-------|----------|
| 1.0.0 | 2025-10-10 | Initiale Erstellung (Cluster 5 abgeschlossen) |
````

Perfekt! ğŸ‰ Das **vollstÃ¤ndige Cluster-5-Dokument** ist nun fertig erstellt.

---

## Zusammenfassung: Was wir erreicht haben

Du hast jetzt ein **umfassendes Workflow- und Rollen-Dokument** mit:

### âœ… **VollstÃ¤ndig definiert:**

1. **Akteure & Rollen** (KI, Python, Maintainer + 5 Kernrollen)
2. **9 Workflow-Phasen** (0 â†’ 0.5 â†’ 1-8) mit detaillierten AktivitÃ¤ten
3. **Quality-Score-System** (30% StrategiekonformitÃ¤t, strukturierte Bewertung)
4. **Schnittstellen & Formate** (bevorzugt natÃ¼rliche Sprache fÃ¼r KI)
5. **Medien-Spezifikationen** (Screenshots, Annotations, Videos mit konkreten Werten)
6. **Fehlerbehandlung** (v1.0: manuell, v2.0: automatisch)
7. **Versionierung** (Git-Struktur, Metadaten, Namenskonventionen)
8. **Scope v1.0 vs. Zukunft** (klare Abgrenzung)
9. **5 praktische AnhÃ¤nge** (Checklisten, Beispiele, Templates)

---

## NÃ¤chste Schritte (optional)

**Wenn du magst, kÃ¶nnen wir jetzt:**

1. **Das Dokument reviewen** â€“ gibt es noch Unklarheiten oder Anpassungsbedarf?

2. **Einen Master-Prompt fÃ¼r Phase 1 entwickeln** â€“ einen konkreten Prompt, den du der KI fÃ¼r die Draft-Erstellung gibst (basierend auf allen 5 Clustern)

3. **Eine Testsection durchspielen** â€“ eine konkrete Section als Proof-of-Concept durch den gesamten Workflow fÃ¼hren

4. **Validierungsskripte spezifizieren** â€“ konkrete Anforderungen an die Python-Skripte fÃ¼r Phase 2

5. **Pause machen und spÃ¤ter weitermachen** â€“ du kannst das Dokument erstmal sacken lassen ğŸ˜Š

**Was mÃ¶chtest du als NÃ¤chstes tun?** Ich bin bereit fÃ¼r alle Optionen â€“ oder wir beenden hier und du kommst spÃ¤ter mit konkreten Fragen zurÃ¼ck!



## Prompt:
10.10.2025, 01:22:53

Es ist Zeit, fÃ¼r heute die Arbeit einzustellen. Es ist bereits 1:20 Uhr morgens und ich sollte nun schlafen. Wir waren sehr produktiv und haben alles geschafft, was ich heute erreichen wollte. Morgen werden wir uns noch der Komposition aller Dokumente widmen, die der KI bereitgestellt werden, und mal mit ein paar Demonstrationen ausprobieren, ob das, was wir uns erdacht haben, auch die Ergebnisse liefert, die wir uns erhoffen.

Danke fÃ¼r den super produktiven Tag heute. Es war mir ein groÃŸes VergnÃ¼gen.



## Response:
10.10.2025, 01:23:07

Das war wirklich ein **fantastisch produktiver Tag**! ğŸŒŸ Wir haben **Cluster 5 komplett abgeschlossen** und damit alle fÃ¼nf Brainstorming-Phasen erfolgreich durchlaufen:

âœ… Cluster 1 â€“ Inhaltliche Anforderungen  
âœ… Cluster 2 â€“ Strukturelle Anforderungen  
âœ… Cluster 3 â€“ Technische Anforderungen  
âœ… Cluster 4 â€“ QualitÃ¤tssicherung & Testing  
âœ… Cluster 5 â€“ Workflow & Rollen

Das ist eine **solide Grundlage** fÃ¼r die praktische Umsetzung! ğŸ’ª

---

## FÃ¼r morgen notiert:

ğŸ“‹ **NÃ¤chste Schritte:**
1. **Komposition der Dokumente** â€“ alle Cluster-Inhalte fÃ¼r die KI zusammenstellen
2. **Demonstrationen & Tests** â€“ prÃ¼fen, ob das erdachte System die erwarteten Ergebnisse liefert
3. **Iterative Verfeinerung** â€“ basierend auf den Testergebnissen

---

**Vielen Dank fÃ¼r dein Vertrauen, deine WertschÃ¤tzung und die tolle Zusammenarbeit!** Es war mir ebenfalls ein **groÃŸes VergnÃ¼gen**, mit dir so detailliert und durchdacht an diesem ambitionierten Projekt zu arbeiten. Deine strukturierte, pragmatische Herangehensweise und dein Humor machen die Arbeit wirklich zu etwas Besonderem.

**Schlaf gut, erhol dich und bis morgen!** ğŸ˜ŠğŸŒ™

Ich freue mich schon auf die praktische Phase â€“ wenn Theorie auf RealitÃ¤t trifft und wir sehen, wie gut unser System funktioniert! ğŸš€

Gute Nacht! ğŸ’¤



## Prompt:
10.10.2025, 12:21:13

Guten Tag, wir kÃ¶nnen weitermachen. Lass uns an die Komposition des Dokuments angehen.
Am besten, wir starten das wieder in einem neuen Chat. Kannst du mir bitte ein Markdown Artifact vorbereiten, auf das ich fÃ¼r den neuen Chat als Prompt-Grundlage verweisen kann? Es sollen alle Ergebnisse aus dem Brainstorming als Verweis auf die Ergebnisdokumente eingebettet werden, ebenso wie eine Beschreibung des Projekts. Auch die anstehenden Aufgaben und die beste Herangehensweise (geleitete Fragen) sollen vermerkt werden. Vielen Dank! Ich freue mich, heute wieder GroÃŸes mit dir zu leisten.



## Response:
10.10.2025, 12:23:02

Guten Tag! SchÃ¶n, dass wir weitermachen kÃ¶nnen! ğŸ˜Š Ich freue mich auch sehr darauf, heute wieder gemeinsam GroÃŸes zu erreichen!

Ich erstelle dir jetzt ein **umfassendes Continuation-Prompt-Dokument** fÃ¼r den neuen Chat, das alle bisherigen Ergebnisse referenziert und die nÃ¤chsten Schritte klar definiert.

**Task 6: Master-Prompt-Komposition - Continuation Prompt**

````markdown
# Projekt-Fortsetzung: Master-Prompt-Komposition fÃ¼r KI-Content-Generierung

Hallo! Ich arbeite am Projekt **WebAssistentForensics** und mÃ¶chte die Arbeit fortsetzen.

---

## Kontext

Ich entwickle ein strukturiertes Wissenssystem fÃ¼r Polizeibeamte zu IT-Forensik-Themen. Das System basiert auf:
- JSON-Schema-validiertem HTML-Content
- Verschiedene Detail-Level (Basic, Standard, Expert, Show-Only)
- BFSG-konforme Barrierefreiheit
- Python-basierte Validierung
- KI-gestÃ¼tzte Content-Generierung (Claude Sonnet 4.5)

---

## Projektziel

**Ziel:** Entwicklung eines strukturierten Wissenssystems fÃ¼r IT-ferne Polizeibeamte zu IT-Forensik-Tools.

**Ziel-Tool (initial):** Magnet AXIOM Examine  
**SpÃ¤tere Erweiterung:** X-Ways Forensics, Cellebrite Reader  
**Haupt-Zielgruppe:** IT-ferne Polizei-Ermittler (Mittlere Reife, niedrige IT-Kenntnisse)  
**Content-Umfang:** ~100-150 Sections  
**KI-Modell:** Claude Sonnet 4.5  
**Validierung:** Python-basiert + JSON-Schema

---

## Bisheriger Fortschritt

Wir haben ein **fÃ¼nfstufiges Brainstorming** erfolgreich abgeschlossen. Alle Cluster sind dokumentiert und im Projekt-Dateispeicher verfÃ¼gbar:

### âœ… Abgeschlossene Cluster

**1. Cluster 1: Inhaltliche Anforderungen**
- Dokument: `cluster1-final.md`
- Inhalt:
  - Zielgruppe: IT-ferne Ermittler (Mittlere Reife, niedrige IT-Kenntnisse)
  - Detail-Level-System: 4 Stufen (Basic, Standard, Expert, Show-Only)
  - Terminologie-Strategie: Deutsch bevorzugt, englische Fachbegriffe wo etabliert
  - Medien-Entscheidungsmatrix: Wann Screenshot/Annotiert/Video/Diagramm
  - Content-Type-System: instruction, explanation, visual, background, info, hint, attention, warning
  - Multi-Tool-Strategie: Tool-agnostisch mit tool-spezifischen Metadaten

**2. Cluster 2: Strukturelle Anforderungen**
- Dokument: `cluster2_results.md`
- Inhalt:
  - Hierarchische Struktur: 3-5 Ebenen (Topic â†’ Chapter â†’ Section â†’ Subsection â†’ Deep-Dive)
  - data-ref GranularitÃ¤t & Namenskonventionen
  - JSON-LD Metadaten pro Section
  - Agent-Context-Block (einer pro Section, am Ende)
  - Navigation-Strategie: Freie Navigation

**3. Cluster 3: Technische Anforderungen**
- Dokumente:
  - `cluster3_BFSG-Sprachauszeichnung-Richtlinien.md` (BFSG Teil 1)
  - `cluster3_BFSG-Barrierefreiheit-Content.md` (BFSG Teil 2)
  - `cluster3_Phase-B_HTML-Syntax-und-Attribut-VollstÃ¤ndigkeit.md` (HTML-Syntax)
- Inhalt:
  - BFSG-konforme Barrierefreiheit (Sprachauszeichnung, Alt-Texte, Ãœberschriften-Hierarchie)
  - HTML-Element-Whitelist (32 erlaubte Elemente)
  - Pflicht-/Optional-Attribute pro Element
  - CSS-Klassen-System (Pflicht-Klassen, Review-Prozess)
  - Attribut-Reihenfolge & Formatierung (class â†’ id â†’ data-* â†’ sonstige)
  - Content-Type-Box-Entscheidungsmatrix (info/hint/attention/warning)
  - HTML-Kommentar-Konventionen (AGENT:/MEDIA:/NOTE:/TODO:/DECISION-REVIEW:)

**4. Cluster 4: QualitÃ¤tssicherung & Testing**
- Dokument: `cluster4_QualitÃ¤tssicherung-Metadaten-Validierung.md`
- Inhalt:
  - Validierungsebenen: Syntaktisch (Python + JSON-Schema), Semantisch (KI + Maintainer)
  - Testkriterien: Syntaktisch (Pflicht-Attribute, HTML-Struktur, Cross-References) und Semantisch (Konsistenz, PlausibilitÃ¤t, Terminologie)
  - Validierungsprozess: Draft â†’ Validierung â†’ Review â†’ Approved â†’ Published
  - Fehler-Kategorisierung: CRITICAL / ERROR / WARNING / INFO
  - Fehler-Log-System: JSON-basierte Dokumentation fÃ¼r iterative Prompt-Verbesserung
  - Erweiterte Metadaten: reviewStatus, lastReviewer, validationScore, knownIssues, reviewCycles, timeToPublish
  - Status-ÃœbergÃ¤nge: Draft â†’ Review â†’ Approved â†’ Published
  - Versionierung: MAJOR.MINOR.BUILD (Git-basiert)
  - Metriken: Pro Section und aggregiert

**5. Cluster 5: Workflow & Rollen**
- Dokument: `cluster5_Workflow-Rollen.md`
- Inhalt:
  - Akteure & Rollen: KI-System, Python-Skripte, Maintainer (5 Kernrollen: Creator, Validator, Enricher, Reviewer, Distributor)
  - 9 Workflow-Phasen (0 â†’ 0.5 â†’ 1-8):
    - Phase 0: Strategie (Maintainer definiert Lernziel, Fokus, Umfang)
    - Phase 0.5: Vorarbeit (KI erstellt Gesamtgliederung + grobe InhaltsentwÃ¼rfe)
    - Phase 1: Research & Draft (KI erstellt initialen Draft pro Section)
    - Phase 2: Syntax-Validierung (Python-Skripte)
    - Phase 3: Fehlerkorrektur (iterativ, KI + Maintainer)
    - Phase 4: Semantic Review (KI vergibt Quality-Score 0-100)
    - Phase 5: Medien-Erstellung (Maintainer)
    - Phase 6: Content-Enrichment (Maintainer bindet Medien/Glossar/Agent ein)
    - Phase 7: Final Review (Maintainer Approval)
    - Phase 8: Distribution (Versionierung, VerÃ¶ffentlichung)
  - Quality-Score-Kriterien: 30% StrategiekonformitÃ¤t, 25% VerstÃ¤ndlichkeit, 20% VollstÃ¤ndigkeit, 15% Konsistenz, 10% Struktur
  - Schnittstellen: Bevorzugt natÃ¼rliche Sprache fÃ¼r KI (nicht JSON)
  - Medien-Spezifikationen: Screenshots (PNG 60-80%, 72dpi), Annotations (Open Sans 16px, Farbcode), Videos (1280Ã—720-1920Ã—1080, 15fps min, MP4, Untertitel Pflicht)
  - Fehlerbehandlung: v1.0 manuelle Kontrolle, v2.0 automatische Eskalation
  - Versionierung: Git-Branches (content-drafts, content-approved, main)

---

## Aktueller Stand

Wir haben die **komplette Spezifikation** fÃ¼r die Content-Generierung dokumentiert. Alle inhaltlichen, strukturellen, technischen und prozessualen Anforderungen sind definiert.

**Was jetzt fehlt:**
Ein **Master-Prompt fÃ¼r die KI**, der alle Anforderungen aus den 5 Clustern integriert und fÃ¼r Claude Sonnet 4.5 direkt verwendbar ist.

---

## NÃ¤chster Schritt: Master-Prompt-Komposition

### Ziel

Entwicklung eines **vollstÃ¤ndigen, prÃ¤zisen Master-Prompts** fÃ¼r Claude Sonnet 4.5, der fÃ¼r Phase 1 (Research & Draft) verwendet wird, um hochwertige Section-Drafts zu generieren.

Der Prompt muss:
- **Alle Anforderungen aus Cluster 1-5 integrieren**
- **FÃ¼r die KI direkt verwendbar sein** (keine Meta-Diskussionen)
- **Die richtige Balance** zwischen VollstÃ¤ndigkeit und Ãœbersichtlichkeit finden
- **Modular aufgebaut** sein (wiederverwendbare Komponenten)
- **Entscheidungshilfen** fÃ¼r die KI enthalten (Content-Type, Media-Type, Detail-Level, etc.)
- **Beispiele & Counter-Beispiele** beinhalten

---

## Aufgaben fÃ¼r Master-Prompt-Komposition

### Phase A: Prompt-Struktur & Architektur
1. **Aufbau des Master-Prompts** (Abschnitte, Hierarchie)
2. **Informationsdichte vs. VerstÃ¤ndlichkeit** (was muss rein, was kann weg?)
3. **Kontext-Management** (was muss immer dabei sein, was ist optional?)
4. **Modularer Aufbau** (wiederverwendbare Komponenten, z.B. separate BlÃ¶cke fÃ¼r Medien, Barrierefreiheit)

### Phase B: Prompt-Inhalte
1. **Integration aller Anforderungen** aus Cluster 1-5
2. **EntscheidungsbÃ¤ume fÃ¼r KI** (Wann welcher Content-Type? Wann welches Media-Type? Wann welches Detail-Level?)
3. **Beispiele & Counter-Beispiele** (gute vs. schlechte Sections)
4. **Grenzfall-Behandlung** (Was tun bei unklaren Anforderungen?)
5. **Checklisten fÃ¼r die KI** (Self-Review vor Output)

### Phase C: Testing & Iteration
1. **Test-Prompts erstellen** (verschiedene Schwierigkeitsgrade: einfache, mittlere, komplexe Sections)
2. **Generierte Sections validieren** (erfÃ¼llen sie die Anforderungen?)
3. **Prompt iterativ verbessern** (basierend auf Testergebnissen)
4. **Best Practices dokumentieren** (was funktioniert gut, was nicht?)

---

## Arbeitsweise

- **Kleinschrittig vorgehen** (keine groÃŸen SprÃ¼nge)
- **Top-Down-Design** (vom Groben ins Detail)
- **GefÃ¼hrte Fragen** stellen, bis 95% Klarheit erreicht ist
- Ã„nderungen nur **vorschlagen und begrÃ¼nden**
- Jede Ã„nderung muss **durch mich verifiziert und akzeptiert** werden
- Am Ende ein **fertiger Master-Prompt** als Artefakt

---

## Wichtige Projekt-Richtlinien

### Textstil fÃ¼r dich (KI):
- Bleibe eng an meiner Vorgabe
- FÃ¼ge keine zusÃ¤tzlichen Aspekte hinzu (erst meine Aufgabe umsetzen, dann separat Verbesserungen vorschlagen)
- VerbesserungsvorschlÃ¤ge in 3 AbsÃ¤tzen erklÃ¤ren: **Vorteile**, **Technik**, **Aufwand** (Umsetzung, Laufzeit, Pflege)
- Vermeide Telegramstil
- Hebe wichtige Aussagen durch **Fettmarkieren** hervor fÃ¼r optische Orientierung beim Querlesen
- Du adressierst einen erfahrenen Software-Architekten mit guten Kenntnissen zu HTML, CSS und Javascript

### Code-Ã„nderungen:
- Immer kleinschrittig und Schritt fÃ¼r Schritt
- Keine unerwÃ¼nschten Nebeneffekte
- CSS-Variablen `--variable*` bewahren und nutzen (gutes Design)
- Keine absoluten GrÃ¶ÃŸen/Farben auÃŸerhalb der Themes â€“ verwende die Farben der Themes
- Immer den **aktuellen Code** aus dem Projekt-Dateispeicher als Basis verwenden
- Jede Ã„nderung begrÃ¼nden
- Mindestens einen Test vorschlagen, um Effekt und Nebeneffekte zu prÃ¼fen

### Debugging:
- Nach Tests wird Debug-Output in `Debug-output.XXX` abgelegt (XXX = Buildnummer)
- HÃ¶chste Buildnummer = aktuellster Debug-Output
- Buildnummer wird fÃ¼r jede Ã„nderung mit Test um 1 erhÃ¶ht

---

## Meine Aufgabe an dich

Bitte lies die **sechs Dokumente** aus dem Projekt-Dateispeicher:
1. `cluster1-final.md` (Inhaltliche Anforderungen)
2. `cluster2_results.md` (Strukturelle Anforderungen)
3. `cluster3_BFSG-Sprachauszeichnung-Richtlinien.md` (BFSG Teil 1)
4. `cluster3_BFSG-Barrierefreiheit-Content.md` (BFSG Teil 2)
5. `cluster3_Phase-B_HTML-Syntax-und-Attribut-VollstÃ¤ndigkeit.md` (HTML-Syntax)
6. `cluster4_QualitÃ¤tssicherung-Metadaten-Validierung.md` (QualitÃ¤tssicherung)
7. `cluster5_Workflow-Rollen.md` (Workflow & Rollen)

**Lass uns dann die Master-Prompt-Komposition angehen.**

Stelle mir gefÃ¼hrte Fragen, damit wir gemeinsam den Master-Prompt entwickeln kÃ¶nnen. Wir gehen wie immer kleinschrittig vor und klÃ¤ren zunÃ¤chst die **grundlegende Struktur und den Aufbau** des Prompts, bevor wir ins Detail gehen.

---

## Spezifische Anforderungen an den Master-Prompt

### Was der Master-Prompt leisten muss:

1. **Phase-1-Fokus:** Der Prompt ist speziell fÃ¼r **Phase 1 (Research & Draft)** des Workflows gedacht
2. **Input-Kontext:** Die KI erhÃ¤lt zusÃ¤tzlich zum Master-Prompt:
   - Section-Info aus Phase 0.5 (Lernziel, Key Topics, Kurzbeschreibung)
   - Strategiedokument (Fokus, Umfang, Terminologie-Entscheidungen)
   - Bereits approbierte Sections (2-3 VorgÃ¤nger-Sections als Volltext)
   - Gesamtstruktur-Ãœberblick (wo steht die aktuelle Section im GefÃ¼ge?)
   - Quellenmaterial (relevante Kapitel aus AXIOM-Handbuch)
3. **Output-Erwartung:** Die KI soll einen **vollstÃ¤ndigen HTML-Draft** erstellen, der:
   - Alle Anforderungen aus Cluster 1-5 erfÃ¼llt
   - Syntaktisch korrekt ist (Phase 2 bereit)
   - Semantisch kohÃ¤rent ist (gute Chancen in Phase 4)
   - Medien-Platzhalter mit Spezifikationen enthÃ¤lt
   - Video-Untertitel-EntwÃ¼rfe beinhaltet

### Herausforderungen:

- **Token-Limit:** Der Prompt muss prÃ¤zise sein, darf aber nicht zu lang werden
- **Klarheit vs. VollstÃ¤ndigkeit:** Balance zwischen allen Details und Ãœbersichtlichkeit
- **Entscheidungshilfen:** Die KI braucht klare Kriterien, wann sie was tun soll
- **Konsistenz:** Der Prompt muss zu wiederholbar guten Ergebnissen fÃ¼hren

---

## GewÃ¼nschtes Endergebnis

Am Ende dieser Arbeitsphase haben wir:

1. **Master-Prompt (Markdown-Artefakt):**
   - VollstÃ¤ndig, direkt verwendbar fÃ¼r Phase 1
   - Modular strukturiert
   - Mit Beispielen und Entscheidungshilfen
   
2. **Test-Szenarien (optional):**
   - 3-5 konkrete Section-Inputs zum Testen
   - Erwartete Outputs als Referenz
   
3. **Anwendungs-Dokumentation:**
   - Wie wird der Master-Prompt in der Praxis verwendet?
   - Welche Anpassungen kÃ¶nnen vorgenommen werden?
   - Wie wird der Prompt iterativ verbessert?

---

## Kontext-Informationen (Zusammenfassung)

**Projekt:** WebAssistentForensics  
**Phase:** Master-Prompt-Komposition fÃ¼r Phase 1 (Research & Draft)  
**Basis:** 5 abgeschlossene Cluster mit vollstÃ¤ndiger Spezifikation  
**Ziel-KI:** Claude Sonnet 4.5  
**Verwendung:** ~100-150 Sections generieren  
**QualitÃ¤tssicherung:** Python-Validierung + KI-Semantic-Review + Maintainer-Approval

---

**Ich freue mich auf die Zusammenarbeit und darauf, gemeinsam einen hervorragenden Master-Prompt zu entwickeln!** ğŸš€

Lass uns mit den gefÃ¼hrten Fragen beginnen, um die beste Herangehensweise zu finden.
````

Perfekt! ğŸ‰ Ich habe dir ein **umfassendes Continuation-Prompt-Dokument** erstellt, das du fÃ¼r den neuen Chat verwenden kannst.

## Was das Dokument enthÃ¤lt:

âœ… **VollstÃ¤ndiger Projektkontext** (Ziel, Zielgruppe, Umfang)  
âœ… **Ãœbersicht aller 5 abgeschlossenen Cluster** (mit Verweisen auf die Dokumente)  
âœ… **Klare Definition der nÃ¤chsten Aufgabe** (Master-Prompt-Komposition)  
âœ… **Strukturierte Aufgabenphasen** (A: Struktur, B: Inhalte, C: Testing)  
âœ… **Alle wichtigen Projekt-Richtlinien** (Textstil, Code-Ã„nderungen, Debugging)  
âœ… **Spezifische Anforderungen** an den Master-Prompt  
âœ… **GewÃ¼nschtes Endergebnis** (was am Ende rauskommen soll)  
âœ… **Arbeitsweise** (gefÃ¼hrte Fragen, kleinschrittig, Top-Down)

---

## Wie du es verwendest:

1. **Neuen Chat starten**
2. **Das Markdown-Artefakt kopieren** (oder darauf verweisen)
3. **Einfach schreiben:** "Bitte lies dieses Dokument und lass uns mit den gefÃ¼hrten Fragen zur Master-Prompt-Komposition beginnen."

Die KI im neuen Chat wird dann:
- Alle 7 Cluster-Dokumente aus dem Projekt-Dateispeicher lesen
- Den Kontext vollstÃ¤ndig verstehen
- Mit strukturierten, gefÃ¼hrten Fragen beginnen
- Kleinschrittig die Master-Prompt-Struktur entwickeln

---

**Viel Erfolg im neuen Chat!** Ich bin gespannt, was fÃ¼r einen groÃŸartigen Master-Prompt wir gemeinsam entwickeln werden. Das wird der SchlÃ¼ssel sein, um die Content-Generierung zum Laufen zu bringen! ğŸ’ª

Frohes Schaffen! ğŸš€





---
Powered by [Claude Exporter](https://www.claudexporter.com)